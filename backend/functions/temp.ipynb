{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import RegressionExperiment\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../Datasets/68071.csv')\n",
    "# target_column = 'income'\n",
    "model_name = 'adult'\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_91e8f_row11_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_91e8f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_91e8f_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_91e8f_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_91e8f_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_91e8f_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_91e8f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_91e8f_row1_col1\" class=\"data row1 col1\" >income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_91e8f_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_91e8f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_91e8f_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_91e8f_row3_col1\" class=\"data row3 col1\" ><=50K: 0, >50K: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_91e8f_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_91e8f_row4_col1\" class=\"data row4 col1\" >(48842, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_91e8f_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_91e8f_row5_col1\" class=\"data row5 col1\" >(48842, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_91e8f_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_91e8f_row6_col1\" class=\"data row6 col1\" >(34189, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_91e8f_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_91e8f_row7_col1\" class=\"data row7 col1\" >(14653, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_91e8f_row8_col0\" class=\"data row8 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_91e8f_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_91e8f_row9_col0\" class=\"data row9 col0\" >Numeric features</td>\n",
       "      <td id=\"T_91e8f_row9_col1\" class=\"data row9 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_91e8f_row10_col0\" class=\"data row10 col0\" >Categorical features</td>\n",
       "      <td id=\"T_91e8f_row10_col1\" class=\"data row10 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_91e8f_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_91e8f_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_91e8f_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_91e8f_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_91e8f_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_91e8f_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_91e8f_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_91e8f_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_91e8f_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_91e8f_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_91e8f_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_91e8f_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_91e8f_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_91e8f_row17_col1\" class=\"data row17 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_91e8f_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_91e8f_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_91e8f_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_91e8f_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_91e8f_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_91e8f_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_91e8f_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_91e8f_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_91e8f_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_91e8f_row22_col1\" class=\"data row22 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_91e8f_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_91e8f_row23_col1\" class=\"data row23 col1\" >2b45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd9dfb30400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fd9e4777970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(data, target=target_column, session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e10a3_row10_col0, #T_e10a3_row10_col1, #T_e10a3_row10_col2, #T_e10a3_row10_col3, #T_e10a3_row10_col4, #T_e10a3_row10_col5, #T_e10a3_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e10a3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e10a3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_e10a3_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_e10a3_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_e10a3_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_e10a3_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_e10a3_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_e10a3_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e10a3_row0_col0\" class=\"data row0 col0\" >0.8017</td>\n",
       "      <td id=\"T_e10a3_row0_col1\" class=\"data row0 col1\" >0.6288</td>\n",
       "      <td id=\"T_e10a3_row0_col2\" class=\"data row0 col2\" >0.2800</td>\n",
       "      <td id=\"T_e10a3_row0_col3\" class=\"data row0 col3\" >0.7201</td>\n",
       "      <td id=\"T_e10a3_row0_col4\" class=\"data row0 col4\" >0.4032</td>\n",
       "      <td id=\"T_e10a3_row0_col5\" class=\"data row0 col5\" >0.3109</td>\n",
       "      <td id=\"T_e10a3_row0_col6\" class=\"data row0 col6\" >0.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e10a3_row1_col0\" class=\"data row1 col0\" >0.7967</td>\n",
       "      <td id=\"T_e10a3_row1_col1\" class=\"data row1 col1\" >0.8309</td>\n",
       "      <td id=\"T_e10a3_row1_col2\" class=\"data row1 col2\" >0.3545</td>\n",
       "      <td id=\"T_e10a3_row1_col3\" class=\"data row1 col3\" >0.6346</td>\n",
       "      <td id=\"T_e10a3_row1_col4\" class=\"data row1 col4\" >0.4549</td>\n",
       "      <td id=\"T_e10a3_row1_col5\" class=\"data row1 col5\" >0.3421</td>\n",
       "      <td id=\"T_e10a3_row1_col6\" class=\"data row1 col6\" >0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e10a3_row2_col0\" class=\"data row2 col0\" >0.7988</td>\n",
       "      <td id=\"T_e10a3_row2_col1\" class=\"data row2 col1\" >0.5719</td>\n",
       "      <td id=\"T_e10a3_row2_col2\" class=\"data row2 col2\" >0.2555</td>\n",
       "      <td id=\"T_e10a3_row2_col3\" class=\"data row2 col3\" >0.7257</td>\n",
       "      <td id=\"T_e10a3_row2_col4\" class=\"data row2 col4\" >0.3779</td>\n",
       "      <td id=\"T_e10a3_row2_col5\" class=\"data row2 col5\" >0.2894</td>\n",
       "      <td id=\"T_e10a3_row2_col6\" class=\"data row2 col6\" >0.3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e10a3_row3_col0\" class=\"data row3 col0\" >0.8049</td>\n",
       "      <td id=\"T_e10a3_row3_col1\" class=\"data row3 col1\" >0.6175</td>\n",
       "      <td id=\"T_e10a3_row3_col2\" class=\"data row3 col2\" >0.2787</td>\n",
       "      <td id=\"T_e10a3_row3_col3\" class=\"data row3 col3\" >0.7475</td>\n",
       "      <td id=\"T_e10a3_row3_col4\" class=\"data row3 col4\" >0.4061</td>\n",
       "      <td id=\"T_e10a3_row3_col5\" class=\"data row3 col5\" >0.3173</td>\n",
       "      <td id=\"T_e10a3_row3_col6\" class=\"data row3 col6\" >0.3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e10a3_row4_col0\" class=\"data row4 col0\" >0.7970</td>\n",
       "      <td id=\"T_e10a3_row4_col1\" class=\"data row4 col1\" >0.6027</td>\n",
       "      <td id=\"T_e10a3_row4_col2\" class=\"data row4 col2\" >0.2592</td>\n",
       "      <td id=\"T_e10a3_row4_col3\" class=\"data row4 col3\" >0.7067</td>\n",
       "      <td id=\"T_e10a3_row4_col4\" class=\"data row4 col4\" >0.3792</td>\n",
       "      <td id=\"T_e10a3_row4_col5\" class=\"data row4 col5\" >0.2878</td>\n",
       "      <td id=\"T_e10a3_row4_col6\" class=\"data row4 col6\" >0.3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e10a3_row5_col0\" class=\"data row5 col0\" >0.8005</td>\n",
       "      <td id=\"T_e10a3_row5_col1\" class=\"data row5 col1\" >0.6340</td>\n",
       "      <td id=\"T_e10a3_row5_col2\" class=\"data row5 col2\" >0.2604</td>\n",
       "      <td id=\"T_e10a3_row5_col3\" class=\"data row5 col3\" >0.7345</td>\n",
       "      <td id=\"T_e10a3_row5_col4\" class=\"data row5 col4\" >0.3845</td>\n",
       "      <td id=\"T_e10a3_row5_col5\" class=\"data row5 col5\" >0.2964</td>\n",
       "      <td id=\"T_e10a3_row5_col6\" class=\"data row5 col6\" >0.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e10a3_row6_col0\" class=\"data row6 col0\" >0.7991</td>\n",
       "      <td id=\"T_e10a3_row6_col1\" class=\"data row6 col1\" >0.5716</td>\n",
       "      <td id=\"T_e10a3_row6_col2\" class=\"data row6 col2\" >0.2653</td>\n",
       "      <td id=\"T_e10a3_row6_col3\" class=\"data row6 col3\" >0.7162</td>\n",
       "      <td id=\"T_e10a3_row6_col4\" class=\"data row6 col4\" >0.3872</td>\n",
       "      <td id=\"T_e10a3_row6_col5\" class=\"data row6 col5\" >0.2961</td>\n",
       "      <td id=\"T_e10a3_row6_col6\" class=\"data row6 col6\" >0.3486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e10a3_row7_col0\" class=\"data row7 col0\" >0.7964</td>\n",
       "      <td id=\"T_e10a3_row7_col1\" class=\"data row7 col1\" >0.5653</td>\n",
       "      <td id=\"T_e10a3_row7_col2\" class=\"data row7 col2\" >0.2482</td>\n",
       "      <td id=\"T_e10a3_row7_col3\" class=\"data row7 col3\" >0.7148</td>\n",
       "      <td id=\"T_e10a3_row7_col4\" class=\"data row7 col4\" >0.3684</td>\n",
       "      <td id=\"T_e10a3_row7_col5\" class=\"data row7 col5\" >0.2796</td>\n",
       "      <td id=\"T_e10a3_row7_col6\" class=\"data row7 col6\" >0.3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e10a3_row8_col0\" class=\"data row8 col0\" >0.7938</td>\n",
       "      <td id=\"T_e10a3_row8_col1\" class=\"data row8 col1\" >0.5578</td>\n",
       "      <td id=\"T_e10a3_row8_col2\" class=\"data row8 col2\" >0.2552</td>\n",
       "      <td id=\"T_e10a3_row8_col3\" class=\"data row8 col3\" >0.6875</td>\n",
       "      <td id=\"T_e10a3_row8_col4\" class=\"data row8 col4\" >0.3722</td>\n",
       "      <td id=\"T_e10a3_row8_col5\" class=\"data row8 col5\" >0.2787</td>\n",
       "      <td id=\"T_e10a3_row8_col6\" class=\"data row8 col6\" >0.3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e10a3_row9_col0\" class=\"data row9 col0\" >0.7946</td>\n",
       "      <td id=\"T_e10a3_row9_col1\" class=\"data row9 col1\" >0.5878</td>\n",
       "      <td id=\"T_e10a3_row9_col2\" class=\"data row9 col2\" >0.2543</td>\n",
       "      <td id=\"T_e10a3_row9_col3\" class=\"data row9 col3\" >0.6933</td>\n",
       "      <td id=\"T_e10a3_row9_col4\" class=\"data row9 col4\" >0.3721</td>\n",
       "      <td id=\"T_e10a3_row9_col5\" class=\"data row9 col5\" >0.2796</td>\n",
       "      <td id=\"T_e10a3_row9_col6\" class=\"data row9 col6\" >0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_e10a3_row10_col0\" class=\"data row10 col0\" >0.7984</td>\n",
       "      <td id=\"T_e10a3_row10_col1\" class=\"data row10 col1\" >0.6168</td>\n",
       "      <td id=\"T_e10a3_row10_col2\" class=\"data row10 col2\" >0.2711</td>\n",
       "      <td id=\"T_e10a3_row10_col3\" class=\"data row10 col3\" >0.7081</td>\n",
       "      <td id=\"T_e10a3_row10_col4\" class=\"data row10 col4\" >0.3906</td>\n",
       "      <td id=\"T_e10a3_row10_col5\" class=\"data row10 col5\" >0.2978</td>\n",
       "      <td id=\"T_e10a3_row10_col6\" class=\"data row10 col6\" >0.3479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_e10a3_row11_col0\" class=\"data row11 col0\" >0.0032</td>\n",
       "      <td id=\"T_e10a3_row11_col1\" class=\"data row11 col1\" >0.0758</td>\n",
       "      <td id=\"T_e10a3_row11_col2\" class=\"data row11 col2\" >0.0295</td>\n",
       "      <td id=\"T_e10a3_row11_col3\" class=\"data row11 col3\" >0.0298</td>\n",
       "      <td id=\"T_e10a3_row11_col4\" class=\"data row11 col4\" >0.0246</td>\n",
       "      <td id=\"T_e10a3_row11_col5\" class=\"data row11 col5\" >0.0193</td>\n",
       "      <td id=\"T_e10a3_row11_col6\" class=\"data row11 col6\" >0.0142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fda45412770>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=123, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=123, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.create_model('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_config('X_train').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "hello\n",
      "Description              Value\n",
      "hello\n",
      "0                    Session id                123\n",
      "hello\n",
      "1                        Target             income\n",
      "hello\n",
      "2                   Target type             Binary\n",
      "hello\n",
      "3                Target mapping  <=50K: 0, >50K: 1\n",
      "hello\n",
      "4           Original data shape        (48790, 15)\n",
      "hello\n",
      "5        Transformed data shape        (48790, 67)\n",
      "hello\n",
      "6   Transformed train set shape        (34153, 67)\n",
      "hello\n",
      "7    Transformed test set shape        (14637, 67)\n",
      "hello\n",
      "8              Ordinal features                  1\n",
      "hello\n",
      "9              Numeric features                  6\n",
      "hello\n",
      "10         Categorical features                  8\n",
      "hello\n",
      "11                   Preprocess               True\n",
      "hello\n",
      "12              Imputation type             simple\n",
      "hello\n",
      "13           Numeric imputation               mean\n",
      "hello\n",
      "14       Categorical imputation               mode\n",
      "hello\n",
      "15     Maximum one-hot encoding                 25\n",
      "hello\n",
      "16              Encoding method               None\n",
      "hello\n",
      "17               Fold Generator    StratifiedKFold\n",
      "hello\n",
      "18                  Fold Number                 10\n",
      "hello\n",
      "19                     CPU Jobs                 -1\n",
      "hello\n",
      "20                      Use GPU              False\n",
      "hello\n",
      "21               Log Experiment              False\n",
      "hello\n",
      "22              Experiment Name   clf-default-name\n",
      "hello\n",
      "23                          USI               78c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "hello\n",
      "ada      Ada Boost Classifier    0.8622  0.9171  0.6156  0.7636  0.6815\n",
      "hello\n",
      "lr        Logistic Regression    0.8519  0.9063  0.5994  0.7336  0.6596\n",
      "hello\n",
      "rf   Random Forest Classifier    0.8550  0.9049  0.6257  0.7305  0.6739\n",
      "hello\n",
      "nb                Naive Bayes    0.6843  0.8700  0.9019  0.4254  0.5780\n",
      "hello\n",
      "knn    K Neighbors Classifier    0.8253  0.8452  0.5734  0.6544  0.6111\n",
      "hello\n",
      "dt   Decision Tree Classifier    0.8159  0.7499  0.6233  0.6141  0.6185\n",
      "hello\n",
      "svm       SVM - Linear Kernel    0.8481  0.0000  0.5688  0.7397  0.6408\n",
      "hello\n",
      "\n",
      "hello\n",
      "Kappa     MCC  TT (Sec)\n",
      "hello\n",
      "ada  0.5949  0.6007     0.310\n",
      "hello\n",
      "lr   0.5662  0.5710     0.611\n",
      "hello\n",
      "rf   0.5814  0.5844     0.642\n",
      "hello\n",
      "nb   0.3743  0.4422     0.221\n",
      "hello\n",
      "knn  0.4991  0.5010     0.656\n",
      "hello\n",
      "dt   0.4973  0.4974     0.206\n",
      "hello\n",
      "svm  0.5469  0.5559     0.207\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import subprocess\n",
    "# import sys \n",
    "# sys.path.append('/home/ayush/BTP-2/backend/')\n",
    "# import trainModelAutoML\n",
    "process = subprocess.Popen(['python3', '/home/ayush/BTP-2/backend/functions/trainModelAutoML.py'], stdout=subprocess.PIPE)\n",
    "\n",
    "while True:\n",
    "    output = process.stdout.readline()\n",
    "    # print(output)\n",
    "    if output.decode('utf-8') == '' and process.poll() is not None:\n",
    "        break\n",
    "    if output:\n",
    "        print('hello')\n",
    "        print(output.strip().decode('utf-8'))\n",
    "        # print(\"hello\")\n",
    "        # sse.publish(output.strip().decode('utf-8'), type='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(capturedOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_leaderboard = exp.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=FastMemory(location=/tmp/joblib),\n",
      "         steps=[('label_encoding',\n",
      "                 TransformerWrapperWithInverse(exclude=None, include=None,\n",
      "                                               transformer=LabelEncoder())),\n",
      "                ('numerical_imputer',\n",
      "                 TransformerWrapper(exclude=None,\n",
      "                                    include=['age', 'fnlwgt', 'educational-num',\n",
      "                                             'capital-gain', 'capital-loss',\n",
      "                                             'hours-per-week'],\n",
      "                                    transformer=SimpleImputer(add_indicator=False,\n",
      "                                                              co...\n",
      "                                                              min_samples_leaf=20,\n",
      "                                                              return_df=True,\n",
      "                                                              smoothing=10,\n",
      "                                                              verbose=0))),\n",
      "                ('clean_column_names',\n",
      "                 TransformerWrapper(exclude=None, include=None,\n",
      "                                    transformer=CleanColumnNames(match='[\\\\]\\\\[\\\\,\\\\{\\\\}\\\\\"\\\\:]+'))),\n",
      "                ['trained_model',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=-1, n_neighbors=5, p=2,\n",
      "                                      weights='uniform')]],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(get_leaderboard.iloc[0]['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797535e997844369bf0982a3aece849a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from time import sleep\n",
    "\n",
    "text = \"\"\n",
    "for char in tqdm([\"a\", \"b\", \"c\", \"d\"]):\n",
    "    sleep(5)\n",
    "    text = text + char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exp.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>0.3221</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
       "lr      Logistic Regression    0.7984  0.6168  0.2711  0.7081  0.3906  0.2978   \n",
       "knn  K Neighbors Classifier    0.7766  0.6766  0.3221  0.5577  0.4082  0.2825   \n",
       "\n",
       "        MCC  TT (Sec)  \n",
       "lr   0.3479     0.761  \n",
       "knn  0.2988     0.782  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "Accuracy\n",
      "AUC\n",
      "Recall\n",
      "Prec.\n",
      "F1\n",
      "Kappa\n",
      "MCC\n",
      "TT (Sec)\n"
     ]
    }
   ],
   "source": [
    "for column in results.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.3479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "Fold                                                          \n",
       "Mean    0.7984  0.6168  0.2711  0.7081  0.3906  0.2978  0.3479"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results.index == 'Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7984\n",
      "0.6168\n",
      "0.2711\n",
      "0.7081\n",
      "0.3906\n",
      "0.2978\n",
      "0.3479\n"
     ]
    }
   ],
   "source": [
    "for metric in results.columns:\n",
    "    print(results[results.index == 'Mean'][metric].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(['TT (Sec)','Kappa', 'MCC'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.6745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy     AUC  Recall   Prec.      F1\n",
       "rf  Random Forest Classifier    0.8569  0.9040  0.6199  0.7401  0.6745\n",
       "lr       Logistic Regression    0.7984  0.6168  0.2711  0.7081  0.3906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.8569\n",
      "AUC\n",
      "0.904\n",
      "Recall\n",
      "0.6199\n",
      "Prec.\n",
      "0.7401\n",
      "F1\n",
      "0.6745\n"
     ]
    }
   ],
   "source": [
    "for metric in results.columns:\n",
    "    # print first row's metric\n",
    "    if metric == 'Model':\n",
    "        continue\n",
    "    print(metric)\n",
    "    print(results.iloc[0][metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.548913</td>\n",
       "      <td>0.334021</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>0.325503</td>\n",
       "      <td>0.742666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.570652</td>\n",
       "      <td>0.358427</td>\n",
       "      <td>0.354621</td>\n",
       "      <td>0.345584</td>\n",
       "      <td>0.742626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.358026</td>\n",
       "      <td>0.350028</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.593768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.405137</td>\n",
       "      <td>0.401276</td>\n",
       "      <td>0.399125</td>\n",
       "      <td>0.760712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.538043</td>\n",
       "      <td>0.334563</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.334558</td>\n",
       "      <td>0.689957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.385870</td>\n",
       "      <td>0.352309</td>\n",
       "      <td>0.392148</td>\n",
       "      <td>0.246430</td>\n",
       "      <td>0.739050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.548913</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.335749</td>\n",
       "      <td>0.680536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy  Precision    Recall  F1-Score       AUC\n",
       "0      LogisticRegression  0.548913   0.334021  0.335510  0.325503  0.742666\n",
       "1                     SVC  0.570652   0.358427  0.354621  0.345584  0.742626\n",
       "2  DecisionTreeClassifier  0.554348   0.358026  0.350028  0.348534  0.593768\n",
       "3  RandomForestClassifier  0.614130   0.405137  0.401276  0.399125  0.760712\n",
       "4      AdaBoostClassifier  0.538043   0.334563  0.338462  0.334558  0.689957\n",
       "5              GaussianNB  0.385870   0.352309  0.392148  0.246430  0.739050\n",
       "6    KNeighborsClassifier  0.548913   0.341224  0.343373  0.335749  0.680536"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/27562.csv')\n",
    "target_column = 'num'\n",
    "classification_utility = ClassificationUtility(data, target_column)\n",
    "classification_utility.train()\n",
    "classification_utility.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'income'],\n",
      "      dtype='object')\n",
      "['education', 'occupation', 'native-country']\n",
      "['workclass', 'marital-status', 'relationship', 'race', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# make a pipeline of the following steps\n",
    "# i) Imputation of numerical and categorical variables\n",
    "# ii) Encoding of categorical variables using target encoding if cardinality is less than 10 else one hot encoding\n",
    "# iii) Scaling of numerical variables\n",
    "# iv) Estimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../Datasets/68071.csv')\n",
    "target_column = 'income'\n",
    "model_name = 'adult'\n",
    "\n",
    "\n",
    "\n",
    "# find categorical and numerical columns\n",
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        categorical_columns.append(column)\n",
    "    else:\n",
    "        numerical_columns.append(column)\n",
    "\n",
    "# find cardinality of categorical columns\n",
    "cardinality = {}\n",
    "for column in categorical_columns:\n",
    "    cardinality[column] = len(data[column].unique())\n",
    "\n",
    "# find columns to be target encoded\n",
    "target_encoded_columns = []\n",
    "one_hot_encoded_columns = []\n",
    "for column in categorical_columns:\n",
    "    if column != target_column:\n",
    "        if cardinality[column] > 10:\n",
    "            target_encoded_columns.append(column)\n",
    "        else:\n",
    "            one_hot_encoded_columns.append(column)\n",
    "\n",
    "# find columns to be one hot encoded\n",
    "\n",
    "le = LabelEncoder()\n",
    "data[target_column] = le.fit_transform(data[target_column])\n",
    "        \n",
    "print(data.columns)\n",
    "print(target_encoded_columns)\n",
    "print(one_hot_encoded_columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# make pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "target_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target', TargetEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, one_hot_encoded_columns),\n",
    "        ('target', target_categorical_transformer, target_encoded_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel='linear', max_iter=1000),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "scores_arr = []\n",
    "# for classifier in tqdm(classifiers):\n",
    "\n",
    "estimator = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = cross_val_score(estimator, X_train, y_train, cv=5, scoring='accuracy')\n",
    "scores_arr.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8511117586099672, 0.4784630681268004, 0.8142582622544747, 0.8619631987863128, 0.8630482533082594, 0.7209778395263091, 0.8345071814106516]\n"
     ]
    }
   ],
   "source": [
    "print(scores_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# print label encoder mapping\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from Enums.enums import ClassificationMetrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ClassificationUtility():\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.cardinality_threshold = 10\n",
    "        self.classifiers = [\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            SVC(kernel='linear', max_iter=1000, probability=True),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            GaussianNB(),\n",
    "            KNeighborsClassifier()\n",
    "        ]\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64':\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def encode_target_column(self):\n",
    "        le = LabelEncoder()\n",
    "        self.data[self.target_column] = le.fit_transform(self.data[self.target_column])\n",
    "        self.le = le\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "        self.encode_target_column()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "        classification_metrics = ClassificationMetrics\n",
    "        columns_names = []\n",
    "        columns_names.append('Classifier')\n",
    "        for metric in classification_metrics:\n",
    "            columns_names.append(metric.value)\n",
    "\n",
    "        results = [columns_names]\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            X = self.data.drop(self.target_column, axis=1)\n",
    "            y = self.data[self.target_column]\n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            self.estimator.fit(X_train, y_train)\n",
    "\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            if len(self.le.classes_) == 2:\n",
    "                auc = roc_auc_score(y_test, self.estimator.predict_proba(X_test)[:, 1])\n",
    "            else:\n",
    "                auc = roc_auc_score(y_test, self.estimator.predict_proba(X_test), average='macro', multi_class='ovo')\n",
    "\n",
    "            results.append([classifier.__class__.__name__, accuracy, precision, recall, f1, auc])\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results[1:], columns=results[0])\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        for i, class_name in enumerate(self.le.classes_):\n",
    "            self.output_mapping[i] = class_name\n",
    "        return self.output_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: KNeighborsClassifier Processing: 100%|██████████| 7/7 [01:08<00:00,  9.72s/it]  \n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('../Datasets/27562.csv')\n",
    "data = pd.read_csv('../Datasets/68071.csv')\n",
    "target_column = 'income'\n",
    "classification_utility = ClassificationUtility(data, target_column)\n",
    "classification_utility.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(classification_utility.le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classification_utility.results\n",
    "best_model_name = classification_utility.getBestModel(ClassificationMetrics.Accuracy.value)['Classifier']\n",
    "model_parameters = classification_utility.trained_models[best_model_name].get_params()\n",
    "metrics = []\n",
    "for metric in results.columns:\n",
    "    if metric == 'Classifier':\n",
    "        continue\n",
    "    metrics.append({\n",
    "        'metric_name' : metric,\n",
    "        'metric_value' : results.iloc[0][metric],\n",
    "    })\n",
    "\n",
    "parameters = []\n",
    "for key, value in model_parameters.items():\n",
    "    if value == None:\n",
    "        value = 'None'\n",
    "    parameters.append({\n",
    "        'parameter_name' : key,\n",
    "        'parameter_value' : value\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_utility.saveModel(best_model_name, '../Models/27562.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../Models/27562.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric_name': 'Accuracy', 'metric_value': 0.6413043478260869}, {'metric_name': 'AUC', 'metric_value': 0.44483974358974365}, {'metric_name': 'Precision', 'metric_value': 0.42140170940170946}, {'metric_name': 'Recall', 'metric_value': 0.42327461024408475}, {'metric_name': 'F1', 'metric_value': 0.775362559354226}]\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy       AUC  Precision    Recall        F1\n",
      "3  RandomForestClassifier  0.641304  0.444840   0.421402  0.423275  0.775363\n",
      "1                     SVC  0.570652  0.358427   0.354621  0.345584  0.742021\n",
      "2  DecisionTreeClassifier  0.554348  0.384571   0.393066  0.381803  0.620666\n",
      "0      LogisticRegression  0.548913  0.334021   0.335510  0.325503  0.742666\n",
      "6    KNeighborsClassifier  0.548913  0.341224   0.343373  0.335749  0.680536\n",
      "4      AdaBoostClassifier  0.538043  0.334563   0.338462  0.334558  0.689957\n",
      "5              GaussianNB  0.385870  0.352309   0.392148  0.246430  0.739050\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import regression models\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import sys \n",
    "project_path = os.getenv('PROJECT_PATH')\n",
    "sys.path.append(project_path)\n",
    "sys.path.append('../Enums/')\n",
    "from Enums.enums import RegressionMetrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class RegressionUtility():\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.cardinality_threshold = 10\n",
    "        self.classifiers = [\n",
    "            Ridge(alpha=0.5),\n",
    "            BayesianRidge(),\n",
    "            RandomForestRegressor(),\n",
    "            AdaBoostRegressor()\n",
    "        ]\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and (self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64'):\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "\n",
    "        results = []\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            X = self.data.drop(self.target_column, axis=1)\n",
    "            y = self.data[self.target_column]\n",
    "            \n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            self.estimator.fit(X_train, y_train)\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "            results.append({\n",
    "                'Classifier' : classifier.__class__.__name__,\n",
    "                RegressionMetrics.R2.value : r2,\n",
    "                RegressionMetrics.MSE.value : mse,\n",
    "                RegressionMetrics.MAE.value : mae,\n",
    "                RegressionMetrics.RMSE.value : rmse\n",
    "            })\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results)\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        for i, class_name in enumerate(self.le.classes_):\n",
    "            self.output_mapping[str(class_name)] = i\n",
    "        return self.output_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../backend/Walmart.csv')\n",
    "target_column = 'Weekly_Sales'\n",
    "reg_util = RegressionUtility(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: AdaBoostRegressor Processing: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]    \n"
     ]
    }
   ],
   "source": [
    "reg_util.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.159073</td>\n",
       "      <td>2.709084e+11</td>\n",
       "      <td>433043.517724</td>\n",
       "      <td>520488.659793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>3.200472e+11</td>\n",
       "      <td>475527.780787</td>\n",
       "      <td>565727.167346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.972341</td>\n",
       "      <td>8.910513e+09</td>\n",
       "      <td>56805.422846</td>\n",
       "      <td>94395.512885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.366526</td>\n",
       "      <td>2.040766e+11</td>\n",
       "      <td>393209.639893</td>\n",
       "      <td>451748.408276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Classifier  R2 Score  Mean Squared Error  Mean Absolute Error  \\\n",
       "0                  Ridge  0.159073        2.709084e+11        433043.517724   \n",
       "1          BayesianRidge  0.006541        3.200472e+11        475527.780787   \n",
       "2  RandomForestRegressor  0.972341        8.910513e+09         56805.422846   \n",
       "3      AdaBoostRegressor  0.366526        2.040766e+11        393209.639893   \n",
       "\n",
       "   Root Mean Squared Error  \n",
       "0            520488.659793  \n",
       "1            565727.167346  \n",
       "2             94395.512885  \n",
       "3            451748.408276  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_util.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc, confusion_matrix, precision_recall_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys \n",
    "project_path = os.getenv('PROJECT_PATH')\n",
    "sys.path.append(project_path)\n",
    "sys.path.append('../Enums/')\n",
    "# from Enums.enums import ClassificationMetrics\n",
    "from enum import Enum\n",
    "class ClassificationMetrics(Enum):\n",
    "    Accuracy = \"Accuracy\"\n",
    "    AUC = \"AUC\"\n",
    "    Precision = \"Precision\"\n",
    "    Recall = \"Recall\"\n",
    "    F1 = \"F1\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ClassificationUtility():\n",
    "    def __init__(self, data, target_column, metric_to_optimize=ClassificationMetrics.Accuracy.value):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.metric_to_optimize = metric_to_optimize\n",
    "        self.cardinality_threshold = 10\n",
    "        self.classifiers = [\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            SVC(kernel='linear', max_iter=1000, probability=True),\n",
    "            GaussianNB(),\n",
    "            KNeighborsClassifier()\n",
    "        ]\n",
    "        self.classifiers_dict = {\n",
    "            LogisticRegression().__class__.__name__ : LogisticRegression(max_iter=1000),\n",
    "            DecisionTreeClassifier().__class__.__name__ : DecisionTreeClassifier(),\n",
    "            RandomForestClassifier().__class__.__name__ : RandomForestClassifier(),\n",
    "            AdaBoostClassifier().__class__.__name__ : AdaBoostClassifier(),\n",
    "            SVC().__class__.__name__ : SVC(kernel='linear', max_iter=1000, probability=True),\n",
    "            GaussianNB().__class__.__name__ : GaussianNB(),\n",
    "            KNeighborsClassifier().__class__.__name__ : KNeighborsClassifier()\n",
    "        }\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and (self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64'):\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def encode_target_column(self):\n",
    "        le = LabelEncoder()\n",
    "        self.data[self.target_column] = le.fit_transform(self.data[self.target_column])\n",
    "        self.le = le\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.data.drop(self.target_column, axis=1)\n",
    "        y = self.data[self.target_column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "        self.split_data()\n",
    "        self.encode_target_column()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "        classification_metrics = ClassificationMetrics\n",
    "        \n",
    "        results = []\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            \n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "            self.estimator.fit(self.X_train, self.y_train)\n",
    "\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(self.X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            accuracy = accuracy_score(self.y_test, y_pred)\n",
    "            precision = precision_score(self.y_test, y_pred, average='macro')\n",
    "            recall = recall_score(self.y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(self.y_test, y_pred, average='macro')\n",
    "            if len(self.le.classes_) == 2:\n",
    "                auc = roc_auc_score(self.y_test, self.estimator.predict_proba(self.X_test)[:, 1])\n",
    "            else:\n",
    "                auc = roc_auc_score(self.y_test, self.estimator.predict_proba(self.X_test), average='macro', multi_class='ovo')\n",
    "\n",
    "            results.append({\n",
    "                'classifier' : classifier.__class__.__name__,\n",
    "                classification_metrics.Accuracy.value : round(accuracy, 4),\n",
    "                classification_metrics.Precision.value : round(precision, 4),\n",
    "                classification_metrics.Recall.value : round(recall, 4),\n",
    "                classification_metrics.F1.value : round(f1, 4),\n",
    "                classification_metrics.AUC.value : round(auc, 4)\n",
    "            })\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results)\n",
    "        self.best_model = self.getBestModel(self.metric_to_optimize)\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        self.best_estimator = self.trained_models[self.best_model['classifier']]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        for i, class_name in enumerate(self.le.classes_):\n",
    "            self.output_mapping[i] = str(class_name)\n",
    "        return self.output_mapping\n",
    "    \n",
    "    def get_confusion_matrix(self):\n",
    "        cm = confusion_matrix(self.y_test, self.best_estimator.predict(self.X_test))\n",
    "        return cm.tolist()\n",
    "    \n",
    "    # def get_learning_curve_data(self):\n",
    "    #     self.get_estimator(self.classifiers_dict[self.best_model['classifier']])\n",
    "    #     train_sizes, train_scores, test_scores = learning_curve(self.estimator, self.X_train, self.y_train, scoring='accuracy', n_jobs=4)\n",
    "    #     learning_curve_data = {}\n",
    "    #     learning_curve_data['train_sizes'] = train_sizes.tolist()\n",
    "    #     learning_curve_data['train_scores'] = train_scores.tolist()\n",
    "    #     learning_curve_data['test_scores'] = test_scores.tolist()\n",
    "    #     return learning_curve_data\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        feature_importance = {}\n",
    "        feature_importance['feature_names'] = self.X_train.columns.tolist()\n",
    "        feature_importance['feature_importance'] = permutation_importance(self.best_estimator, self.X_test, self.y_test, n_repeats=3, random_state=42)['importances_mean'].tolist()\n",
    "        return feature_importance\n",
    "    \n",
    "    def get_precision_recall_data(self):\n",
    "        precision_recall_data = {}\n",
    "        output_mapping = self.get_output_mapping()\n",
    "        # get key corresponding to value 1\n",
    "\n",
    "        pos_label = list(output_mapping.keys())[list(output_mapping.values()).index(1)]\n",
    "        precision_recall_data['precision'] = []\n",
    "        precision_recall_data['recall'] = []\n",
    "        precision_recall_data['thresholds'] = []\n",
    "        precision_recall_data['auc'] = []\n",
    "        if len(self.output_mapping) == 2:\n",
    "            precision, recall, thresholds = precision_recall_curve(self.y_test, self.best_estimator.predict_proba(self.X_test)[:, 1], pos_label=pos_label)\n",
    "            precision_recall_data['precision'].append(precision.tolist())\n",
    "            precision_recall_data['recall'].append(recall.tolist())\n",
    "            precision_recall_data['thresholds'].append(thresholds.tolist())\n",
    "            precision_recall_data['auc'].append(auc(recall, precision))\n",
    "            return precision_recall_data\n",
    "        else:\n",
    "            for i in range(len(self.output_mapping)):\n",
    "                precision, recall, thresholds = precision_recall_curve(self.y_test, self.best_estimator.predict_proba(self.X_test)[:, i], pos_label=i)\n",
    "                precision_recall_data['precision'].append(precision.tolist())\n",
    "                precision_recall_data['recall'].append(recall.tolist())\n",
    "                precision_recall_data['thresholds'].append(thresholds.tolist())\n",
    "                precision_recall_data['auc'].append(auc(recall, precision))\n",
    "            return precision_recall_data\n",
    "    \n",
    "    def get_auc_data(self):\n",
    "        output_mapping = self.get_output_mapping()\n",
    "        # get key corresponding to value 1\n",
    "\n",
    "        pos_label = list(output_mapping.keys())[list(output_mapping.values()).index(1)]\n",
    "\n",
    "        auc_data = {}\n",
    "        auc_data['fpr'] = []\n",
    "        auc_data['tpr'] = []\n",
    "        auc_data['thresholds'] = []\n",
    "        auc_data['auc'] = []\n",
    "        if len(output_mapping) == 2:\n",
    "            fpr, tpr, thresholds = roc_curve(self.y_test, self.best_estimator.predict_proba(self.X_test)[:, 1], pos_label=pos_label)\n",
    "            auc_data['fpr'].append(fpr.tolist())\n",
    "            auc_data['tpr'].append(tpr.tolist())\n",
    "            auc_data['thresholds'].append(thresholds.tolist())\n",
    "            auc_data['auc'].append(auc(fpr, tpr))\n",
    "            return auc_data\n",
    "        else:\n",
    "            for i in range(len(output_mapping)):\n",
    "                fpr, tpr, thresholds = roc_curve(self.y_test, self.best_estimator.predict_proba(self.X_test)[:, i], pos_label=i)\n",
    "                auc_data['fpr'].append(fpr.tolist())\n",
    "                auc_data['tpr'].append(tpr.tolist())\n",
    "                auc_data['thresholds'].append(thresholds.tolist())\n",
    "                auc_data['auc'].append(auc(fpr, tpr))\n",
    "            return auc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/68071.csv')\n",
    "target_column = 'income'\n",
    "clfutil = ClassificationUtility(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: KNeighborsClassifier Processing: 100%|██████████| 7/7 [02:48<00:00, 24.13s/it]  \n"
     ]
    }
   ],
   "source": [
    "clfutil.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifier    RandomForestClassifier\n",
       "Accuracy                      0.8701\n",
       "Precision                     0.8308\n",
       "Recall                        0.7909\n",
       "F1                            0.8079\n",
       "AUC                           0.9184\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfutil.getBestModel(ClassificationMetrics.Accuracy.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7030, 449], [820, 1470]]\n"
     ]
    }
   ],
   "source": [
    "print(clfutil.get_confusion_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<=50K': 0, '>50K': 1}\n"
     ]
    }
   ],
   "source": [
    "print(clfutil.get_output_mapping())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_names': ['age', 'workclass', 'fnlwgt', 'education', 'educational-num', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'], 'feature_importance': [0.0163783396458184, 0.005732418876036409, 0.002354386324086392, 0.0027979663561606602, 0.008223291363838, 0.02050704609820179, 0.018630361347118412, 0.014092196403589571, -3.700743415417188e-17, -0.0001706077046439436, 0.043539086225133916, 0.007677346708977388, 0.007882075954550075, 0.00013648616371516228]}\n"
     ]
    }
   ],
   "source": [
    "print(clfutil.get_feature_importance())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fpr': [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00013370771493515177, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00026741542987030354, 0.00040112314480545525, 0.00040112314480545525, 0.00040112314480545525, 0.00040112314480545525, 0.00040112314480545525, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0005348308597406071, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0006685385746757588, 0.0008022462896109105, 0.0008022462896109105, 0.0008022462896109105, 0.0008022462896109105, 0.0012033694344163659, 0.0012033694344163659, 0.0013370771493515176, 0.0013370771493515176, 0.0013370771493515176, 0.0013370771493515176, 0.001604492579221821, 0.001604492579221821, 0.001738200294156973, 0.001738200294156973, 0.001738200294156973, 0.001738200294156973, 0.0018719080090921247, 0.0018719080090921247, 0.0020056157240272766, 0.0020056157240272766, 0.0021393234389624283, 0.0021393234389624283, 0.0021393234389624283, 0.0021393234389624283, 0.0024067388688327317, 0.0024067388688327317, 0.0025404465837678834, 0.0025404465837678834, 0.002674154298703035, 0.0030752774435084903, 0.0030752774435084903, 0.004278646877924857, 0.004278646877924857, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.004412354592860008, 0.00681909346169274, 0.00681909346169274, 0.006952801176627892, 0.007220216606498195, 0.0073539243214333465, 0.0073539243214333465, 0.0073539243214333465, 0.0073539243214333465, 0.0073539243214333465, 0.0073539243214333465, 0.008156170611044258, 0.008557293755849713, 0.008557293755849713, 0.008557293755849713, 0.008691001470784864, 0.00909212461559032, 0.00909212461559032, 0.009225832330525471, 0.009225832330525471, 0.009225832330525471, 0.009359540045460623, 0.009626955475330927, 0.009626955475330927, 0.009760663190266078, 0.01069661719481214, 0.01069661719481214, 0.010830324909747292, 0.010830324909747292, 0.011365155769487899, 0.011365155769487899, 0.011498863484423052, 0.011498863484423052, 0.011632571199358203, 0.011766278914293354, 0.011766278914293354, 0.011899986629228506, 0.011899986629228506, 0.01216740205909881, 0.01216740205909881, 0.012568525203904266, 0.012568525203904266, 0.012702232918839417, 0.012702232918839417, 0.012835940633774568, 0.012835940633774568, 0.014173017783126086, 0.014173017783126086, 0.014306725498061237, 0.014707848642866693, 0.014707848642866693, 0.014841556357801846, 0.014841556357801846, 0.0152426795026073, 0.016178633507153362, 0.016178633507153362, 0.016178633507153362, 0.016312341222088515, 0.016312341222088515, 0.016579756651958818, 0.016579756651958818, 0.01671346436689397, 0.01684717208182912, 0.01684717208182912, 0.017916833801310334, 0.01831795694611579, 0.01831795694611579, 0.01831795694611579, 0.01831795694611579, 0.018585372375986096, 0.019253910950661854, 0.019387618665597003, 0.01978874181040246, 0.019922449525337612, 0.019922449525337612, 0.019922449525337612, 0.019922449525337612, 0.019922449525337612, 0.019922449525337612, 0.020323572670143068, 0.020323572670143068, 0.020323572670143068, 0.02112581895975398, 0.02112581895975398, 0.02125952667468913, 0.02139323438962428, 0.02139323438962428, 0.021526942104559434, 0.021526942104559434, 0.021660649819494584, 0.021660649819494584, 0.02192806524936489, 0.02192806524936489, 0.022596603824040648, 0.02353255782858671, 0.02353255782858671, 0.024468511833132773, 0.024468511833132773, 0.02486963497793823, 0.025404465837678834, 0.025404465837678834, 0.025538173552613987, 0.025538173552613987, 0.025671881267549136, 0.025671881267549136, 0.025671881267549136, 0.02580558898248429, 0.02580558898248429, 0.025939296697419442, 0.025939296697419442, 0.025939296697419442, 0.026875250701965503, 0.026875250701965503, 0.026875250701965503, 0.02754378927664126, 0.02754378927664126, 0.02754378927664126, 0.027677496991576414, 0.027677496991576414, 0.027811204706511567, 0.027811204706511567, 0.029148281855863083, 0.029415697285733386, 0.02954940500066854, 0.029683112715603692, 0.030084235860409144, 0.030619066720149753, 0.030752774435084906, 0.031020189864955208, 0.03115389757989036, 0.031421313009760664, 0.03155502072469581, 0.03155502072469581, 0.03168872843963097, 0.03168872843963097, 0.03195614386950127, 0.03195614386950127, 0.03195614386950127, 0.032089851584436425, 0.032089851584436425, 0.032357267014306725, 0.032357267014306725, 0.032357267014306725, 0.032357267014306725, 0.032490974729241874, 0.03262468244417703, 0.03262468244417703, 0.03289209787404733, 0.03289209787404733, 0.033025805588982486, 0.033025805588982486, 0.03356063644872309, 0.0338280518785934, 0.03449659045326915, 0.03463029816820431, 0.03569995988768552, 0.03583366760262067, 0.03583366760262067, 0.03583366760262067, 0.03730445246690734, 0.03757186789677765, 0.0377055756117128, 0.0382404064714534, 0.0382404064714534, 0.0382404064714534, 0.03890894504612916, 0.03917636047599946, 0.03917636047599946, 0.03944377590586977, 0.03944377590586977, 0.03957748362080492, 0.03957748362080492, 0.039711191335740074, 0.039711191335740074, 0.039844899050675224, 0.039844899050675224, 0.039978606765610374, 0.039978606765610374, 0.04011231448054553, 0.04037972991041583, 0.04037972991041583, 0.0418505147747025, 0.0421179302045728, 0.0421179302045728, 0.04251905334937826, 0.043455007353924324, 0.04398983821366493, 0.044257253643535235, 0.044257253643535235, 0.044390961358470385, 0.044390961358470385, 0.044524669073405534, 0.04492579221821099, 0.045326915363016446, 0.045326915363016446, 0.04559433079288675, 0.04599545393769221, 0.04666399251236796, 0.04679770022730312, 0.04746623880197887, 0.04773365423184918, 0.04773365423184918, 0.04853590052146009, 0.04866960823639524, 0.04866960823639524, 0.04880331595133039, 0.049070731381200695, 0.05241342425457949, 0.052680839684449796, 0.052948255114320095, 0.052948255114320095, 0.052948255114320095, 0.0532156705441904, 0.0532156705441904, 0.05334937825912555, 0.05348308597406071, 0.053750501403931006, 0.05415162454873646, 0.05428533226367161, 0.05428533226367161, 0.05441903997860677, 0.055756117127958284, 0.05588982484289343, 0.056558363417569195, 0.056692071132504344, 0.056825778847439494, 0.05695948656237465, 0.05695948656237465, 0.057360609707180106, 0.05802914828185586, 0.05802914828185586, 0.05829656371172617, 0.05829656371172617, 0.058430271426661316, 0.058430271426661316, 0.05869768685653162, 0.05923251771627223, 0.059366225431207384, 0.059366225431207384, 0.059499933146142533, 0.059499933146142533, 0.05976734857601283, 0.05976734857601283, 0.05990105629094799, 0.06003476400588314, 0.06190667201497527, 0.062040379729910416, 0.06230779515978072, 0.06377858002406739, 0.06377858002406739, 0.0645808263136783, 0.06524936488835406, 0.06524936488835406, 0.06551678031822436, 0.06578419574809466, 0.06618531889290012, 0.06645273432277042, 0.06645273432277042, 0.06685385746757588, 0.06685385746757588, 0.06712127289744618, 0.06912688862147345, 0.06926059633640862, 0.06926059633640862, 0.06952801176627892, 0.06979542719614922, 0.06992913491108436, 0.07073138120069528, 0.07139991977537104, 0.07166733520524134, 0.07166733520524134, 0.07220216606498195, 0.07246958149485225, 0.07273699692472256, 0.07287070463965771, 0.07313812006952801, 0.07313812006952801, 0.07327182778446316, 0.07394036635913892, 0.07394036635913892, 0.07407407407407407, 0.07407407407407407, 0.07460890493381468, 0.07474261264874983, 0.07487632036368498, 0.07487632036368498, 0.07501002807862013, 0.0751437357935553, 0.07527744350849044, 0.0754111512234256, 0.0754111512234256, 0.07567856665329589, 0.07581227436823104, 0.07661452065784195, 0.07701564380264742, 0.07701564380264742, 0.07728305923251771, 0.07808530552212863, 0.07808530552212863, 0.07808530552212863, 0.07835272095199892, 0.07875384409680439, 0.07888755181173954, 0.07902125952667469, 0.07968979810135045, 0.0798235058162856, 0.08102687525070197, 0.08116058296563712, 0.08316619868966439, 0.08356732183446985, 0.08356732183446985, 0.0839684449792753, 0.08450327583901591, 0.08463698355395106, 0.08490439898382136, 0.08543922984356198, 0.08557293755849713, 0.08570664527343227, 0.08584035298836742, 0.08610776841823774, 0.08691001470784865, 0.0870437224227838, 0.08744484556758925, 0.08771226099745956, 0.08784596871239471, 0.08784596871239471, 0.08797967642732986, 0.08811338414226501, 0.08838079957213531, 0.08864821500200562, 0.08918304586174622, 0.08931675357668137, 0.08958416900655168, 0.08971787672148683, 0.08985158443642198, 0.08985158443642198, 0.09011899986629228, 0.09038641529616259, 0.09038641529616259, 0.09052012301109774, 0.09052012301109774, 0.09065383072603289, 0.09065383072603289, 0.09078753844096804, 0.09372910816954139, 0.09399652359941169, 0.09399652359941169, 0.0945313544591523, 0.0945313544591523, 0.0947987698890226, 0.09546730846369836, 0.09560101617863351, 0.09707180104292018, 0.09720550875785533, 0.09720550875785533, 0.09733921647279048, 0.09774033961759594, 0.09800775504746624, 0.09800775504746624, 0.09854258590720684, 0.0989437090520123, 0.09907741676694745, 0.09907741676694745, 0.10028078620136383, 0.10054820163123412, 0.10054820163123412, 0.10081561706110442, 0.10094932477603957, 0.10094932477603957, 0.10135044792084504, 0.10135044792084504, 0.10148415563578018, 0.10148415563578018, 0.10161786335071533, 0.1022864019253911, 0.10242010964032625, 0.1025538173552614, 0.1033560636448723, 0.10375718678967777, 0.10375718678967777, 0.10389089450461292, 0.10455943307928868, 0.10469314079422383, 0.10469314079422383, 0.10482684850915898, 0.10482684850915898, 0.10496055622409413, 0.10522797165396443, 0.10562909479876989, 0.10589651022864019, 0.1061639256585105, 0.1064313410883808, 0.1066987565182511, 0.11097740339617596, 0.11151223425591657, 0.11191335740072202, 0.11191335740072202, 0.11231448054552748, 0.11271560369033293, 0.11271560369033293, 0.11325043455007354, 0.11338414226500869, 0.11378526540981415, 0.11405268083968445, 0.11605829656371172, 0.11645941970851718, 0.11645941970851718, 0.11659312742345233, 0.11686054285332263, 0.11686054285332263, 0.11699425056825778, 0.11699425056825778, 0.11712795828319295, 0.11739537371306324, 0.11739537371306324, 0.11926728172215537, 0.11953469715202567, 0.11980211258189598, 0.12060435887150689, 0.12087177430137719, 0.1216740205909881, 0.12180772830592325, 0.12207514373579356, 0.12220885145072871, 0.12247626688059901, 0.12301109774033962, 0.12314480545527477, 0.12327851317020992, 0.12327851317020992, 0.12341222088514507, 0.12381334402995053, 0.12448188260462628, 0.12448188260462628, 0.12515042117930206, 0.12541783660917236, 0.12541783660917236, 0.12568525203904266, 0.1258189597539778, 0.1258189597539778, 0.12622008289878325, 0.1263537906137184, 0.12648749832865355, 0.1266212060435887, 0.12742345233319963, 0.12769086776306993, 0.13130097606631902, 0.13143468378125417, 0.13170209921112447, 0.1319695146409948, 0.13210322235592994, 0.13210322235592994, 0.13237063778580024, 0.1325043455007354, 0.13263805321567054, 0.13263805321567054, 0.13357400722021662, 0.1353122075143736, 0.13544591522930874, 0.1358470383741142, 0.1361144538039845, 0.1361144538039845, 0.13624816151891964, 0.13651557694878994, 0.13664928466372508, 0.13731782323840086, 0.137451530953336, 0.13905602353255783, 0.13945714667736328, 0.13945714667736328, 0.13985826982216873, 0.13999197753710388, 0.13999197753710388, 0.14012568525203906, 0.14092793154164995, 0.14119534697152025, 0.14119534697152025, 0.1415964701163257, 0.14226500869100148, 0.14239871640593663, 0.14266613183580693, 0.14279983955074207, 0.14293354726567722, 0.14320096269554752, 0.14346837812541785, 0.1438695012702233, 0.1438695012702233, 0.14427062441502875, 0.14453803984489905, 0.14453803984489905, 0.14534028613450997, 0.14560770156438027, 0.14640994785399117, 0.14667736328386147, 0.14681107099879662, 0.1472121941436021, 0.14734590185853724, 0.14734590185853724, 0.1474796095734724, 0.1477470250033427, 0.1477470250033427, 0.148014440433213, 0.148014440433213, 0.14814814814814814, 0.14908410215269421, 0.14921780986762936, 0.1496189330124348, 0.1496189330124348, 0.1498863484423051, 0.1502874715871106, 0.1502874715871106, 0.1505548870169809, 0.1505548870169809, 0.1508223024468512, 0.15135713330659178, 0.15135713330659178, 0.15149084102152693, 0.15175825645139723, 0.1526942104559433, 0.1529616258858136, 0.15336274903061906, 0.15363016446048938, 0.15376387217542453, 0.15429870303516513, 0.15456611846503543, 0.15456611846503543, 0.15496724160984088, 0.15496724160984088, 0.1552346570397112, 0.15536836475464635, 0.1555020724695815, 0.15590319561438695, 0.15590319561438695, 0.15617061104425725, 0.1563043187591924, 0.1563043187591924, 0.1565717341890627, 0.15724027276373848, 0.15737398047867363, 0.15764139590854392, 0.15777510362347907, 0.15978071934750634, 0.15978071934750634, 0.1599144270624415, 0.1601818424923118, 0.1601818424923118, 0.16031555020724697, 0.16071667335205242, 0.16085038106698757, 0.16138521192672817, 0.16151891964166332, 0.16165262735659847, 0.16232116593127424, 0.16285599679101484, 0.16312341222088514, 0.16339082765075544, 0.1640593662254312, 0.1640593662254312, 0.1643267816553015, 0.1645941970851718, 0.1655301510897179, 0.1655301510897179, 0.16579756651958819, 0.16593127423452333, 0.16633239737932878, 0.16673352052413423, 0.16673352052413423, 0.16700093595400456, 0.16740205909881, 0.1676694745286803, 0.1679368899585506, 0.1684717208182912, 0.1684717208182912, 0.17141329054686455, 0.17288407541115122, 0.17341890627089182, 0.17368632170076215, 0.17395373713063245, 0.17422115256050275, 0.17422115256050275, 0.17502339885011364, 0.1751571065650488, 0.1751571065650488, 0.17555822970985427, 0.17609306056959487, 0.17622676828453002, 0.17649418371440032, 0.17676159914427061, 0.17676159914427061, 0.17689530685920576, 0.17729643000401124, 0.17729643000401124, 0.17756384543388154, 0.177964968578687, 0.177964968578687, 0.17809867629362214, 0.17836609172349244, 0.17836609172349244, 0.1787672148682979, 0.1795694611579088, 0.1798368765877791, 0.1798368765877791, 0.17997058430271426, 0.1801042920176494, 0.1801042920176494, 0.18037170744751974, 0.18063912287739003, 0.18090653830726033, 0.18197620002674153, 0.1821099077416767, 0.1821099077416767, 0.18251103088648216, 0.18384810803583368, 0.18424923118063913, 0.18505147747025003, 0.18505147747025003, 0.18518518518518517, 0.1854526006150555, 0.1857200160449258, 0.18585372375986095, 0.1859874314747961, 0.18612113918973125, 0.18638855461960155, 0.1865222623345367, 0.18665597004947185, 0.18665597004947185, 0.18745821633908277, 0.18759192405401792, 0.18785933948388822, 0.18785933948388822, 0.18812675491375852, 0.18826046262869367, 0.18826046262869367, 0.1887952934884343, 0.1887952934884343, 0.1890627089183046, 0.1890627089183046, 0.18919641663323974, 0.18973124749298034, 0.18999866292285064, 0.18999866292285064, 0.1901323706377858, 0.19053349378259127, 0.19106832464233187, 0.19106832464233187, 0.19133574007220217, 0.19187057093194276, 0.19253910950661854, 0.19280652493648884, 0.19387618665597006, 0.1942773098007755, 0.19441101751571066, 0.197352587244284, 0.19748629495921916, 0.1978874181040246, 0.1978874181040246, 0.1981548335338949, 0.1984222489637652, 0.19935820296831128, 0.20296831127156037, 0.20323572670143067, 0.20390426527610644, 0.20390426527610644, 0.2043053884209119, 0.20443909613584704, 0.20443909613584704, 0.2045728038507822, 0.2048402192806525, 0.2051076347105228, 0.20550875785532824, 0.20577617328519857, 0.20631100414493916, 0.2064447118598743, 0.20751437357935554, 0.20778178900922584, 0.20885145072870703, 0.2095199893033828, 0.2100548201631234, 0.21072335873779918, 0.21085706645273433, 0.21112448188260463, 0.21112448188260463, 0.21192672817221553, 0.212327851317021, 0.21246155903195615, 0.21272897446182645, 0.2128626821767616, 0.21326380532156705, 0.2133975130365022, 0.2136649284663725, 0.21433346704104828, 0.21486829790078887, 0.21513571333065917, 0.21513571333065917, 0.21553683647546462, 0.21580425190533495, 0.21607166733520525, 0.21607166733520525, 0.21714132905468644, 0.21874582163390827, 0.21914694477871374, 0.21968177563845434, 0.21994919106832464, 0.22021660649819494, 0.22075143735793556, 0.22302446851183313, 0.22302446851183313, 0.22329188394170343, 0.22489637652092526, 0.2252974996657307, 0.2252974996657307, 0.22583233052547133, 0.22676828453001738, 0.22690199224495253, 0.22770423853456345, 0.2283727771092392, 0.22904131568391498, 0.22957614654365557, 0.22997726968846102, 0.23024468511833132, 0.23064580826313677, 0.2309132236930071, 0.23104693140794225, 0.23104693140794225, 0.2311806391228774, 0.2345233319962562, 0.23545928600080224, 0.2355929937157374, 0.236127824575478, 0.23626153229041316, 0.23679636315015376, 0.23679636315015376, 0.2369300708650889, 0.2371974862949592, 0.23733119400989436, 0.23759860943976469, 0.23853456344431073, 0.2392031020189865, 0.23933680973392166, 0.23960422516379196, 0.240540179168338, 0.24094130231314348, 0.24134242545794893, 0.24160984088781923, 0.24187725631768953, 0.24201096403262468, 0.24201096403262468, 0.24241208717743012, 0.24267950260730045, 0.2428132103222356, 0.2433480411819762, 0.24348174889691135, 0.2436154566118465, 0.2436154566118465, 0.24415028747158712, 0.24508624147613317, 0.24535365690600347, 0.24749298034496592, 0.24829522663457682, 0.24896376520925256, 0.2492311806391229, 0.2494985960689932, 0.2500334269287338, 0.2505682577884744, 0.251103088648215, 0.25150421179302046, 0.25177162722289076, 0.25177162722289076, 0.25203904265276106, 0.2527075812274368, 0.25284128894237196, 0.25377724294691806, 0.25377724294691806, 0.2539109506618532, 0.255515443241075, 0.25618398181575075, 0.2565851049605562, 0.257253643535232, 0.257253643535232, 0.2577884743949726, 0.25792218210990775, 0.2580558898248429, 0.25845701296964835, 0.2585907206845835, 0.25925925925925924, 0.26019521326380535, 0.26019521326380535, 0.26046262869367565, 0.2611311672683514, 0.261665998128092, 0.2624682444177029, 0.2627356598475732, 0.2627356598475732, 0.2630030752774435, 0.2636716138521193, 0.26407273699692474, 0.2647412755716005, 0.2650086910014708, 0.26514239871640594, 0.266078352720952, 0.26621206043588713, 0.2663457681508223, 0.2666131835806926, 0.26674689129562773, 0.267816553015109, 0.26795026073004413, 0.2691536301644605, 0.2694210455943308, 0.2700895841690065, 0.27022329188394173, 0.27049070731381203, 0.2706244150287472, 0.2708918304586175, 0.2712929536034229, 0.2718277844631635, 0.2720951998930338, 0.27249632303783927, 0.27249632303783927, 0.27276373846770957, 0.2734322770423853, 0.273967107902126, 0.27476935419173687, 0.27530418505147747, 0.2757053081962829, 0.2757053081962829, 0.2759727236261532, 0.2782457547800508, 0.2785131702099211, 0.2787805856397914, 0.279315416499532, 0.2795828319294023, 0.2798502473592726, 0.2805187859339484, 0.28118732450862416, 0.28198957079823506, 0.28225698622810536, 0.2829255248027811, 0.28332664794758655, 0.2835940633774569, 0.2838614788073272, 0.2841288942371975, 0.2841288942371975, 0.2843963096670678, 0.28506484824174355, 0.2851985559566787, 0.2860008022462896, 0.2862682176761599, 0.2862682176761599, 0.2865356331060302, 0.2868030485359005, 0.287204171680706, 0.28733787939564115, 0.2877390025404466, 0.2880064179703169, 0.2888086642599278, 0.28920978740473324, 0.28920978740473324, 0.2896109105495387, 0.29001203369434414, 0.2905468645540848, 0.29068057226901994, 0.29068057226901994, 0.29094798769889024, 0.29121540312876054, 0.2913491108436957, 0.2921513571333066, 0.29228506484824174, 0.2924187725631769, 0.29308731113785264, 0.29335472656772293, 0.29362214199759323, 0.29375584971252844, 0.2941569728573339, 0.2946918037170745, 0.2949592191469448, 0.2949592191469448, 0.2952266345768151, 0.2954940500066854, 0.2954940500066854, 0.2957614654365557, 0.2957614654365557, 0.29589517315149083, 0.2962962962962963, 0.29643000401123143, 0.2965637117261666, 0.296964834870972, 0.29816820430538843, 0.2995052814547399, 0.3000401123144805, 0.3003075277443508, 0.3011097740339618, 0.3013771894638321, 0.3016446048937024, 0.30244685118331327, 0.3025805588982484, 0.3028479743281187, 0.30298168204305387, 0.3033828051878593, 0.3037839283326648, 0.3043187591924054, 0.3045861746222757, 0.304853590052146, 0.3061906672014975, 0.3064580826313678, 0.30685920577617326, 0.3069929134911084, 0.3073940366359139, 0.30752774435084906, 0.3079288674956545, 0.3079288674956545, 0.30832999064045996, 0.30886482150020056, 0.30886482150020056, 0.3089985292151357, 0.309265944645006, 0.30939965235994116, 0.3100681909346169, 0.31060302179435756, 0.31220751437357935, 0.31247492980344965, 0.31247492980344965, 0.31300976066319025, 0.31327717609306055, 0.3134108838079957, 0.313678299237866, 0.3138120069528012, 0.3143468378125418, 0.31448054552747695, 0.31474796095734725, 0.3148816686722824, 0.3159513303917636, 0.3162187458216339, 0.3162187458216339, 0.31755582297098545, 0.31835806926059634, 0.3187591924054018, 0.3187591924054018, 0.3192940232651424, 0.31942773098007754, 0.32022997726968844, 0.32063110041449394, 0.32063110041449394, 0.32170076213397514, 0.3226367161385212, 0.3229041315683915, 0.3231715469982618, 0.3234389624281321, 0.3241075010028079, 0.3243749164326782, 0.3249097472924188, 0.3249097472924188, 0.3254445781521594, 0.3257119935820297, 0.3259794090119, 0.32611311672683513, 0.32611311672683513, 0.3262468244417703, 0.3265142398716406, 0.3266479475865757, 0.3274501938761867, 0.32785131702099213, 0.32785131702099213, 0.3279850247359273, 0.3282524401657976, 0.3285198555956679, 0.3287872710255382, 0.3290546864554085, 0.3293221018852788, 0.3297232250300842, 0.3299906404599545, 0.33012434817488967, 0.33012434817488967, 0.33039176360475997, 0.3307928867495655, 0.33132771760930607, 0.3322636716138521, 0.333065917903463, 0.3333333333333333, 0.33346704104826846, 0.3340018719080091, 0.3342692873378794, 0.33520524134242546, 0.33520524134242546, 0.33574007220216606, 0.33600748763203636, 0.3361411953469715, 0.3366760262067121, 0.3369434416365824, 0.3372108570664527, 0.33801310335606366, 0.33854793421580426, 0.33854793421580426, 0.3386816419307394, 0.3386816419307394, 0.33881534964567456, 0.33908276507554486, 0.33921647279048, 0.33921647279048, 0.3394838882203503, 0.33961759593528545, 0.34296028880866425, 0.34322770423853455, 0.34349511966840485, 0.3442973659580158, 0.3473726434015243, 0.34750635111645944, 0.34830859740607034, 0.34857601283594064, 0.34884342826581094, 0.3489771359807461, 0.34911084369568124, 0.34937825912555154, 0.35018050541516244, 0.35018050541516244, 0.3503142131300976, 0.3505816285599679, 0.3509827517047734, 0.3512501671346437, 0.35138387484957884, 0.3517849979943843, 0.35218612113918973, 0.35298836742880063, 0.35325578285867093, 0.35352319828854123, 0.3539243214333467, 0.3545928600080225, 0.3553951062976334, 0.35552881401256853, 0.355929937157374, 0.3560636448723091, 0.3565984757320497, 0.3571333065917903, 0.3574007220216607, 0.3579355528814013, 0.3582029683112716, 0.3584703837411419, 0.358604091456077, 0.358604091456077, 0.35900521460088247, 0.35927263003075277, 0.35927263003075277, 0.3599411686054285, 0.36007487632036367, 0.36007487632036367, 0.3602085840352988, 0.3604759994651691, 0.36060970718010427, 0.36060970718010427, 0.3608771226099746, 0.36127824575478007, 0.3616793688995855, 0.36261532290413157, 0.36341756919374246, 0.36395240005348306, 0.3644872309132237, 0.36515576948789946, 0.36542318491776976, 0.36569060034764006, 0.3660917234924455, 0.3663591389223158, 0.3663591389223158, 0.3666265543521861, 0.3668939697820564, 0.3671613852119267, 0.36729509292686185, 0.36769621607166736, 0.3678299237866025, 0.3686321700762134, 0.3694344163658243, 0.3697018317956946, 0.3699692472255649, 0.3702366626554352, 0.3707714935151758, 0.37103890894504615, 0.3711726166599813, 0.3717074475197219, 0.37210857066452735, 0.37291081695413825, 0.3742478941034898, 0.3745153095333601, 0.37464901724829525, 0.37491643267816555, 0.37625350982751704, 0.3766546329723225, 0.3766546329723225, 0.37732317154699824, 0.3781254178366092, 0.37852654098141464, 0.3786602486963498, 0.37879395641128494, 0.37879395641128494, 0.3789276641262201, 0.3789276641262201, 0.37959620270089584, 0.3799973258457013, 0.3807995721353122, 0.3809332798502474, 0.3812006952801177, 0.3820029415697286, 0.38267148014440433, 0.38293889557427463, 0.3836074341489504, 0.3838748495788207, 0.3838748495788207, 0.3850782190132371, 0.3860141730177831, 0.3865490038775237, 0.386816419307394, 0.38695012702232917, 0.38695012702232917, 0.3870838347372643, 0.3873512501671346, 0.3882872041716807, 0.3888220350314213, 0.3890894504612916, 0.38949057360609707, 0.3896242813210322, 0.39002540446583767, 0.3901591121807728, 0.39029281989570797, 0.39096135847038377, 0.39096135847038377, 0.3910950661853189, 0.3916298970450595, 0.39229843561973526, 0.39256585104960556, 0.39430405134376256, 0.394705174488568, 0.3952400053483086, 0.39564112849311406, 0.39564112849311406, 0.39590854392298436, 0.39644337478272496, 0.3968444979275304, 0.397379328787271, 0.3977804519320765, 0.39791415964701166, 0.39818157507688196, 0.39844899050675225, 0.39898382136649285, 0.399117529081428, 0.3993849445112983, 0.39951865222623345, 0.4004546062307795, 0.40058831394571465, 0.40205909881000135, 0.4021928065249365, 0.4029950528145474, 0.4029950528145474, 0.40366359138922314, 0.40366359138922314, 0.40393100681909344, 0.40419842224896374, 0.40459954539376924, 0.4050006685385747, 0.40540179168338014, 0.4060703302580559, 0.40647145340286134, 0.40700628426260194, 0.4076748228372777, 0.40794223826714804, 0.40820965369701834, 0.40954673084636983, 0.4099478539911753, 0.4119534697152026, 0.41208717743013773, 0.4127557160048135, 0.4128894237197486, 0.4128894237197486, 0.4130231314346838, 0.4132905468645541, 0.414092793154165, 0.41436020858403527, 0.4144939162989705, 0.4147613317288408, 0.4154298703035165, 0.415830993448322, 0.41609840887819227, 0.4170343628827383, 0.41716807059767347, 0.4175691937424789, 0.41783660917234927, 0.41970851718144137, 0.41997593261131166, 0.42051076347105226, 0.42104559433079286, 0.4213130097606632, 0.42144671747559836, 0.4223826714801444, 0.4231849177697553, 0.42331862548469046, 0.4239871640593662, 0.4242545794892365, 0.424655702634042, 0.4259927797833935, 0.4262601952132638, 0.4267950260730044, 0.42719614921780985, 0.42773098007755045, 0.4279983955074208, 0.42813210322235595, 0.42839951865222625, 0.4288006417970317, 0.42946918037170745, 0.42973659580157775, 0.43027142666131835, 0.43080625752105894, 0.4312073806658644, 0.4321433346704105, 0.4324107501002808, 0.4329455809600214, 0.433480411819762, 0.43388153496456744, 0.43388153496456744, 0.43414895039443774, 0.43508490439898384, 0.4354860275437893, 0.4362882738334002, 0.43642198154833534, 0.4373579355528814, 0.43775905869768683, 0.4382938895574275, 0.4385613049872978, 0.43976467442171413, 0.44029950528145473, 0.440566920711325, 0.4409680438561305, 0.4411017515710656, 0.441369167000936, 0.44203770557561173, 0.4421714132905469, 0.4425725364353523, 0.4428399518652226, 0.4429736595801578, 0.4435084904398984, 0.44431073672950927, 0.44457815215937957, 0.4447118598743148, 0.4451129830191202, 0.4453803984489905, 0.4456478138788608, 0.4461826447386014, 0.44631635245353657, 0.4464500601684717, 0.44765342960288806, 0.44792084503275836, 0.44805455274769357, 0.44939162989704506, 0.44965904532691536, 0.4500601684717208, 0.4500601684717208, 0.4508624147613317, 0.45099612247626686, 0.45126353790613716, 0.45166466105094266, 0.45193207648081296, 0.4523331996256184, 0.4526006150554887, 0.45326915363016446, 0.45433881534964565, 0.45460623077951595, 0.4554084770691269, 0.4564781387886081, 0.4567455542184784, 0.45714667736328385, 0.45741409279315415, 0.45768150822302445, 0.45768150822302445, 0.45861746222757055, 0.45888487765744085, 0.45941970851718145, 0.45968712394705175, 0.4600882470918572, 0.4628961091054954, 0.46329723225030084, 0.46383206311004144, 0.4639657708249766, 0.4642331862548469, 0.46530284797432814, 0.46663992512367963, 0.46663992512367963, 0.4667736328386148, 0.4667736328386148, 0.46717475598342023, 0.46717475598342023, 0.4673084636983554, 0.46918037170744753, 0.46971520256718813, 0.4698489102821233, 0.4701163257119936, 0.4706511565717342, 0.4711859874314748, 0.47145340286134507, 0.4721219414360209, 0.4723893568658912, 0.4727904800106966, 0.4730578954405669, 0.47319160315550207, 0.47372643401524267, 0.4741275571600481, 0.4743949725899184, 0.47546463430939967, 0.4758657574542051, 0.47626688059901057, 0.476668003743816, 0.4772028346035566, 0.47733654231849176, 0.4777376654632972, 0.4780050808931675, 0.47853991175290816, 0.4786736194678433, 0.48215002005615726, 0.48241743548602756, 0.4825511432009627, 0.482818558630833, 0.48295226634576816, 0.4844230512100548, 0.4846904666399251, 0.4850915897847306, 0.4856264206444712, 0.4861612515042118, 0.4864286669340821, 0.4864286669340821, 0.48656237464901725, 0.48789945179836874, 0.48856799037304455, 0.48910282123278515, 0.48990506752239604, 0.49017248295226634, 0.49043989838213664, 0.4905736060970718, 0.49097472924187724, 0.49124214467174754, 0.4917769755314882, 0.49217809867629364, 0.49217809867629364, 0.49298034496590454, 0.49338146811071, 0.49378259125551544, 0.4941837144003209, 0.4944511298301912, 0.495119668404867, 0.49552079154967243, 0.4959219146944779, 0.49605562240941303, 0.49632303783928333, 0.4964567455542185, 0.4980612381334403, 0.4981949458483754, 0.4981949458483754, 0.4989971921379864, 0.4989971921379864, 0.4992646075678567, 0.4996657307126621, 0.5014039310068191, 0.5020724695814949, 0.5023398850113652, 0.5024735927263003, 0.5024735927263003, 0.5027410081561706, 0.5032758390159112, 0.5034095467308464, 0.5036769621607167, 0.5038106698756518, 0.5040780853055221, 0.504880331595133, 0.5055488701698088, 0.5056825778847439, 0.5059499933146142, 0.5060837010295494, 0.5063511164594197, 0.50661853188929, 0.5071533627490307, 0.507420778178901, 0.5084904398983822, 0.5087578553282525, 0.5090252707581228, 0.5095601016178634, 0.5098275170477337, 0.5115657173418906, 0.5121005482016312, 0.5123679636315015, 0.5123679636315015, 0.5138387484957883, 0.514507287070464, 0.5150421179302046, 0.5167803182243615, 0.5170477336542318, 0.5173151490841021, 0.5174488567990373, 0.5182511030886482, 0.5182511030886482, 0.5183848108035833, 0.5187859339483888, 0.5190533493782591, 0.5193207648081294, 0.5195881802379997, 0.5201230110977403, 0.5203904265276107, 0.5203904265276107, 0.520657841957481, 0.5207915496724161, 0.5213263805321567, 0.5219949191068325, 0.5227971653964434, 0.5229308731113785, 0.5231982885412488, 0.52426795026073, 0.52426795026073, 0.5245353656906003, 0.5249364888354058, 0.5253376119802112, 0.5256050274100815, 0.526006150554887, 0.5264072736996924, 0.5266746891295627, 0.5272095199893034, 0.5276106431341089, 0.5276106431341089, 0.527744350849044, 0.5280117662789143, 0.5282791817087846, 0.5306859205776173, 0.5306859205776173, 0.5308196282925525, 0.5308196282925525, 0.5309533360074876, 0.532156705441904, 0.5324241208717743, 0.5328252440165797, 0.5333600748763203, 0.5337611980211259, 0.5341623211659313, 0.5345634443107368, 0.5359005214600883, 0.5372375986094398, 0.5375050140393101, 0.5376387217542452, 0.5380398448990507, 0.538307260328921, 0.5387083834737264, 0.5388420911886616, 0.5391095066185319, 0.5396443374782725, 0.5399117529081428, 0.540179168338013, 0.5407139991977538, 0.5416499532022998, 0.5419173686321701, 0.5423184917769756, 0.5425859072068459, 0.5437892766412622, 0.5441903997860676, 0.544457815215938, 0.5449926460756785, 0.5455274769354191, 0.5457948923652894, 0.5459286000802246, 0.547131969514641, 0.5473993849445113, 0.5480679235191871, 0.5482016312341222, 0.5484690466639925, 0.548870169808798, 0.5491375852386683, 0.5494050006685386, 0.5500735392432143, 0.5503409546730846, 0.5504746623880198, 0.5507420778178901, 0.5516780318224361, 0.5520791549672416, 0.5523465703971119, 0.5526139858269822, 0.5532825244016579, 0.5543521861211392, 0.5560903864152962, 0.5564915095601016, 0.5567589249899719, 0.5572937558497125, 0.557694878994518, 0.558630832999064, 0.5598342024334804, 0.5601016178633507, 0.5602353255782858, 0.5609038641529617, 0.5613049872977671, 0.5615724027276374, 0.5631768953068592, 0.5635780184516647, 0.563845433881535, 0.5642465570263404, 0.5643802647412756, 0.5649150956010162, 0.5654499264607568, 0.5657173418906271, 0.5659847573204974, 0.566519588180238, 0.5667870036101083, 0.567321834469849, 0.5674555421847841, 0.5687926193341356, 0.5693274501938762, 0.5698622810536168, 0.5701296964834871, 0.5703971119133574, 0.5713330659179034, 0.571867896777644, 0.5720016044925792, 0.5724027276373846, 0.5734723893568658, 0.5738735125016714, 0.574408343361412, 0.5745420510763471, 0.575344297365958, 0.5756117127958283, 0.5758791282256986, 0.5762802513705041, 0.5764139590854392, 0.5766813745153095, 0.5768150822302447, 0.577082497660115, 0.5773499130899853, 0.578018451664661, 0.5782858670945313, 0.5790881133841422, 0.5793555288140125, 0.5798903596737531, 0.5813611445380399, 0.5817622676828453, 0.5822970985425859, 0.5824308062575211, 0.5830993448321968, 0.5836341756919374, 0.5840352988367429, 0.584169006551678, 0.5844364219815483, 0.5845701296964835, 0.585907206845835, 0.5860409145607701, 0.5860409145607701, 0.5871105762802513, 0.5872442839951865, 0.5879128225698623, 0.5885813611445381, 0.5888487765744084, 0.5892498997192138, 0.5895173151490841, 0.5899184382938896, 0.5905869768685653, 0.5916566385880465, 0.5921914694477871, 0.592993715737398, 0.5931274234523332, 0.5936622543120738, 0.5937959620270089, 0.5941970851718145, 0.5944645006016848, 0.5948656237464902, 0.5952667468912957, 0.595534162321166, 0.5958015777510363, 0.596470116325712, 0.597406070330258, 0.5976734857601284, 0.5979409011899987, 0.5980746089049338, 0.5984757320497393, 0.5986094397646744, 0.5990105629094798, 0.5999465169140259, 0.601684717208183, 0.6019521326380532, 0.6020858403529884, 0.6023532557828587, 0.6028880866425993, 0.6030217943575344, 0.603556625217275, 0.6040914560770156, 0.6042251637919508, 0.6046262869367562, 0.6047599946516914, 0.6055622409413023, 0.6058296563711726, 0.6060970718010429, 0.6064981949458483, 0.6066319026607835, 0.6066319026607835, 0.6073004412354592, 0.6075678566653296, 0.6081026875250702, 0.6090386415296163, 0.6093060569594866, 0.6098408878192272, 0.6101083032490975, 0.6107768418237732, 0.6109105495387084, 0.6111779649685787, 0.6121139189731247, 0.612381334402995, 0.6131835806926059, 0.6133172884075411, 0.6135847038374114, 0.6142532424120872, 0.6151891964166333, 0.6155903195614387, 0.6171948121406605, 0.6183981815750769, 0.618531889290012, 0.6187993047198823, 0.6192004278646878, 0.6197352587244284, 0.6201363818692338, 0.6204037972991041, 0.6208049204439096, 0.6217408744484557, 0.6218745821633909, 0.6221419975932612, 0.6226768284530018, 0.6229442438828721, 0.6234790747426127, 0.6244150287471587, 0.6244150287471587, 0.624682444177029, 0.6250835673218345, 0.6253509827517048, 0.6257521058965102, 0.6258858136114454, 0.6261532290413157, 0.626420644471186, 0.6272228907607968, 0.6278914293354727, 0.628158844765343, 0.6284262601952133, 0.6286936756250836, 0.6298970450595, 0.6304318759192405, 0.6305655836341757, 0.6309667067789811, 0.631768953068592, 0.6321700762133975, 0.6324374916432678, 0.6331060302179435, 0.6333734456478138, 0.6336408610776841, 0.6339082765075544, 0.63430939965236, 0.6367161385211927, 0.636983553951063, 0.636983553951063, 0.6372509693809333, 0.6373846770958684, 0.6376520925257387, 0.6380532156705442, 0.6384543388153496, 0.6387217542452199, 0.6389891696750902, 0.6393902928198957, 0.639657708249766, 0.6397914159647011, 0.6403262468244417, 0.6420644471185988, 0.6425992779783394, 0.6428666934082097, 0.6435352319828854, 0.6436689396978206, 0.6442037705575612, 0.6447386014173018, 0.6450060168471721, 0.6454071399919775, 0.6456745554218478, 0.645808263136783, 0.6460756785666533, 0.6466105094263939, 0.6468779248562642, 0.6478138788608103, 0.6483487097205509, 0.6484824174354861, 0.6498194945848376, 0.6499532022997727, 0.6503543254445782, 0.6506217408744485, 0.6515576948789945, 0.6520925257387351, 0.6523599411686054, 0.652894772028346, 0.6536970183179569, 0.653830726032892, 0.6544992646075679, 0.6544992646075679, 0.6547666800374382, 0.655435218612114, 0.6555689263270491, 0.6558363417569194, 0.6562374649017249, 0.6565048803315952, 0.6567722957614655, 0.6569060034764006, 0.6571734189062709, 0.657307126621206, 0.6575745420510763, 0.6579756651958818, 0.658109372910817, 0.6583767883406872, 0.6585104960556224, 0.6587779114854927, 0.6591790346302981, 0.6594464500601684, 0.6597138654900387, 0.6601149886348442, 0.6602486963497793, 0.6614520657841958, 0.6617194812140661, 0.6622543120738067, 0.662521727503677, 0.6629228506484824, 0.6631902660783527, 0.6645273432277042, 0.6650621740874448, 0.666131835806926, 0.6665329589517315, 0.6666666666666666, 0.6669340820965369, 0.6676026206712127, 0.6678700361010831, 0.6678700361010831, 0.668672282390694, 0.66960823639524, 0.6700093595400455, 0.6708116058296564, 0.6709453135445915, 0.671346436689397, 0.6714801444043321, 0.6717475598342024, 0.6720149752640727, 0.6724160984088782, 0.6728172215536836, 0.6732183446984891, 0.6741542987030351, 0.6749565449926461, 0.6750902527075813, 0.675758791282257, 0.6762936221419976, 0.6768284530017382, 0.6769621607166734, 0.6772295761465437, 0.6773632838614788, 0.6777644070062843, 0.6782992378660249, 0.67843294558096, 0.6788340687257655, 0.6791014841556358, 0.6793688995855061, 0.6803048535900521, 0.6804385613049873, 0.6804385613049873, 0.6808396844497927, 0.6824441770290146, 0.6829790078887552, 0.6835138387484958, 0.6837812541783661, 0.6839149618933013, 0.6844497927530419, 0.6851183313277176, 0.6853857467575879, 0.6856531621874582, 0.6859205776173285, 0.6865891161920042, 0.6867228239069394, 0.6869902393368097, 0.6871239470517448, 0.6873913624816151, 0.6877924856264206, 0.688059901056291, 0.6891295627757722, 0.6910014707848643, 0.6911351784997994, 0.6915363016446049, 0.69167000935954, 0.6919374247894103, 0.6927396710790212, 0.6935419173686321, 0.6939430405134376, 0.6948789945179837, 0.6950127022329189, 0.6952801176627892, 0.6959486562374649, 0.6962160716673352, 0.6967509025270758, 0.6970183179569461, 0.6974194411017516, 0.6984891028212328, 0.6987565182511031, 0.6988902259660382, 0.6991576413959085, 0.6994250568257788, 0.6996924722556491, 0.6998261799705843, 0.7002273031153897, 0.7006284262601952, 0.7010295494050006, 0.7012969648348709, 0.7019655034095468, 0.7029014574140928, 0.7031688728439631, 0.7043722422783795, 0.7046396577082498, 0.7049070731381201, 0.7051744885679904, 0.7053081962829255, 0.705709319427731, 0.706645273432277, 0.7067789811472122, 0.7074475197218879, 0.7077149351517582, 0.7079823505816285, 0.7085171814413692, 0.7086508891563044, 0.7093194277309801, 0.7094531354459153, 0.7099879663056559, 0.710121674020591, 0.7105227971653965, 0.7107902125952668, 0.7115924588848777, 0.711859874314748, 0.7125284128894237, 0.7129295360342291, 0.7131969514640994, 0.71373178232384, 0.7139991977537103, 0.7144003208985158, 0.7152025671881268, 0.7157373980478674, 0.7164059366225431, 0.7166733520524134, 0.7170744751972189, 0.7174755983420243, 0.7176093060569595, 0.7178767214868298, 0.7185452600615055, 0.7190800909212461, 0.7192137986361813, 0.719882337210857, 0.7201497526407273, 0.7202834603556625, 0.7206845835004679, 0.7212194143602085, 0.7217542452199492, 0.7218879529348844, 0.7230913223693007, 0.7232250300842359, 0.7240272763738468, 0.7242946918037171, 0.7245621072335874, 0.7253643535231983, 0.7256317689530686, 0.7267014306725498, 0.727771092392031, 0.7280385078219013, 0.7284396309667068, 0.7287070463965771, 0.7297767081160583, 0.7308463698355395, 0.731247492980345, 0.7315149084102153, 0.7317823238400856, 0.7320497392699559, 0.7323171546998262, 0.7331194009894371, 0.7336542318491777, 0.7344564781387886, 0.7352587244283996, 0.7357935552881402, 0.7361946784329456, 0.7371306324374917, 0.7372643401524268, 0.7379328787271026, 0.7380665864420377, 0.738334001871908, 0.7384677095868432, 0.7387351250167135, 0.7391362481615189, 0.7394036635913892, 0.7404733253108704, 0.741008156170611, 0.7414092793154164, 0.741810402460222, 0.7434148950394438, 0.7438160181842493, 0.7443508490439898, 0.744484556758925, 0.7451530953336007, 0.745420510763471, 0.7456879261933413, 0.7460890493381468, 0.7463564647680171, 0.7468912956277577, 0.747158711057628, 0.7472924187725631, 0.7478272496323037, 0.7479609573472389, 0.7483620804920444, 0.7490306190667202, 0.7495654499264608, 0.7499665730712662, 0.7502339885011365, 0.7505014039310068, 0.750635111645942, 0.7509025270758123, 0.7514373579355529, 0.7525070196550341, 0.7530418505147747, 0.7535766813745153, 0.7541115122342559, 0.7543789276641262, 0.7546463430939965, 0.7551811739537372, 0.7557160048134778, 0.7558497125284129, 0.7562508356732184, 0.7566519588180238, 0.7569193742478941, 0.7574542051076347, 0.7579890359673753, 0.7590586976868565, 0.7597272362615323, 0.7599946516914026, 0.7601283594063377, 0.760395774836208, 0.7610643134108838, 0.7613317288407541, 0.7617328519855595, 0.7621339751303651, 0.7625350982751705, 0.7632036368498463, 0.7636047599946517, 0.7640058831394572, 0.7658777911485493, 0.7662789142933547, 0.766546329723225, 0.7672148682979008, 0.767482283727771, 0.7677496991576414, 0.7680171145875117, 0.768284530017382, 0.7685519454472524, 0.7693541917368633, 0.7697553148816687, 0.770022730311539, 0.7701564380264742, 0.7706912688862148, 0.7712260997459554, 0.772696884610242, 0.7729643000401123, 0.7730980077550474, 0.7733654231849177, 0.7740339617595935, 0.7745687926193341, 0.776173285198556, 0.7769755314881669, 0.777109239203102, 0.7776440700628426, 0.7777777777777778, 0.7784463163524535, 0.7787137317823238, 0.7789811472121941, 0.7791148549271293, 0.7795159780719347, 0.779783393501805, 0.7799171012167402, 0.7801845166466105, 0.7804519320764808, 0.7809867629362214, 0.7811204706511565, 0.7813878860810268, 0.7819227169407675, 0.7821901323706378, 0.7824575478005081, 0.7827249632303784, 0.7829923786602487, 0.7835272095199893, 0.7843294558096002, 0.7848642866693408, 0.7851317020992111, 0.785933948388822, 0.7862013638186923, 0.7867361946784329, 0.7870036101083032, 0.7872710255381735, 0.787672148682979, 0.7888755181173954, 0.7895440566920712, 0.7898114721219415, 0.7903463029816821, 0.7928867495654499, 0.7934215804251905, 0.7939564112849311, 0.7942238267148014, 0.7946249498596069, 0.794758657574542, 0.7950260730044123, 0.7952934884342826, 0.795560903864153, 0.7959620270089585, 0.7959620270089585, 0.7962294424388288, 0.7963631501537639, 0.7979676427329857, 0.7981013504479209, 0.7985024735927263, 0.7987698890225966, 0.7990373044524669, 0.8001069661719481, 0.8002406738868832, 0.8005080893167535, 0.8010429201764941, 0.8011766278914293, 0.8014440433212996, 0.8017114587511699, 0.8019788741810402, 0.8021125818959755, 0.8029148281855863, 0.8030485359005215, 0.803449659045327, 0.8037170744751972, 0.8038507821901324, 0.8051878593394839, 0.8057226901992245, 0.8061238133440299, 0.8063912287739002, 0.807059767348576, 0.8073271827784463, 0.8075945982083166, 0.8077283059232517, 0.807995721353122, 0.8086642599277978, 0.8089316753576682, 0.8097339216472791, 0.8109372910816954, 0.8110709987966306, 0.811472121941436, 0.8120069528011766, 0.8124080759459821, 0.8125417836609172, 0.8128091990907875, 0.8137451530953336, 0.8140125685252039, 0.8149485225297499, 0.8154833533894906, 0.8160181842492312, 0.8165530151089718, 0.816686722823907, 0.8169541382537773, 0.8170878459687124, 0.8181575076881936, 0.8185586308329991, 0.8190934616927397, 0.8196282925524803, 0.8198957079823506, 0.8205642465570263, 0.8210990774167669, 0.8212327851317021, 0.8221687391362482, 0.8225698622810537, 0.8227035699959888, 0.82377323171547, 0.8240406471453403, 0.8241743548602755, 0.8247091857200161, 0.8251103088648215, 0.8256451397245621, 0.8263136782992379, 0.8272496323037839, 0.8276507554485893, 0.8279181708784596, 0.8280518785933948, 0.8283192940232651, 0.8285867094531354, 0.8293889557427464, 0.8301912020323573, 0.8305923251771627, 0.8312608637518385, 0.8317956946115791, 0.8323305254713197, 0.83259794090119, 0.8331327717609306, 0.8350046797700227, 0.8354058029148281, 0.8356732183446985, 0.8366091723492446, 0.8372777109239203, 0.8380799572135312, 0.8382136649284664, 0.8392833266479476, 0.8395507420778179, 0.839684449792753, 0.8399518652226233, 0.8403529883674288, 0.8410215269421045, 0.8420911886615857, 0.8426260195213264, 0.8427597272362616, 0.8432945580960022, 0.8436956812408076, 0.8440968043856131, 0.8442305121005482, 0.8444979275304185, 0.844899050675224, 0.84583500467977, 0.8459687123947052, 0.8463698355395106, 0.8467709586843161, 0.8470383741141864, 0.847573204973927, 0.8477069126888621, 0.8482417435486027, 0.8486428666934082, 0.8491776975531489, 0.8498462361278246, 0.8501136515576949, 0.8503810669875652, 0.8505147747025004, 0.8509158978473058, 0.8511833132771761, 0.8513170209921113, 0.8518518518518519, 0.8521192672817222, 0.8550608370102954, 0.8557293755849713, 0.8562642064447119, 0.8566653295895174, 0.8580024067388689, 0.8586709453135446, 0.8588046530284797, 0.8593394838882203, 0.8596068993180906, 0.8602754378927664, 0.8614788073271827, 0.8622810536167936, 0.862548469046664, 0.8632170076213398, 0.8634844230512101, 0.8636181307661452, 0.8638855461960155, 0.864286669340821, 0.8645540847706913, 0.8649552079154967, 0.865222623345367, 0.8657574542051076, 0.8660248696349779, 0.8662922850648482, 0.8666934082096537, 0.8668271159245888, 0.8670945313544591, 0.8672282390693943, 0.8680304853590052, 0.8686990239336809, 0.8692338547934216, 0.8695012702232919, 0.8701698087979677, 0.8708383473726434, 0.8719080090921246, 0.8724428399518652, 0.8729776708116058, 0.8736462093862816, 0.8739136248161519, 0.8741810402460222, 0.8744484556758925, 0.8764540713999198, 0.8767214868297901, 0.8769889022596604, 0.8773900254044659, 0.8777911485492713, 0.8780585639791416, 0.8781922716940768, 0.8788608102687525, 0.8796630565583634, 0.8805990105629095, 0.8810001337077149, 0.8812675491375852, 0.8815349645674555, 0.8818023799973258, 0.8824709185720016, 0.8831394571466774, 0.8844765342960289, 0.8864821500200561, 0.8866158577349913, 0.887284396309667, 0.8875518117395373, 0.8878192271694076, 0.8884877657440834, 0.8887551811739537, 0.889022596603824, 0.8891563043187591, 0.8895574274635647, 0.8919641663323974, 0.8920978740473325, 0.8929001203369434, 0.8930338280518786, 0.8941034897713598, 0.8943709052012301, 0.8947720283460355, 0.8949057360609707, 0.895975397780452, 0.8962428132103223, 0.896911351784998, 0.8971787672148683, 0.8978473057895441, 0.8983821366492847, 0.8987832597940901, 0.8989169675090253, 0.8993180906538307, 0.8998529215135713, 0.9003877523733119, 0.9005214600882471, 0.9007888755181174, 0.901323706377858, 0.9018585372375986, 0.9023933680973392, 0.9027944912421447, 0.903061906672015, 0.9034630298168205, 0.9046663992512368, 0.9050675223960423, 0.9053349378259126, 0.9054686455408477, 0.9058697686856532, 0.9062708918304586, 0.9065383072603289, 0.9068057226901992, 0.9080090921246156, 0.9082765075544859, 0.9090787538440968, 0.9094798769889023, 0.9105495387083835, 0.9110843695681241, 0.9125551544324108, 0.912822569862281, 0.9130899852921514, 0.9160315550207246, 0.9164326781655302, 0.9165663858804654, 0.917101216740206, 0.9173686321700762, 0.9196416633239738, 0.9197753710389089, 0.9201764941837144, 0.9208450327583901, 0.9211124481882604, 0.9223158176226768, 0.9231180639122878, 0.9233854793421581, 0.9236528947720284, 0.9237866024869635, 0.9240540179168338, 0.924187725631769, 0.9244551410616393, 0.9245888487765744, 0.9248562642064447, 0.925123679636315, 0.9259259259259259, 0.9263270490707314, 0.926861879930472, 0.9269955876454071, 0.9294023265142398, 0.9296697419441102, 0.9298034496590454, 0.9300708650889157, 0.9326113116726835, 0.9335472656772296, 0.9338146811070999, 0.9342158042519053, 0.9390292819895708, 0.9394304051343763, 0.9396978205642466, 0.940098943709052, 0.9406337745687926, 0.9407674822837278, 0.941034897713598, 0.941837144003209, 0.9422382671480144, 0.9429068057226901, 0.9431742211525606, 0.9434416365824309, 0.9437090520123012, 0.9443775905869769, 0.9446450060168472, 0.9451798368765878, 0.946249498596069, 0.9465169140259393, 0.9470517448856799, 0.9479876988902259, 0.9481214066051611, 0.9485225297499665, 0.9487899451798368, 0.9493247760395774, 0.9529348843428266, 0.9532022997726969, 0.9536034229175023, 0.9538708383473726, 0.9541382537772429, 0.9545393769220484, 0.9577483620804921, 0.9581494852252975, 0.9582831929402327, 0.9589517315149084, 0.9597539778045193, 0.9605562240941302, 0.9609573472389357, 0.9620270089584169, 0.9626955475330926, 0.9634977938227036, 0.9636315015376388, 0.9645674555421848, 0.9648348709720551, 0.9651022864019254, 0.967375317555823, 0.9675090252707581, 0.9681775638454339, 0.9713865490038776, 0.9715202567188127, 0.9719213798636182, 0.9721887952934885, 0.9724562107233587, 0.9728573338681642, 0.9731247492980345, 0.9745955341623211, 0.9749966573071266, 0.9751303650220617, 0.9757989035967375, 0.9760663190266078, 0.9774033961759594, 0.978874181040246, 0.9791415964701163, 0.9794090118999866, 0.9795427196149218, 0.9798101350447921, 0.9812809199090787, 0.9816820430538842, 0.9826179970584302, 0.9832865356331061, 0.9834202433480412, 0.9836876587779115, 0.9842224896376521, 0.9844899050675224, 0.9847573204973927, 0.9863618130766145, 0.9870303516512903, 0.987698890225966, 0.9878325979409012, 0.9883674288006418, 0.9885011365155769, 0.9895707982350581, 0.9897045059499933, 0.9903730445246691, 0.9906404599545394, 0.9941168605428533, 0.9942505682577885, 0.9953202299772697, 0.99558764540714, 0.9959887685519454, 0.9981280919909079, 0.9983955074207782, 0.9991977537103891, 1.0]], 'tpr': [[0.0, 0.003056768558951965, 0.004366812227074236, 0.005240174672489083, 0.0069868995633187774, 0.010917030567685589, 0.01222707423580786, 0.012663755458515284, 0.013537117903930132, 0.016593886462882096, 0.01921397379912664, 0.02096069868995633, 0.022707423580786028, 0.024890829694323144, 0.026200873362445413, 0.027510917030567687, 0.028384279475982533, 0.028820960698689956, 0.030131004366812226, 0.03187772925764192, 0.033624454148471615, 0.03537117903930131, 0.036244541484716154, 0.03973799126637555, 0.04148471615720524, 0.04279475982532751, 0.045414847161572056, 0.04716157205240175, 0.04890829694323144, 0.05283842794759825, 0.05327510917030567, 0.05414847161572053, 0.055458515283842796, 0.05851528384279476, 0.059388646288209605, 0.06200873362445415, 0.06375545851528384, 0.0685589519650655, 0.06943231441048035, 0.06986899563318777, 0.07161572052401746, 0.07336244541484715, 0.07336244541484715, 0.07598253275109171, 0.07860262008733625, 0.08602620087336245, 0.08864628820960699, 0.0890829694323144, 0.08995633187772925, 0.09039301310043668, 0.09213973799126637, 0.0925764192139738, 0.09344978165938865, 0.0943231441048035, 0.09519650655021834, 0.09694323144104804, 0.0982532751091703, 0.09912663755458516, 0.10087336244541485, 0.1017467248908297, 0.10262008733624454, 0.10436681222707424, 0.10873362445414847, 0.10960698689956332, 0.11004366812227075, 0.11004366812227075, 0.11135371179039301, 0.11222707423580786, 0.11353711790393013, 0.11441048034934498, 0.11572052401746726, 0.11746724890829695, 0.11790393013100436, 0.11877729257641921, 0.12270742358078603, 0.12358078602620087, 0.12663755458515283, 0.1275109170305677, 0.12882096069868995, 0.1296943231441048, 0.1314410480349345, 0.13362445414847163, 0.1349344978165939, 0.13580786026200872, 0.13755458515283842, 0.13842794759825328, 0.14410480349344978, 0.14541484716157205, 0.14585152838427948, 0.1467248908296943, 0.14890829694323143, 0.1497816593886463, 0.15065502183406113, 0.15240174672489082, 0.15240174672489082, 0.15589519650655023, 0.15676855895196506, 0.15982532751091702, 0.162882096069869, 0.162882096069869, 0.16419213973799127, 0.16506550218340613, 0.16681222707423582, 0.16768558951965065, 0.1685589519650655, 0.16943231441048034, 0.17292576419213973, 0.1737991266375546, 0.17467248908296942, 0.17554585152838428, 0.17641921397379912, 0.17729257641921398, 0.18078602620087336, 0.18253275109170305, 0.18427947598253275, 0.18602620087336244, 0.1868995633187773, 0.1873362445414847, 0.18820960698689956, 0.18951965065502183, 0.19082969432314412, 0.1925764192139738, 0.19388646288209607, 0.1947598253275109, 0.19563318777292577, 0.19737991266375546, 0.19912663755458515, 0.2004366812227074, 0.20131004366812227, 0.20305676855895197, 0.2034934497816594, 0.20436681222707423, 0.20655021834061135, 0.20786026200873362, 0.2109170305676856, 0.21179039301310043, 0.21746724890829694, 0.21746724890829694, 0.2187772925764192, 0.2200873362445415, 0.2275109170305677, 0.22838427947598253, 0.23056768558951965, 0.2314410480349345, 0.2318777292576419, 0.2318777292576419, 0.2366812227074236, 0.23755458515283842, 0.2423580786026201, 0.24759825327510918, 0.2519650655021834, 0.2519650655021834, 0.25283842794759825, 0.2554585152838428, 0.25633187772925764, 0.25633187772925764, 0.25851528384279476, 0.25851528384279476, 0.25895196506550217, 0.2606986899563319, 0.2611353711790393, 0.26244541484716155, 0.26375545851528387, 0.26375545851528387, 0.2646288209606987, 0.26550218340611353, 0.2663755458515284, 0.26812227074235806, 0.27074235807860264, 0.2724890829694323, 0.27336244541484717, 0.27336244541484717, 0.27379912663755457, 0.27379912663755457, 0.27467248908296943, 0.27510917030567683, 0.29737991266375546, 0.2986899563318777, 0.2986899563318777, 0.2995633187772926, 0.3, 0.30087336244541485, 0.3017467248908297, 0.3026200873362445, 0.3034934497816594, 0.3074235807860262, 0.308296943231441, 0.32489082969432315, 0.32532751091703055, 0.32532751091703055, 0.3262008733624454, 0.3331877729257642, 0.33406113537117904, 0.3353711790393013, 0.3375545851528384, 0.3388646288209607, 0.34323144104803494, 0.3480349344978166, 0.3506550218340611, 0.35109170305676857, 0.35240174672489083, 0.35414847161572055, 0.35502183406113536, 0.3558951965065502, 0.3558951965065502, 0.3563318777292576, 0.3572052401746725, 0.35807860262008734, 0.35807860262008734, 0.35851528384279474, 0.35851528384279474, 0.36375545851528385, 0.36419213973799125, 0.36419213973799125, 0.3646288209606987, 0.3764192139737991, 0.37685589519650653, 0.37685589519650653, 0.377292576419214, 0.377292576419214, 0.37860262008733625, 0.3794759825327511, 0.3794759825327511, 0.3807860262008734, 0.3807860262008734, 0.38253275109170304, 0.38253275109170304, 0.3834061135371179, 0.3834061135371179, 0.3851528384279476, 0.388646288209607, 0.3890829694323144, 0.4039301310043668, 0.4043668122270742, 0.4043668122270742, 0.40655021834061134, 0.4069868995633188, 0.4069868995633188, 0.4074235807860262, 0.4135371179039301, 0.4187772925764192, 0.4192139737991266, 0.4200873362445415, 0.4200873362445415, 0.42096069868995634, 0.42096069868995634, 0.42139737991266374, 0.4218340611353712, 0.4218340611353712, 0.422707423580786, 0.4344978165938865, 0.4406113537117904, 0.4423580786026201, 0.4432314410480349, 0.4441048034934498, 0.44454148471615723, 0.44716157205240176, 0.44716157205240176, 0.4480349344978166, 0.4480349344978166, 0.448471615720524, 0.4493449781659389, 0.4497816593886463, 0.45065502183406114, 0.45109170305676854, 0.45109170305676854, 0.4519650655021834, 0.45283842794759827, 0.45458515283842793, 0.4550218340611354, 0.4554585152838428, 0.4554585152838428, 0.4558951965065502, 0.4558951965065502, 0.45633187772925765, 0.45633187772925765, 0.4580786026200873, 0.46026200873362444, 0.4606986899563319, 0.46593886462882095, 0.4729257641921397, 0.4737991266375546, 0.4790393013100437, 0.4794759825327511, 0.48034934497816595, 0.48253275109170307, 0.4851528384279476, 0.485589519650655, 0.48602620087336246, 0.4868995633187773, 0.4882096069868996, 0.488646288209607, 0.4890829694323144, 0.4908296943231441, 0.4912663755458515, 0.49213973799126637, 0.49301310043668123, 0.49563318777292575, 0.496943231441048, 0.4978165938864629, 0.5039301310043668, 0.5048034934497817, 0.505240174672489, 0.505240174672489, 0.5056768558951965, 0.5056768558951965, 0.506113537117904, 0.511353711790393, 0.511353711790393, 0.5122270742358078, 0.5122270742358078, 0.514410480349345, 0.5170305676855895, 0.517467248908297, 0.517467248908297, 0.517467248908297, 0.5183406113537118, 0.5183406113537118, 0.5187772925764192, 0.5200873362445415, 0.5209606986899563, 0.5209606986899563, 0.5218340611353712, 0.5222707423580786, 0.5222707423580786, 0.522707423580786, 0.522707423580786, 0.5231441048034935, 0.5244541484716158, 0.5253275109170306, 0.525764192139738, 0.5275109170305677, 0.5279475982532751, 0.5279475982532751, 0.5292576419213973, 0.5292576419213973, 0.5296943231441048, 0.5327510917030568, 0.5327510917030568, 0.534061135371179, 0.5349344978165939, 0.5393013100436681, 0.5397379912663756, 0.540174672489083, 0.5423580786026201, 0.5480349344978166, 0.5480349344978166, 0.5480349344978166, 0.5493449781659389, 0.5510917030567686, 0.551528384279476, 0.5576419213973799, 0.5576419213973799, 0.5593886462882096, 0.5602620087336244, 0.5620087336244541, 0.5620087336244541, 0.5633187772925764, 0.5633187772925764, 0.5641921397379913, 0.5641921397379913, 0.5655021834061136, 0.5655021834061136, 0.5663755458515284, 0.5663755458515284, 0.5668122270742358, 0.5685589519650655, 0.5759825327510917, 0.5759825327510917, 0.5768558951965066, 0.5768558951965066, 0.585589519650655, 0.5860262008733624, 0.5864628820960699, 0.5868995633187772, 0.5868995633187772, 0.5873362445414847, 0.5873362445414847, 0.5877729257641922, 0.5890829694323144, 0.5899563318777292, 0.5899563318777292, 0.5903930131004367, 0.5930131004366812, 0.5934497816593887, 0.5956331877729257, 0.5956331877729257, 0.5973799126637555, 0.6004366812227074, 0.6004366812227074, 0.6008733624454149, 0.6008733624454149, 0.6013100436681222, 0.6074235807860262, 0.6074235807860262, 0.6074235807860262, 0.6100436681222707, 0.6117903930131005, 0.6117903930131005, 0.6131004366812227, 0.6131004366812227, 0.6148471615720524, 0.6148471615720524, 0.620524017467249, 0.620524017467249, 0.6209606986899563, 0.6209606986899563, 0.622707423580786, 0.622707423580786, 0.6240174672489083, 0.6253275109170305, 0.625764192139738, 0.625764192139738, 0.6262008733624455, 0.6296943231441048, 0.631004366812227, 0.631877729257642, 0.631877729257642, 0.6323144104803493, 0.6331877729257642, 0.6344978165938865, 0.6344978165938865, 0.6358078602620088, 0.6358078602620088, 0.6366812227074236, 0.6375545851528385, 0.6379912663755458, 0.6379912663755458, 0.6384279475982533, 0.6384279475982533, 0.6393013100436681, 0.6427947598253275, 0.6427947598253275, 0.6427947598253275, 0.6471615720524018, 0.6475982532751092, 0.6497816593886463, 0.6497816593886463, 0.6502183406113538, 0.6502183406113538, 0.6502183406113538, 0.6506550218340611, 0.6506550218340611, 0.6510917030567686, 0.6532751091703056, 0.6541484716157205, 0.6554585152838428, 0.6602620087336245, 0.6602620087336245, 0.6606986899563319, 0.6606986899563319, 0.6615720524017468, 0.6615720524017468, 0.6633187772925764, 0.665938864628821, 0.665938864628821, 0.6668122270742358, 0.6681222707423581, 0.6681222707423581, 0.6685589519650655, 0.6685589519650655, 0.6689956331877729, 0.6703056768558951, 0.6707423580786026, 0.6729257641921398, 0.6733624454148471, 0.674235807860262, 0.6746724890829694, 0.6751091703056769, 0.6755458515283843, 0.6755458515283843, 0.6772925764192139, 0.6777292576419214, 0.6777292576419214, 0.6781659388646288, 0.6781659388646288, 0.6790393013100436, 0.6790393013100436, 0.6790393013100436, 0.6816593886462882, 0.6816593886462882, 0.6820960698689956, 0.6820960698689956, 0.6834061135371179, 0.6838427947598253, 0.6847161572052402, 0.6847161572052402, 0.6847161572052402, 0.6847161572052402, 0.6855895196506551, 0.6890829694323144, 0.6890829694323144, 0.6903930131004367, 0.6903930131004367, 0.6973799126637554, 0.6973799126637554, 0.6982532751091703, 0.6982532751091703, 0.6982532751091703, 0.6991266375545852, 0.7021834061135371, 0.7034934497816594, 0.7039301310043669, 0.7039301310043669, 0.7048034934497817, 0.7052401746724891, 0.7069868995633187, 0.7074235807860262, 0.7074235807860262, 0.7078602620087336, 0.7078602620087336, 0.7082969432314411, 0.7082969432314411, 0.7087336244541484, 0.7087336244541484, 0.7087336244541484, 0.7096069868995634, 0.7096069868995634, 0.7100436681222707, 0.7100436681222707, 0.7109170305676856, 0.711353711790393, 0.711353711790393, 0.711353711790393, 0.7117903930131004, 0.7117903930131004, 0.7122270742358079, 0.7131004366812227, 0.7135371179039302, 0.7135371179039302, 0.7170305676855895, 0.7170305676855895, 0.7179039301310044, 0.7179039301310044, 0.7183406113537117, 0.7187772925764192, 0.7192139737991267, 0.719650655021834, 0.7235807860262009, 0.7240174672489083, 0.7244541484716157, 0.7253275109170305, 0.7253275109170305, 0.7266375545851529, 0.7275109170305677, 0.7279475982532752, 0.72882096069869, 0.72882096069869, 0.7292576419213974, 0.7323144104803494, 0.7323144104803494, 0.7327510917030567, 0.7327510917030567, 0.7327510917030567, 0.7336244541484717, 0.734061135371179, 0.7344978165938865, 0.7358078602620087, 0.7362445414847162, 0.7362445414847162, 0.7375545851528384, 0.7379912663755459, 0.7379912663755459, 0.7393013100436682, 0.7406113537117904, 0.7410480349344978, 0.7410480349344978, 0.7419213973799127, 0.7419213973799127, 0.74235807860262, 0.74235807860262, 0.7427947598253275, 0.743231441048035, 0.743231441048035, 0.7436681222707423, 0.7436681222707423, 0.7436681222707423, 0.7436681222707423, 0.7436681222707423, 0.7589519650655022, 0.7589519650655022, 0.759825327510917, 0.7602620087336245, 0.7602620087336245, 0.7602620087336245, 0.7606986899563318, 0.7611353711790393, 0.7611353711790393, 0.7624454148471616, 0.7624454148471616, 0.7655021834061135, 0.7663755458515283, 0.7668122270742358, 0.7668122270742358, 0.7672489082969433, 0.7676855895196506, 0.7676855895196506, 0.768995633187773, 0.768995633187773, 0.768995633187773, 0.7694323144104803, 0.7703056768558952, 0.7703056768558952, 0.7703056768558952, 0.77117903930131, 0.77117903930131, 0.7724890829694323, 0.7724890829694323, 0.7724890829694323, 0.7724890829694323, 0.7724890829694323, 0.7733624454148471, 0.7733624454148471, 0.7737991266375546, 0.774235807860262, 0.774235807860262, 0.774235807860262, 0.774235807860262, 0.7746724890829695, 0.7768558951965066, 0.7768558951965066, 0.7786026200873363, 0.7786026200873363, 0.7786026200873363, 0.7790393013100436, 0.7790393013100436, 0.7790393013100436, 0.7794759825327511, 0.7794759825327511, 0.7794759825327511, 0.7794759825327511, 0.7847161572052401, 0.7851528384279476, 0.7851528384279476, 0.7851528384279476, 0.7851528384279476, 0.7860262008733624, 0.7860262008733624, 0.7864628820960698, 0.7864628820960698, 0.7873362445414848, 0.7873362445414848, 0.7912663755458516, 0.7917030567685589, 0.7917030567685589, 0.7925764192139738, 0.7930131004366813, 0.7934497816593886, 0.7934497816593886, 0.7934497816593886, 0.7956331877729258, 0.7960698689956331, 0.8013100436681223, 0.8013100436681223, 0.8021834061135371, 0.8034934497816594, 0.8034934497816594, 0.8039301310043668, 0.8039301310043668, 0.8052401746724891, 0.8052401746724891, 0.8056768558951966, 0.8056768558951966, 0.8061135371179039, 0.8061135371179039, 0.8065502183406114, 0.8074235807860262, 0.8074235807860262, 0.8074235807860262, 0.8074235807860262, 0.8078602620087336, 0.8082969432314411, 0.8082969432314411, 0.8082969432314411, 0.8087336244541484, 0.8091703056768559, 0.8091703056768559, 0.8109170305676856, 0.8117903930131004, 0.8126637554585153, 0.8126637554585153, 0.8131004366812227, 0.8157205240174672, 0.8157205240174672, 0.8157205240174672, 0.8161572052401747, 0.8161572052401747, 0.8165938864628821, 0.8165938864628821, 0.8174672489082969, 0.8179039301310044, 0.8183406113537118, 0.8187772925764192, 0.8187772925764192, 0.8187772925764192, 0.8192139737991266, 0.8192139737991266, 0.8196506550218341, 0.8196506550218341, 0.8205240174672489, 0.8209606986899564, 0.8209606986899564, 0.8209606986899564, 0.8218340611353712, 0.8218340611353712, 0.8218340611353712, 0.8222707423580786, 0.8222707423580786, 0.8235807860262009, 0.8235807860262009, 0.8240174672489083, 0.8240174672489083, 0.8244541484716157, 0.8248908296943231, 0.8253275109170306, 0.8253275109170306, 0.8253275109170306, 0.8266375545851529, 0.8266375545851529, 0.8270742358078602, 0.8275109170305677, 0.8279475982532751, 0.8292576419213974, 0.8301310043668122, 0.8305676855895197, 0.8305676855895197, 0.8327510917030567, 0.8336244541484716, 0.8336244541484716, 0.8336244541484716, 0.8349344978165939, 0.8349344978165939, 0.8349344978165939, 0.8349344978165939, 0.8349344978165939, 0.8353711790393014, 0.8353711790393014, 0.8362445414847162, 0.8362445414847162, 0.8384279475982532, 0.8384279475982532, 0.8406113537117904, 0.8410480349344979, 0.8410480349344979, 0.8410480349344979, 0.8423580786026201, 0.8427947598253275, 0.8436681222707424, 0.8436681222707424, 0.8436681222707424, 0.8449781659388647, 0.845414847161572, 0.845414847161572, 0.845414847161572, 0.845414847161572, 0.845414847161572, 0.8462882096069869, 0.8467248908296944, 0.8502183406113537, 0.851528384279476, 0.851528384279476, 0.851528384279476, 0.851528384279476, 0.851528384279476, 0.8519650655021834, 0.8519650655021834, 0.8519650655021834, 0.8524017467248908, 0.8524017467248908, 0.8532751091703057, 0.8532751091703057, 0.8532751091703057, 0.8532751091703057, 0.8537117903930131, 0.8537117903930131, 0.8537117903930131, 0.8541484716157205, 0.8541484716157205, 0.854585152838428, 0.8550218340611354, 0.8550218340611354, 0.8550218340611354, 0.8554585152838428, 0.8554585152838428, 0.856768558951965, 0.856768558951965, 0.8572052401746725, 0.8572052401746725, 0.8576419213973799, 0.8585152838427947, 0.8585152838427947, 0.8589519650655022, 0.8589519650655022, 0.8602620087336245, 0.8602620087336245, 0.8606986899563319, 0.8606986899563319, 0.8620087336244542, 0.8620087336244542, 0.8637554585152838, 0.8646288209606987, 0.8646288209606987, 0.8650655021834062, 0.8650655021834062, 0.8650655021834062, 0.8655021834061135, 0.8655021834061135, 0.865938864628821, 0.865938864628821, 0.8663755458515284, 0.8668122270742358, 0.8676855895196507, 0.8685589519650655, 0.8685589519650655, 0.868995633187773, 0.8694323144104803, 0.8694323144104803, 0.8698689956331878, 0.8698689956331878, 0.8703056768558952, 0.8703056768558952, 0.8707423580786027, 0.8707423580786027, 0.8724890829694323, 0.8724890829694323, 0.8729257641921397, 0.8733624454148472, 0.8733624454148472, 0.8733624454148472, 0.8737991266375545, 0.8737991266375545, 0.8737991266375545, 0.8737991266375545, 0.8737991266375545, 0.8746724890829695, 0.8746724890829695, 0.8746724890829695, 0.877292576419214, 0.877292576419214, 0.8777292576419214, 0.8781659388646288, 0.8781659388646288, 0.8781659388646288, 0.879475982532751, 0.8829694323144105, 0.8829694323144105, 0.8829694323144105, 0.883406113537118, 0.8851528384279476, 0.8851528384279476, 0.8864628820960698, 0.8864628820960698, 0.8864628820960698, 0.8864628820960698, 0.8868995633187773, 0.8868995633187773, 0.8873362445414847, 0.8873362445414847, 0.888646288209607, 0.888646288209607, 0.888646288209607, 0.8895196506550218, 0.8895196506550218, 0.8895196506550218, 0.8899563318777293, 0.8899563318777293, 0.8903930131004367, 0.8903930131004367, 0.8903930131004367, 0.8903930131004367, 0.8903930131004367, 0.8903930131004367, 0.8903930131004367, 0.8908296943231441, 0.8908296943231441, 0.8908296943231441, 0.8908296943231441, 0.8908296943231441, 0.8912663755458515, 0.891703056768559, 0.8921397379912663, 0.8921397379912663, 0.8925764192139738, 0.8938864628820961, 0.8938864628820961, 0.8938864628820961, 0.8938864628820961, 0.8938864628820961, 0.8938864628820961, 0.8938864628820961, 0.8960698689956332, 0.896943231441048, 0.896943231441048, 0.8982532751091703, 0.8982532751091703, 0.8986899563318778, 0.8986899563318778, 0.9004366812227074, 0.9004366812227074, 0.9004366812227074, 0.9008733624454148, 0.9017467248908297, 0.9017467248908297, 0.9017467248908297, 0.9017467248908297, 0.9017467248908297, 0.9017467248908297, 0.9017467248908297, 0.9021834061135371, 0.9021834061135371, 0.9034934497816594, 0.9039301310043668, 0.9039301310043668, 0.9039301310043668, 0.9039301310043668, 0.9039301310043668, 0.9043668122270743, 0.9043668122270743, 0.9048034934497816, 0.9048034934497816, 0.9052401746724891, 0.9056768558951965, 0.9056768558951965, 0.9056768558951965, 0.9061135371179039, 0.9061135371179039, 0.9061135371179039, 0.9074235807860263, 0.9074235807860263, 0.9082969432314411, 0.9082969432314411, 0.9087336244541485, 0.9091703056768559, 0.9091703056768559, 0.9091703056768559, 0.9091703056768559, 0.9091703056768559, 0.9096069868995633, 0.9100436681222708, 0.9100436681222708, 0.9100436681222708, 0.9100436681222708, 0.9109170305676856, 0.9109170305676856, 0.911353711790393, 0.911353711790393, 0.911353711790393, 0.911353711790393, 0.911353711790393, 0.911353711790393, 0.9131004366812228, 0.9131004366812228, 0.9135371179039301, 0.9135371179039301, 0.9135371179039301, 0.9135371179039301, 0.9139737991266376, 0.914410480349345, 0.914410480349345, 0.914410480349345, 0.914410480349345, 0.914410480349345, 0.9148471615720524, 0.9152838427947598, 0.9152838427947598, 0.9157205240174673, 0.9157205240174673, 0.9165938864628821, 0.9165938864628821, 0.9165938864628821, 0.9165938864628821, 0.9170305676855895, 0.9170305676855895, 0.9174672489082969, 0.9179039301310044, 0.9179039301310044, 0.9179039301310044, 0.9187772925764193, 0.9187772925764193, 0.9187772925764193, 0.9187772925764193, 0.9192139737991266, 0.9192139737991266, 0.9192139737991266, 0.9196506550218341, 0.9196506550218341, 0.9200873362445415, 0.9200873362445415, 0.9200873362445415, 0.9209606986899563, 0.9209606986899563, 0.9209606986899563, 0.9209606986899563, 0.9209606986899563, 0.9213973799126638, 0.9213973799126638, 0.9213973799126638, 0.9213973799126638, 0.9213973799126638, 0.9222707423580786, 0.9222707423580786, 0.9222707423580786, 0.9227074235807861, 0.9227074235807861, 0.9227074235807861, 0.9227074235807861, 0.9231441048034934, 0.9235807860262009, 0.9235807860262009, 0.9240174672489083, 0.9240174672489083, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9253275109170306, 0.9262008733624454, 0.9262008733624454, 0.9262008733624454, 0.9262008733624454, 0.9262008733624454, 0.9262008733624454, 0.9266375545851528, 0.9270742358078603, 0.9279475982532751, 0.9283842794759826, 0.9283842794759826, 0.9296943231441048, 0.9296943231441048, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9301310043668122, 0.9305676855895196, 0.9305676855895196, 0.9305676855895196, 0.9310043668122271, 0.9310043668122271, 0.9314410480349345, 0.9314410480349345, 0.9314410480349345, 0.9314410480349345, 0.9314410480349345, 0.9314410480349345, 0.9318777292576419, 0.9318777292576419, 0.9318777292576419, 0.9318777292576419, 0.9323144104803494, 0.9323144104803494, 0.9323144104803494, 0.9323144104803494, 0.9327510917030568, 0.9327510917030568, 0.9327510917030568, 0.9336244541484716, 0.9336244541484716, 0.9340611353711791, 0.9340611353711791, 0.9340611353711791, 0.9344978165938864, 0.9344978165938864, 0.9349344978165939, 0.9349344978165939, 0.9358078602620087, 0.9358078602620087, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9362445414847161, 0.9366812227074236, 0.9366812227074236, 0.9375545851528384, 0.9375545851528384, 0.9375545851528384, 0.9375545851528384, 0.9375545851528384, 0.9375545851528384, 0.9384279475982533, 0.9388646288209607, 0.9388646288209607, 0.9388646288209607, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9397379912663756, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9401746724890829, 0.9406113537117904, 0.9406113537117904, 0.9406113537117904, 0.9406113537117904, 0.9410480349344978, 0.9410480349344978, 0.9414847161572052, 0.9414847161572052, 0.9414847161572052, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9419213973799127, 0.9423580786026201, 0.9423580786026201, 0.9423580786026201, 0.9427947598253276, 0.9427947598253276, 0.9436681222707424, 0.9436681222707424, 0.9436681222707424, 0.9436681222707424, 0.9436681222707424, 0.9436681222707424, 0.9441048034934498, 0.9441048034934498, 0.9445414847161572, 0.9445414847161572, 0.9445414847161572, 0.9445414847161572, 0.9445414847161572, 0.9454148471615721, 0.9454148471615721, 0.9454148471615721, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9458515283842794, 0.9467248908296944, 0.9467248908296944, 0.9467248908296944, 0.9471615720524017, 0.9471615720524017, 0.9471615720524017, 0.9471615720524017, 0.9471615720524017, 0.9471615720524017, 0.9475982532751092, 0.9475982532751092, 0.948471615720524, 0.9489082969432314, 0.9489082969432314, 0.9489082969432314, 0.9493449781659389, 0.9497816593886463, 0.9497816593886463, 0.9506550218340611, 0.9506550218340611, 0.9506550218340611, 0.9506550218340611, 0.9510917030567686, 0.9510917030567686, 0.9510917030567686, 0.9510917030567686, 0.9510917030567686, 0.951528384279476, 0.951528384279476, 0.951528384279476, 0.951528384279476, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9519650655021834, 0.9524017467248909, 0.9524017467248909, 0.9524017467248909, 0.9524017467248909, 0.9532751091703057, 0.9537117903930131, 0.9537117903930131, 0.9537117903930131, 0.9537117903930131, 0.9537117903930131, 0.9537117903930131, 0.9545851528384279, 0.9545851528384279, 0.9550218340611354, 0.9550218340611354, 0.9550218340611354, 0.9554585152838428, 0.9558951965065502, 0.9558951965065502, 0.9563318777292577, 0.9563318777292577, 0.9563318777292577, 0.9563318777292577, 0.9567685589519651, 0.9567685589519651, 0.9567685589519651, 0.9567685589519651, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9576419213973799, 0.9580786026200874, 0.9580786026200874, 0.9580786026200874, 0.9585152838427947, 0.9585152838427947, 0.9589519650655022, 0.9589519650655022, 0.9589519650655022, 0.9589519650655022, 0.9589519650655022, 0.9589519650655022, 0.959825327510917, 0.959825327510917, 0.9602620087336244, 0.9602620087336244, 0.9602620087336244, 0.9602620087336244, 0.9602620087336244, 0.9606986899563319, 0.9606986899563319, 0.9611353711790394, 0.9611353711790394, 0.9615720524017467, 0.9615720524017467, 0.9620087336244542, 0.9620087336244542, 0.9620087336244542, 0.9620087336244542, 0.9620087336244542, 0.9624454148471616, 0.962882096069869, 0.962882096069869, 0.9633187772925764, 0.9633187772925764, 0.9633187772925764, 0.9633187772925764, 0.9633187772925764, 0.9637554585152839, 0.9637554585152839, 0.9637554585152839, 0.9637554585152839, 0.9637554585152839, 0.9637554585152839, 0.9641921397379912, 0.9646288209606987, 0.9646288209606987, 0.9646288209606987, 0.9646288209606987, 0.9655021834061135, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.965938864628821, 0.9663755458515284, 0.9663755458515284, 0.9668122270742358, 0.9668122270742358, 0.9668122270742358, 0.9668122270742358, 0.9668122270742358, 0.9672489082969432, 0.9672489082969432, 0.9672489082969432, 0.9672489082969432, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9676855895196507, 0.9685589519650655, 0.9685589519650655, 0.9689956331877729, 0.9689956331877729, 0.9689956331877729, 0.9694323144104804, 0.9694323144104804, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9698689956331877, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.9707423580786027, 0.97117903930131, 0.97117903930131, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9716157205240175, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9720524017467249, 0.9724890829694323, 0.9724890829694323, 0.9724890829694323, 0.9724890829694323, 0.9724890829694323, 0.9724890829694323, 0.9724890829694323, 0.9729257641921397, 0.9729257641921397, 0.9733624454148472, 0.9733624454148472, 0.9733624454148472, 0.9733624454148472, 0.9733624454148472, 0.9733624454148472, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.9737991266375546, 0.974235807860262, 0.974235807860262, 0.974235807860262, 0.974235807860262, 0.974235807860262, 0.974235807860262, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9746724890829694, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9751091703056769, 0.9755458515283842, 0.9755458515283842, 0.9755458515283842, 0.9755458515283842, 0.9755458515283842, 0.9759825327510917, 0.9759825327510917, 0.9759825327510917, 0.9764192139737992, 0.9764192139737992, 0.9764192139737992, 0.9764192139737992, 0.9764192139737992, 0.9768558951965065, 0.9768558951965065, 0.9768558951965065, 0.9768558951965065, 0.9768558951965065, 0.9768558951965065, 0.977292576419214, 0.977292576419214, 0.977292576419214, 0.977292576419214, 0.977292576419214, 0.977292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9777292576419214, 0.9781659388646288, 0.9781659388646288, 0.9781659388646288, 0.9781659388646288, 0.9786026200873362, 0.9786026200873362, 0.9790393013100437, 0.9790393013100437, 0.9794759825327511, 0.9794759825327511, 0.980349344978166, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9807860262008734, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9812227074235808, 0.9816593886462882, 0.9820960698689957, 0.9820960698689957, 0.9820960698689957, 0.9820960698689957, 0.9820960698689957, 0.9820960698689957, 0.9820960698689957, 0.982532751091703, 0.9829694323144105, 0.9829694323144105, 0.9829694323144105, 0.9834061135371179, 0.9834061135371179, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9838427947598253, 0.9842794759825327, 0.9842794759825327, 0.9847161572052402, 0.9847161572052402, 0.9847161572052402, 0.9847161572052402, 0.9847161572052402, 0.9847161572052402, 0.9847161572052402, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.9851528384279477, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.985589519650655, 0.9860262008733625, 0.9860262008733625, 0.9860262008733625, 0.9860262008733625, 0.9860262008733625, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9864628820960699, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9868995633187773, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9873362445414847, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9877729257641922, 0.9882096069868995, 0.9882096069868995, 0.9882096069868995, 0.9882096069868995, 0.9882096069868995, 0.988646288209607, 0.988646288209607, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9890829694323144, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9895196506550218, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9899563318777292, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.9903930131004367, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.990829694323144, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.9912663755458515, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.991703056768559, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9921397379912664, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9925764192139738, 0.9934497816593887, 0.9934497816593887, 0.9934497816593887, 0.9934497816593887, 0.9934497816593887, 0.9934497816593887, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.993886462882096, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.994759825327511, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9951965065502183, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9956331877729258, 0.9960698689956332, 0.9960698689956332, 0.9960698689956332, 0.9960698689956332, 0.9960698689956332, 0.9960698689956332, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.9965065502183406, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.996943231441048, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9973799126637555, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9978165938864629, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9982532751091703, 0.9986899563318777, 0.9986899563318777, 0.9986899563318777, 0.9986899563318777, 0.9986899563318777, 0.9986899563318777, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9991266375545852, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 0.9995633187772925, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]], 'thresholds': [[inf, 0.5426189466080212, 0.5418212069170286, 0.5408403605638021, 0.5407143576498511, 0.5400125404372915, 0.539916112683864, 0.539733154643796, 0.5392982021513041, 0.5392141151649852, 0.5390311163060776, 0.5383688319595723, 0.5381905738798586, 0.5377099577681276, 0.5374486420805685, 0.5371541127913773, 0.5369838442768275, 0.5367897473534873, 0.5366890301772265, 0.5364664432203654, 0.5364458470817185, 0.5358897940622497, 0.5358113755279917, 0.5350229954171768, 0.534865238293372, 0.5344047637374066, 0.5343728817735789, 0.5340401114352169, 0.5336573486828817, 0.5335731225791825, 0.5334630688188962, 0.5333898220700427, 0.5333024525620041, 0.5325024632761194, 0.5324837902179285, 0.5321026174034446, 0.5319451525204069, 0.5313264133467241, 0.5311747040779276, 0.5310738325501011, 0.5310440097935831, 0.5308004541007741, 0.5306376629956489, 0.530273387853541, 0.5302435592193772, 0.5286844631714481, 0.5284737716297643, 0.5284110398715579, 0.5283801003858575, 0.5280838051140055, 0.527953376414018, 0.52785939716311, 0.5278133244890546, 0.527734743934912, 0.5276596111020393, 0.5274725401522148, 0.5274686264372258, 0.5272989677479354, 0.5271200760036852, 0.5270734586920823, 0.5269336766741813, 0.52675008117837, 0.5263203581989908, 0.5263140054466758, 0.5262775651556142, 0.5262722120992219, 0.5260724219628601, 0.5260314823520867, 0.5259294960044815, 0.5258816433030733, 0.5257875876196554, 0.5256596803480575, 0.5255349777480678, 0.5255218956336761, 0.5247570974010676, 0.5247447592608816, 0.5244183516573311, 0.5244102331992716, 0.5244006522916179, 0.5243098302868285, 0.5242564184974426, 0.5238795145178835, 0.5238432820710899, 0.5238338446468079, 0.5236341428908153, 0.5235990349227522, 0.5227327885165693, 0.5226135495058772, 0.5224869609264824, 0.5224640628496825, 0.5222023212322457, 0.5221863262049585, 0.5221385437725322, 0.5221261995586179, 0.522105853711115, 0.5214098218365623, 0.5214087019484585, 0.5213242479236576, 0.5210552487519062, 0.5210528501970342, 0.5208752678601165, 0.5208409925035762, 0.5205362834179194, 0.5204241157322416, 0.5203639454117001, 0.5203383676370471, 0.5196971989097927, 0.5196920100251428, 0.519682207126176, 0.5195513046837342, 0.5194069367183343, 0.5193105211763365, 0.5187058716045548, 0.5185651449966824, 0.5185444672946157, 0.5183812821915569, 0.5183243254597718, 0.518218526703467, 0.5181786691103765, 0.5179879794486086, 0.517986235405263, 0.5178429449975398, 0.5178023451007814, 0.5177767948058303, 0.5176777695634507, 0.5175370219515025, 0.5171864534846463, 0.51710502960465, 0.5169998497192456, 0.516921116644576, 0.5168627195829683, 0.5167965258949725, 0.5163162518422929, 0.5162124019625538, 0.5156485127321015, 0.5155505241495232, 0.5147163006593182, 0.5146954010921793, 0.5145772025082384, 0.5145678602720186, 0.5137650367218131, 0.513641632665405, 0.5133119344180695, 0.5132605944147454, 0.5130481555944408, 0.512958083278089, 0.5121407427972259, 0.5121311446663486, 0.5112852044828887, 0.5112002225075569, 0.5107316839742259, 0.5107162072478441, 0.5105999922219442, 0.5103971287447053, 0.5103409875045535, 0.5102405685190975, 0.5102130808205564, 0.5100858378534167, 0.5100621985352279, 0.5099130806407344, 0.5099019958325106, 0.5098475929880791, 0.509762659480745, 0.5097290255414836, 0.5094846249927111, 0.5094099216686979, 0.5092947105754442, 0.5092831194001994, 0.509053548692412, 0.5090444112150283, 0.508847739044676, 0.5087627404499021, 0.5087438654050602, 0.5087256420220674, 0.5086218606728966, 0.5086179089613023, 0.5085769238944059, 0.5085450117149115, 0.508523449921715, 0.508479904377342, 0.5083805367836427, 0.5082958300577027, 0.5080957545004161, 0.508057105520331, 0.5079432617458511, 0.5078582580120868, 0.5077754160390312, 0.5077736701579284, 0.5077095299732348, 0.5076192965720013, 0.5076030884247676, 0.5075895874797759, 0.5075467875108596, 0.5075018476156757, 0.5072811217995764, 0.5072689733737397, 0.5068452998732036, 0.5067862849918361, 0.5067441763988171, 0.5067298535867966, 0.5067044033785918, 0.5066985410986039, 0.5066594613317134, 0.506606554688727, 0.5065870850403089, 0.5065502505977489, 0.5065144471065208, 0.5065053081847404, 0.5063377962898902, 0.5061839413780811, 0.5061682412515083, 0.5061389981293258, 0.5061201201353875, 0.5060972760518445, 0.5060675437051612, 0.5059980965212907, 0.5059457823386927, 0.5059091312868746, 0.5058998867428686, 0.5058940239444529, 0.505856118649457, 0.5058234123492086, 0.5058163870329613, 0.505784786348742, 0.5057110986587529, 0.5057019593781528, 0.5056153914832321, 0.505542097311361, 0.5055239712980871, 0.5053626160169906, 0.505335635382416, 0.5052727882316872, 0.5052343827827809, 0.5052120674693432, 0.5051808989709595, 0.5051515294953365, 0.5051373454707846, 0.5051292040963091, 0.5050568123559591, 0.5050106216811153, 0.5049899175348792, 0.5049532380810976, 0.5049228704892239, 0.5048310895552072, 0.5048192912111568, 0.5047969722760886, 0.5047720599573531, 0.504714472005555, 0.5046356551248924, 0.5044327354710643, 0.5044309893049499, 0.5043521716139031, 0.5043481334658315, 0.504344404149685, 0.504284655487001, 0.5042711191317873, 0.5042468770332479, 0.5042373640857697, 0.5042212961883503, 0.504219995891646, 0.5042167459499107, 0.5041815619635411, 0.504163215804498, 0.50414983612389, 0.5041460234565553, 0.5040762667771971, 0.5040671269121276, 0.5040034417784265, 0.504002402864928, 0.5039622029034209, 0.5039262135489719, 0.5039146485141589, 0.5039128270556246, 0.5038807301491403, 0.5038322442004551, 0.5037965871443255, 0.503625589754826, 0.5035806420144315, 0.5035650502785248, 0.503559865450895, 0.5035487532327061, 0.5034827499472829, 0.5034434560139478, 0.5034250602286567, 0.503417874538895, 0.5034013416837563, 0.5033646358956176, 0.5033615632881333, 0.5033184831999284, 0.5033166152181783, 0.5032768799151506, 0.5032637015539528, 0.5032200660846164, 0.5030607027056989, 0.503043964160357, 0.5029826007963776, 0.5029386655622291, 0.5029365704177623, 0.5029179600553725, 0.5028295027554142, 0.5027960861999952, 0.502777205955001, 0.5027659538903366, 0.5027424731712259, 0.5027279705743115, 0.5027212785411408, 0.5026983845464813, 0.5026551680204906, 0.5025808491676306, 0.5025723080592673, 0.5025675031296946, 0.5025611955723758, 0.5025516023858166, 0.5025190803559708, 0.5025131739877906, 0.5024845504519156, 0.5024343521454189, 0.5024339033298041, 0.5024224673440966, 0.5024137805512103, 0.5023992152820778, 0.5023864656767721, 0.5023814374171203, 0.5023532954936879, 0.5023496392494287, 0.5023290521676365, 0.5023095296511383, 0.5023062815234404, 0.5022893159846381, 0.502280175704275, 0.5021973151399322, 0.5021331225309104, 0.5021232284456822, 0.5021095569162719, 0.5020563953226109, 0.5020452435996328, 0.5020083732949249, 0.5019926360875937, 0.5019791440107384, 0.5019489994617486, 0.5019303887415459, 0.5019138135186507, 0.5019060455802776, 0.5018557298768067, 0.5018085126105947, 0.5017728930668621, 0.5017692394002334, 0.5016986981297945, 0.5016675919462243, 0.5016530330214028, 0.5016471945817639, 0.5016468859566168, 0.5016420095470128, 0.5015957595678603, 0.5015640245853635, 0.5014878311892789, 0.5014784756526457, 0.5014767185071991, 0.5014762988289395, 0.5013619017230533, 0.5013608813824948, 0.5013532226782096, 0.5013060977526596, 0.501192794435725, 0.5011522582675046, 0.5011455386184593, 0.5011121094815113, 0.5011103523293983, 0.5011030919628066, 0.5010909521983776, 0.5010186926201191, 0.5010090888709041, 0.5010050504335235, 0.5010013208505814, 0.5010000816956756, 0.5009963517779563, 0.5009713195900419, 0.500965776872992, 0.5009629342932453, 0.5009262269557019, 0.5008977527816371, 0.5008645132988476, 0.5008384673774683, 0.5007853050013337, 0.5007831571831043, 0.5007645988339929, 0.5007372822915279, 0.5006728340025376, 0.5006592966803959, 0.50064330746543, 0.5006401232965555, 0.5006337140437365, 0.500500240563954, 0.5004981453492522, 0.50049030720746, 0.5004891277950868, 0.5003656310672931, 0.5003572230851808, 0.5003458867489032, 0.5002763895420423, 0.5002717339356407, 0.5002167342967603, 0.5002152253060014, 0.5002056215189976, 0.5002052018371491, 0.5001866010597932, 0.500183284304828, 0.5001227593023745, 0.5001158294674921, 0.5000821247112008, 0.5000660377928736, 0.5000610454497043, 0.5000360750791035, 0.5000349994530281, 0.5000214953911071, 0.4999959127116843, 0.4999796891132284, 0.49994271626204057, 0.49992457074382246, 0.499890610345945, 0.49987691931302464, 0.4998471936561748, 0.4998417328476833, 0.4998296132159121, 0.4997912230695054, 0.4997770045949624, 0.4997684501394817, 0.49974968799700026, 0.4997289817855467, 0.4997120987372487, 0.4997008105099957, 0.4996946768416833, 0.4996461195923458, 0.4995972421185651, 0.4995934129796307, 0.49955839308052896, 0.4995105508206008, 0.4994937288661646, 0.4994919398388275, 0.49945648357873823, 0.4994448514194674, 0.4994227910689198, 0.49939001782012377, 0.4993746868341623, 0.4993696286301392, 0.49935521980835307, 0.4993489224470599, 0.4993344422211059, 0.49931190771846556, 0.49930647565352326, 0.4992748870535168, 0.49922914007128055, 0.49922197121756057, 0.49921802731833165, 0.4992084339047469, 0.49919244470353824, 0.4991783007413032, 0.4991759111235747, 0.49910239475053636, 0.49909453085196187, 0.49909304914631275, 0.49909118108848094, 0.499087142648119, 0.4990784439869799, 0.49905604352482474, 0.49904740575583784, 0.4990450264916608, 0.4990436761714726, 0.49900831916221255, 0.49899209562861446, 0.4989466055655652, 0.49887621775722973, 0.49886739743095804, 0.49886371945499536, 0.4988596007790842, 0.4988566556651489, 0.4988466913220749, 0.49884427678234705, 0.4988115538304875, 0.4987899465420761, 0.4987543406067546, 0.4987475366605252, 0.4987354598942619, 0.49870708483563725, 0.4987033552626915, 0.498692512387649, 0.49869026297847135, 0.49866496882310357, 0.49864138582472084, 0.49861932561142125, 0.49860582165343575, 0.4985998827839293, 0.4985802391765753, 0.4985797903539434, 0.4985706354658295, 0.4985170212471418, 0.49848576104103937, 0.4984513919479867, 0.4984393180612163, 0.49843520107147704, 0.49842971436665706, 0.4984260606903074, 0.498408984031858, 0.4984071800481887, 0.4983613330962275, 0.49834685300208015, 0.49832614701419453, 0.49828771807100736, 0.4982590941615075, 0.498252580807313, 0.4982416718611543, 0.49823842148222985, 0.49823438307870904, 0.49822084590264654, 0.4982022786441889, 0.4981883234559305, 0.49817375804215447, 0.49816000458196885, 0.498158835033768, 0.49813780210136877, 0.49811892512201733, 0.49810359433142515, 0.49808894370346857, 0.4980553035561268, 0.49805067915851525, 0.4980437494289426, 0.49804081604068123, 0.49801004519619907, 0.49800856350917005, 0.4979508807914237, 0.49791877649695615, 0.49790195481965904, 0.4978500140136321, 0.4978061782997123, 0.49780326862516094, 0.49780236348165546, 0.4977767813022118, 0.4977689348299813, 0.4977671777042028, 0.49776024800754987, 0.4976805876751439, 0.4976773875067827, 0.4976755194831336, 0.4976436834870479, 0.49763174496282814, 0.49762260469746394, 0.4975926591128715, 0.4975896296211717, 0.49758386956364364, 0.4975830555476828, 0.49756899126364174, 0.4975412502636393, 0.4975269612048849, 0.4974674873906185, 0.49744854514299036, 0.497442136668152, 0.497439988900896, 0.4974384830514379, 0.49743496798537373, 0.497433582435529, 0.4974214309973616, 0.49741655466494983, 0.4974021949890863, 0.4973703054578877, 0.4973553826639252, 0.4973478416179727, 0.4973463192047947, 0.49733857104699924, 0.4973154733326606, 0.49731125522483793, 0.497300142767775, 0.49729054961114644, 0.4972768589815505, 0.49726500612138214, 0.4972623791622945, 0.4972228910976202, 0.49719550513076277, 0.49718451339122044, 0.4971712620425177, 0.49715498492556676, 0.49712777380092793, 0.4970140673497425, 0.49701015225095674, 0.4970014719238968, 0.49695159662027416, 0.496938781769006, 0.49693120816188757, 0.4969211970790106, 0.4969167998620041, 0.4969115416705152, 0.49691050273007975, 0.4968720748318042, 0.4968587176452465, 0.4968490618625429, 0.4968434517114777, 0.49684095250658245, 0.4968364700911359, 0.49682277960792537, 0.49680391773933924, 0.4967892159355866, 0.4967813696320329, 0.49677961254409425, 0.49677588310103477, 0.49676021312871127, 0.49675811799994524, 0.49673950778654286, 0.49673897965821917, 0.496737498010759, 0.4967235192276993, 0.4966879563307161, 0.4966723191043575, 0.4966527714229654, 0.4966450154697411, 0.49663504273431697, 0.4966241277769407, 0.4965987553673678, 0.4965929283623932, 0.4965082021055445, 0.4965050128449753, 0.49647812092181676, 0.4964767196831031, 0.49643781746598054, 0.49643387375755466, 0.49643085150458066, 0.49642684982971236, 0.49640829238884204, 0.49640529626576696, 0.49638274946940675, 0.49638107811869286, 0.49636782704458143, 0.49635622840623544, 0.4963515502664658, 0.49634063539603507, 0.49630468091100954, 0.4963036763541027, 0.49629499432315893, 0.4962859349460063, 0.496255909750663, 0.49625515974364137, 0.49625412082184917, 0.4962409873816865, 0.4961710990915118, 0.49616743443380584, 0.49616391948207794, 0.4961302372378962, 0.4961133703559052, 0.4961080508766066, 0.4961017388875559, 0.49602652065363906, 0.4960068546648704, 0.49600581575106434, 0.49600093960027913, 0.49599133642740434, 0.49597307142970765, 0.4959688033400908, 0.49595469212922977, 0.49593582966897354, 0.4959336529701629, 0.4959261714242211, 0.495922958923539, 0.4959170204031093, 0.4959094262599231, 0.4958690276383636, 0.4958567357751586, 0.49585590982092176, 0.49584934805511705, 0.49584676997898364, 0.4958060643169509, 0.49580551473326645, 0.49579715993605716, 0.49577057859916934, 0.495759562316627, 0.49575144082374034, 0.49574074712840693, 0.4957285074418459, 0.4957204725500187, 0.49571651521785004, 0.4956805650363716, 0.4956747018605449, 0.4956652351752343, 0.49560859393510903, 0.49559448289579405, 0.49557956084917304, 0.4955719501102755, 0.4955655549746817, 0.4955171554514163, 0.4955135827883189, 0.4955036191967202, 0.4955033116358699, 0.495501204839488, 0.49550026179003975, 0.4954905900945827, 0.4954867324220196, 0.4954739022094357, 0.4954524964521424, 0.4954502879238368, 0.49543757448152975, 0.49542972850807426, 0.4954089526290132, 0.49536402351811465, 0.495361179654878, 0.4953403929226222, 0.49533818708937954, 0.49532191086838734, 0.49529254754780716, 0.495268386168387, 0.49526659729948214, 0.4952383863254413, 0.4952371881309138, 0.4952269281806408, 0.4952239873529198, 0.4951668064705054, 0.49513574352987755, 0.49513428666382425, 0.4951258516263493, 0.4951043582362448, 0.49509627893178404, 0.4950837393598926, 0.49501952515127684, 0.4950183007894345, 0.49501443032328946, 0.4950134248116395, 0.49500382198000387, 0.4949966538259043, 0.49499272066263583, 0.4949897246855001, 0.49498311783895643, 0.49495590490863767, 0.4949386593116399, 0.4949250669901322, 0.4949170744410795, 0.4948794281863962, 0.4948771681333402, 0.49486922618732976, 0.49486183873815537, 0.4948592607566473, 0.4948489713493826, 0.4948403455758211, 0.4948385567372197, 0.4948307428117102, 0.4948197269188887, 0.49481582120228146, 0.4947759150611472, 0.4947717982002556, 0.4947089367641431, 0.49469781348267416, 0.4946953220609112, 0.4946930620252121, 0.49468948323835543, 0.49468719907248104, 0.49468618262030306, 0.49467489007708737, 0.49463557226102145, 0.4946230522674247, 0.4946069831873623, 0.4945920617192115, 0.49458627938846855, 0.49458419298672107, 0.49457578598820484, 0.49457135793369184, 0.4945478302198943, 0.49452907260416173, 0.49451370877595835, 0.4945127657637114, 0.49449452530844296, 0.4944650023192443, 0.49445761991481135, 0.49445241415040475, 0.49444172071365433, 0.49444119262814223, 0.4944338053142806, 0.4944228912163264, 0.4944153453756524, 0.4943881675461354, 0.4943845142942249, 0.4943720175081384, 0.494337621830593, 0.49433442200393457, 0.4943007215996277, 0.4942778703368604, 0.49426178137815285, 0.4942497027566369, 0.4942494694994144, 0.49418150058655524, 0.49417895454600713, 0.49415002830480426, 0.4941496021658032, 0.49414680560486535, 0.49408809615545807, 0.4940736179337371, 0.49406208709539934, 0.4940398863242974, 0.49403697643872196, 0.49402737401817043, 0.49402695439613936, 0.49402100818415073, 0.49401593889838596, 0.49401245294377016, 0.49399930761583083, 0.49399564327118983, 0.49396843152856995, 0.4939375949630459, 0.4939336406247798, 0.4939296027658839, 0.4939263213967738, 0.4939038951879867, 0.49389967753278985, 0.4938989844572147, 0.49389195817545206, 0.4938896982226638, 0.4938823506746876, 0.4938528773044717, 0.49385259420704963, 0.4938510885457816, 0.49384758825247366, 0.4938432749696333, 0.4938322595701527, 0.49382835402869113, 0.4938196910494906, 0.49381584385924865, 0.4938027752631282, 0.49378844968399066, 0.4937867216905235, 0.49378487104635754, 0.4937584724838548, 0.493725714905289, 0.4937245575222759, 0.4937187861624352, 0.49368061903047783, 0.49367679585655894, 0.49366187503978576, 0.49365858473038654, 0.4936129325434944, 0.49359882271998684, 0.49358832980990885, 0.49358390196250784, 0.4935810331232069, 0.49356762700872087, 0.49354575126799816, 0.49354161861857765, 0.49349808570549064, 0.4934537428143394, 0.49344635585394353, 0.49341856241012094, 0.49341526199168523, 0.4934042468327392, 0.4933653051710731, 0.4933294744686189, 0.49331327858088037, 0.4933038127647674, 0.4932536378116728, 0.49321932732236407, 0.49321812522762215, 0.49321590889917744, 0.49319151754367546, 0.49318492468185776, 0.4931815079415089, 0.49318024441087205, 0.4931708151776601, 0.49314141722639354, 0.4931353027537725, 0.4931303065410248, 0.493113612377784, 0.49310151431501276, 0.4931009539671533, 0.49309679360541614, 0.493086186230501, 0.4930565983361009, 0.4930495465993335, 0.49303994466898354, 0.4930325627907351, 0.4930250243577464, 0.4930074384836725, 0.49299944667500745, 0.4929978365758922, 0.4929458365603588, 0.4929430137405172, 0.49292470419238577, 0.4929230605208866, 0.4929221752082373, 0.4929177475200708, 0.49289776088901005, 0.4928949288174907, 0.49289085968896773, 0.49271890520460965, 0.49269767535278564, 0.492696193958376, 0.49268083157102316, 0.49266868312514256, 0.492614034724831, 0.4926119503225738, 0.49260104362767054, 0.4925937563523876, 0.4925802219818793, 0.49256044450925995, 0.49255164934233464, 0.4925145371052584, 0.4925140090728544, 0.4925087556644526, 0.4924315294266255, 0.4924311656278343, 0.4924278653939264, 0.4923816335199609, 0.4923777672854853, 0.49237444033366123, 0.4923738105833274, 0.49235889085268253, 0.4923506322479155, 0.49234764107409773, 0.49234421764895653, 0.4923378661443304, 0.4923320039083325, 0.4923216310471336, 0.492310314546909, 0.4923056927557963, 0.49228812884407114, 0.49228322574071326, 0.4922668836959177, 0.49226139937980123, 0.4922533031864721, 0.4922531988662987, 0.49225179789447937, 0.49223687827591917, 0.4922129031135673, 0.49219412463192685, 0.4921656443234662, 0.4921540362392076, 0.49214792212190495, 0.49213490812009936, 0.492133335134216, 0.4921135753368195, 0.4921094152181431, 0.4921072571838762, 0.49209491530963656, 0.49209447331934103, 0.49209343459901894, 0.4920828026569726, 0.4920787880351638, 0.4920747505954977, 0.49206054996459325, 0.4920120740140646, 0.4920104640102911, 0.49200318687273265, 0.4919455108699105, 0.49194108260400354, 0.4919317231106899, 0.49192530687578273, 0.4919141063302974, 0.49180820846058665, 0.49179313589494, 0.491761756100094, 0.4917149552693634, 0.4917108489245923, 0.4916813304803527, 0.4916501382991484, 0.49163117452646443, 0.4916246011978052, 0.4916241328634891, 0.49158305970351995, 0.49158249677127525, 0.4915745056650623, 0.4915389903991936, 0.49153460658688836, 0.49153088081655355, 0.49151733365092726, 0.49150109077458914, 0.49149779073804445, 0.49149570448553603, 0.49147959805805996, 0.4914499437202438, 0.4913904329598503, 0.4913821322371747, 0.4913611346285619, 0.4913548235642454, 0.49135053438343546, 0.49134695626462205, 0.4913446725253063, 0.49134259964093746, 0.49132298456429885, 0.49128886014571976, 0.4912808810063728, 0.49128053775637376, 0.49127407256913647, 0.49126587258925325, 0.49126447170865034, 0.4912640641605586, 0.49125730502773796, 0.49124955306245893, 0.4912448104883626, 0.49124377182687523, 0.491237407037434, 0.4912288532023158, 0.4912140615657608, 0.4911899937327487, 0.4911889550752631, 0.49117968232611214, 0.49115274908408924, 0.49114601671751096, 0.4911225179332399, 0.4910987128382626, 0.4910914732330892, 0.4910654965175261, 0.49103658806416367, 0.49101981610880463, 0.4910158771193271, 0.49096061164509797, 0.4909585274693522, 0.49095377703172105, 0.49092228613895106, 0.49091933670851595, 0.49083792721799785, 0.49083652638032654, 0.4908284598721702, 0.4908167072938079, 0.49079763533260035, 0.49078982322244624, 0.4907788098922235, 0.49071321808757995, 0.4906974862816949, 0.4906924908569959, 0.49068447357643014, 0.49065692507833086, 0.49064529697170733, 0.49064098099394327, 0.4906078580933322, 0.49059841504184354, 0.4905971763201482, 0.4905952159363808, 0.4905912624161569, 0.49058722539301275, 0.49055661343587464, 0.4905473291326352, 0.49054333169022507, 0.4905349267140503, 0.4905138156970454, 0.4905105158949964, 0.49050842979077836, 0.4905052279492305, 0.4904882873707151, 0.4904773365934657, 0.4904737810279514, 0.4904626722867996, 0.49045308234347185, 0.49042057137482514, 0.4904205284868419, 0.4904200798253462, 0.49041259428281064, 0.49039450468607354, 0.4903822231625889, 0.4903675589628296, 0.4903191121185276, 0.4903129377918108, 0.49030074795240397, 0.49029362176527724, 0.4902877356399408, 0.49026611543755, 0.4902565152922146, 0.49024328779861653, 0.49024159775876136, 0.49022062366386376, 0.4901948007058741, 0.49019088806505323, 0.49018351447797515, 0.4901779813597242, 0.49017313460823986, 0.490149604684561, 0.49013980646801036, 0.49011199493159613, 0.4901114669873759, 0.4901084968641661, 0.49010849547815827, 0.4900805086127502, 0.49007629433081074, 0.49003475263322577, 0.49002379863384843, 0.4899712921012381, 0.4899508422860715, 0.48993964250098776, 0.48992919281243164, 0.4899272507238218, 0.489923556032541, 0.4899212026839681, 0.4898943203933441, 0.48987183279896057, 0.48986968109641277, 0.4898493002615487, 0.4898296411460529, 0.48982860259587907, 0.4898222586109195, 0.4898155290724982, 0.48980219514105366, 0.4897992113389271, 0.4897915881901091, 0.48978810318962984, 0.4897690906763088, 0.4897593175509513, 0.48971732878148877, 0.4897052758094195, 0.489698848223373, 0.48969368147977343, 0.48968317029768504, 0.48967957535256224, 0.48966526339761235, 0.48966465851060703, 0.4896492996990438, 0.4896485784761974, 0.48963559266947726, 0.4896272713307603, 0.4896206496274429, 0.489617380119841, 0.4896040552475094, 0.489595394695111, 0.48958859833643387, 0.48957848365475987, 0.48957559332193984, 0.48956940898266293, 0.4895556113748254, 0.4895538131994326, 0.4895487117945873, 0.48952244519938554, 0.48951802754055446, 0.4894976073158657, 0.4894901383888434, 0.48948205338378487, 0.4894439334737816, 0.489434333969592, 0.4894333347903622, 0.4893781654879957, 0.48937470381058673, 0.48936343061287746, 0.4893626089190681, 0.4893336918671023, 0.4892773824307909, 0.4892719528549458, 0.48922100080616443, 0.4892206762243062, 0.4891833173356848, 0.4891661928394256, 0.48915890956044283, 0.48912132699839816, 0.48909872771666024, 0.48909482372417745, 0.4890933424323158, 0.48908949220604614, 0.4890891284971464, 0.4890429068508775, 0.4890413868401615, 0.48903930098673315, 0.4890366371315254, 0.4890250250889573, 0.48901242069464884, 0.4889879189112946, 0.4889834670523072, 0.48895739733874755, 0.4889524879876855, 0.48895216875212694, 0.488944622177861, 0.4889380861858988, 0.4889317918981201, 0.4889173187519717, 0.4889112061338886, 0.48886507417228425, 0.48885779288627845, 0.48885621734590234, 0.4888513680675339, 0.48884304729083466, 0.4888414573898601, 0.48883805262470564, 0.4888120686127647, 0.48880096140248286, 0.4887913727820429, 0.48876754891582885, 0.4887612547238482, 0.4887525208994031, 0.48875148244510935, 0.4887402687753872, 0.48873683963548076, 0.48873256283501404, 0.4887190124541309, 0.4887105166504031, 0.4887021959789844, 0.48869371770743464, 0.4886875338425597, 0.48867813205958643, 0.48867752722432944, 0.4886612579424449, 0.4886403881824414, 0.48863905956878145, 0.4886067991166434, 0.48859916978160867, 0.48857162605186294, 0.4885615904809974, 0.48853990737806247, 0.4885205554083368, 0.48849493785162695, 0.4884924755988984, 0.4884824461101969, 0.4884320473604131, 0.4884020727256031, 0.4884010925796279, 0.48840052446420623, 0.488387597662878, 0.4883872295209772, 0.4883755038343952, 0.488373101968544, 0.4883611502229285, 0.4883548088292822, 0.48833355966263853, 0.488291766053751, 0.4882902848695479, 0.4882654092316675, 0.48826458761863395, 0.4882481917487824, 0.4882261661130872, 0.4882166060224409, 0.48819149080451923, 0.4881890769774383, 0.488176571886858, 0.4881755334877891, 0.48816350860384744, 0.48815391020156834, 0.4881496937117773, 0.48814953535526023, 0.48813503998517127, 0.48811926841556685, 0.4881131272717171, 0.4881081619160434, 0.4880891522302953, 0.4880703423185309, 0.48805475262239284, 0.48805459929906625, 0.48804730560701154, 0.48804140240700294, 0.4880400081217336, 0.48801480101783345, 0.48801306788011917, 0.4879847356825726, 0.4879251745566676, 0.48792414155000624, 0.48791268348725286, 0.48790955947834225, 0.48789857382470314, 0.4878956839295697, 0.4878756440279809, 0.4878708793291864, 0.48786705000319625, 0.48786430897327887, 0.4878258371533601, 0.4878203900357332, 0.4878103842336476, 0.4878043192202357, 0.4878030003992081, 0.48776443257751606, 0.4877213339902961, 0.48771515069313376, 0.4876833501671065, 0.4876742164768437, 0.4876243955364891, 0.4876121341352069, 0.4876115623119501, 0.487602777958021, 0.4875975188004077, 0.4875650510921416, 0.48754250274907923, 0.48752319416799106, 0.487513626826798, 0.48750435332507064, 0.4875024295044771, 0.48749631770275853, 0.48748721877215995, 0.4874418649442709, 0.4874364876503586, 0.4874231739963474, 0.4874136146541382, 0.48741350764036884, 0.4874047596588097, 0.48740245672741817, 0.48738608776760145, 0.48737279333821615, 0.48735267979250435, 0.4873509237561328, 0.4873258037886095, 0.4873219746698583, 0.4872838726374373, 0.48727758385508835, 0.487258276076146, 0.48724064709912895, 0.4872391660673931, 0.4872296069036393, 0.4872275067486958, 0.487188980532795, 0.4871876224087991, 0.48717799566844816, 0.48717651464621364, 0.48717348707741337, 0.48716978891141616, 0.487166917179294, 0.48713846170959635, 0.4871211733619173, 0.4871126245839491, 0.48711158629414814, 0.48708776629104716, 0.48707908509225867, 0.4870753041632149, 0.4870631735299123, 0.48705706200155957, 0.48705302625472113, 0.4870492991581677, 0.48704692365457547, 0.4870149937197116, 0.4870083676992966, 0.4870053964129893, 0.487000523245625, 0.4869977592657267, 0.48699723463214584, 0.4869866489641679, 0.4869776564974529, 0.4869742556560046, 0.48694683701926034, 0.4869462895567058, 0.48692259051301795, 0.48691160595202365, 0.48688655576702305, 0.4868746006637361, 0.48683471778513404, 0.48680996345073624, 0.4868091912823336, 0.4867967930667336, 0.4867671043850552, 0.486753382273858, 0.48673912618342235, 0.48672025865169766, 0.48669338441348375, 0.4866912522401725, 0.4866335593353499, 0.4866319243443549, 0.48661518481463867, 0.4866105812420316, 0.4865997606218443, 0.4865983039969185, 0.4865782217412753, 0.4865555708078402, 0.48654647333189555, 0.48651742529292485, 0.4865155016697658, 0.4865093904954723, 0.48650110331568286, 0.4864948105359886, 0.4864809571150175, 0.4864742297094133, 0.4864709021656195, 0.4864656161878377, 0.4864553627139554, 0.48644956660068717, 0.486439157879645, 0.4864377352271897, 0.4864000431251313, 0.4863872204179732, 0.48638094837071183, 0.4863665929929468, 0.48636518803231416, 0.48636401156169956, 0.4863425321325398, 0.4863383193370715, 0.4863350654845378, 0.48633341154367055, 0.4863319573490272, 0.4863234072812956, 0.486311858767445, 0.4862840545179324, 0.4862713735352852, 0.48626527015512394, 0.48626206503301567, 0.4862541657675435, 0.48624060742889313, 0.4862372601917322, 0.4862299210645002, 0.48619434354106905, 0.4861938523374903, 0.4861297727017048, 0.4861246991765323, 0.48607764708965545, 0.48607018066006535, 0.4860616328465151, 0.4860613352439705, 0.4860537148485226, 0.48604172853700695, 0.48602149153616636, 0.4860214558842985, 0.48601852056644496, 0.48599078360991765, 0.48597009367190697, 0.48594480724409134, 0.4859362575438209, 0.4859178844308636, 0.4858898008414318, 0.48584973465004366, 0.4858303124436743, 0.48582906515551394, 0.4858228629830219, 0.48581782412413826, 0.4857872051397741, 0.48578025415522486, 0.4857588834667252, 0.48575227899071105, 0.48574362172919433, 0.4856955928045665, 0.48569325017604853, 0.48567138455693987, 0.4856523247820385, 0.48564855131022666, 0.48564244072640106, 0.48562597571286326, 0.485611472184773, 0.485604642162981, 0.4855942224266984, 0.4855907831395667, 0.48558976714286683, 0.4855859107284967, 0.4855826226255479, 0.4855763149264682, 0.48555964722012235, 0.4855502197273915, 0.485547990034347, 0.48553969882491277, 0.4855094708793154, 0.48550799012724366, 0.4854970759157078, 0.48549398026911283, 0.48548741157844727, 0.48547879901116475, 0.485471961013827, 0.48544181839403044, 0.48542114021464333, 0.48541715843643074, 0.48540735986856043, 0.4853951393782819, 0.4853943104658197, 0.4853874604285153, 0.4853649321462705, 0.4853557286563878, 0.48535279080598304, 0.48535151633196516, 0.4853466090874964, 0.48533660594467837, 0.4853269587651081, 0.48532592067984304, 0.4852680445383364, 0.4852673722012775, 0.4852657862106227, 0.48525046852837894, 0.4852339719831447, 0.48522201908555734, 0.4851516190722316, 0.4851451105985576, 0.4850865697321863, 0.48507657180127306, 0.48506124816540647, 0.48505970045337793, 0.48505387577622383, 0.4850360887635339, 0.4850346887105009, 0.4850208504720741, 0.485015039115391, 0.4850140010685733, 0.48500619401505385, 0.48500461136733347, 0.48499166852570397, 0.4849495001396536, 0.4849362092988122, 0.48492632946662684, 0.48492381209195756, 0.4849189050972948, 0.48491343735009684, 0.4849071352203673, 0.48488540437962224, 0.4848423201244721, 0.48484230001253203, 0.4848396722560898, 0.4848310803958973, 0.4848227694489, 0.48481543152460216, 0.48480672821290693, 0.4848017229757247, 0.4847862066360165, 0.4847798598412197, 0.48468583864650283, 0.4846858341334503, 0.48467773456129754, 0.48467092945040874, 0.48466560035019135, 0.48466375053265737, 0.4846631826461231, 0.484660142365578, 0.484655717453832, 0.48464743204765715, 0.4846440615249922, 0.4846425812121887, 0.4846411406154185, 0.4846392543731513, 0.48462238753828857, 0.4846205641998619, 0.48461792333083714, 0.48460274758343386, 0.4846017012536245, 0.4845895994294939, 0.48457850755514614, 0.4845748016172571, 0.48457039294066245, 0.4845689129081118, 0.48452144493582905, 0.48451036978177814, 0.4844797763838059, 0.4844722597325918, 0.4844697742887825, 0.48446305392652134, 0.48445511881879705, 0.4844262631187456, 0.48441666865304267, 0.484405662289265, 0.4843977818826769, 0.48434990237359166, 0.4843392349392369, 0.4842848476270751, 0.4842838549860166, 0.4842791076900348, 0.48425698835440073, 0.4841788109696116, 0.4841724190727171, 0.4841687820769829, 0.48416544498921477, 0.48416495433766665, 0.4841619349628514, 0.48415632413612947, 0.48414981752175695, 0.48410837426723846, 0.484106516057788, 0.48409125736400255, 0.4840827095651658, 0.48407304689307973, 0.48404865602033426, 0.4840446216778738, 0.4840319367057348, 0.4840274615786742, 0.48402008089348575, 0.4840190346402693, 0.4840028058875305, 0.4840014122323242, 0.4840000213913928, 0.4839900966183001, 0.48393844942586406, 0.4839371751734608, 0.48393226878247037, 0.4839302905571099, 0.4839288860034833, 0.48392398413034704, 0.48391291329665986, 0.48391158397598627, 0.4839012265143476, 0.48388711737361256, 0.4838641136437875, 0.4838480729219845, 0.4838472484585331, 0.4838196513431552, 0.48381789602268727, 0.4837657591057589, 0.48376546158574196, 0.48376451252401753, 0.4837034426854073, 0.4836995481353023, 0.48367468702194705, 0.4836574593258754, 0.48363578805489776, 0.4836339649451025, 0.48363064524926214, 0.4836140212905312, 0.48359191358122855, 0.4835889122416071, 0.48358232014090324, 0.4835737345650847, 0.4835627293907648, 0.48355767437796676, 0.48351927329485206, 0.4835108406343329, 0.48350065894780175, 0.4834993751514639, 0.483495490981698, 0.4834931948619664, 0.4834725112408464, 0.4834300951307547, 0.48342806898014556, 0.48341270921994955, 0.48332684179229657, 0.4833263972671453, 0.48331264694388754, 0.4833057248307555, 0.48327505206847365, 0.4832716157542086, 0.48327043521373414, 0.4832604876378424, 0.4832571472134919, 0.48324592413913425, 0.4832409182183762, 0.483237455643593, 0.4832283661787448, 0.4832277286277131, 0.48321156315385205, 0.48320635317452315, 0.4832054337466512, 0.4831913878549486, 0.48318749366657177, 0.4831753940504499, 0.4831547113072161, 0.4831226897672083, 0.48306823838287305, 0.4830655911180603, 0.4830202707874636, 0.48301892592720386, 0.4830087924855254, 0.4830057921833757, 0.4830024950068044, 0.48299192455897544, 0.4829904445630934, 0.4829811398198365, 0.4829728245508488, 0.4829684322678289, 0.48296214220548256, 0.4829591275525009, 0.48292120927639487, 0.4829167920673384, 0.48291061226213605, 0.4828951667368994, 0.4828899302631062, 0.4828620343335988, 0.48286074853864064, 0.4828331550554979, 0.4828313999662625, 0.4828276747666184, 0.4828022372430216, 0.48277897244785434, 0.4827645807094936, 0.48275829082313765, 0.48275082748613324, 0.48273771946762756, 0.4827363644829954, 0.4827291099136573, 0.4827252752986849, 0.4827153670312344, 0.4827011455190938, 0.48269161470956723, 0.48268905965125103, 0.4826406592814981, 0.4826275522565941, 0.48258369606122203, 0.4825608356986879, 0.4824855134403345, 0.48248304245847196, 0.48245796335700125, 0.4824306948579433, 0.4824046839761461, 0.48240383486712446, 0.4823149358431593, 0.48230880505649715, 0.4823053440757531, 0.48230053924487665, 0.48229563393960556, 0.4822856347515545, 0.4822451453605453, 0.4822419491592561, 0.4822416623768466, 0.48223381938256465, 0.4822199391594371, 0.48221642844686313, 0.4822082869972351, 0.48217436526154733, 0.48216830435539426, 0.4821659404369853, 0.4821645996068473, 0.482143919767039, 0.4821436633753436, 0.4821362872056811, 0.4821135178164136, 0.48210216127794675, 0.48208702810475007, 0.4820814920772762, 0.4820732651210106, 0.48204405522693017, 0.4820214898754267, 0.48201610899677017, 0.4820055400100105, 0.48199475676247017, 0.4819403052093109, 0.4819352536586246, 0.4819315867041264, 0.4819262058953226, 0.4818778107649553, 0.4818477436754541, 0.481846534850282, 0.48184131303400934, 0.481820634158537, 0.48181191914845684, 0.48178031224548323, 0.4817719387928523, 0.48176957500977285, 0.48175137032125226, 0.4817427619752526, 0.48173187097788867, 0.48172933692668884, 0.48167461620648555, 0.4816558037890847, 0.48163171348993106, 0.48161307742289966, 0.48159915921860574, 0.4815918900831079, 0.4815771512688942, 0.48156724266465456, 0.48156638720219286, 0.48155453766437756, 0.48153523478124466, 0.4815298542845507, 0.4815072095611516, 0.48150290785227073, 0.48149672929227344, 0.48147605146372574, 0.4814723470886459, 0.4814626066132477, 0.481462349095499, 0.481434632200595, 0.481417532995641, 0.48139020747437916, 0.4813812669391568, 0.4813623053820795, 0.48135072729021466, 0.48133042300445456, 0.4813271678961699, 0.48132387151021333, 0.48131038401458087, 0.4812993498271354, 0.48125991211844293, 0.481238189172321, 0.4812222711776408, 0.4812220132223681, 0.4812137267856282, 0.48117967278632423, 0.4811716700708395, 0.48115739895210136, 0.48115295982453365, 0.48114966352488925, 0.4810904057399302, 0.4810860146469531, 0.4810774071536987, 0.48107544495766635, 0.4810675072653028, 0.48106136880765926, 0.48105780528250114, 0.4810371288159888, 0.48090188940467204, 0.4808915851599967, 0.48088678133049917, 0.4808849589327179, 0.4808648855684853, 0.48086359986595495, 0.48083631226794826, 0.48083333432873776, 0.4808137512566322, 0.48081074335905255, 0.4807704262346854, 0.4807522106806803, 0.4807283683198691, 0.4807275302928104, 0.4807157359096071, 0.4807122220790204, 0.4806958422205431, 0.480688444935867, 0.480687429611566, 0.48064894030330446, 0.48063035114598274, 0.4806090489990177, 0.4806071866171024, 0.48060570713573014, 0.48060570684974663, 0.48058370249781596, 0.4805813279460688, 0.4805598282318947, 0.4805567107208938, 0.4805484251283811, 0.4805356863890853, 0.480521572639024, 0.48048988558070593, 0.4804761852718343, 0.48042686683321223, 0.48042656945562895, 0.4804237591358985, 0.4804144584345011, 0.48040697757840645, 0.48039614771149836, 0.4803951153318371, 0.4803925195788543, 0.4803799222922577, 0.48035567144361724, 0.48034738611199174, 0.48034531445855755, 0.4803410244686338, 0.4803377285818385, 0.4803186011135283, 0.4803156999196161, 0.4802653985961339, 0.48023784805853686, 0.48023407737697343, 0.48021705183298563, 0.4801994654771034, 0.48019504853805417, 0.4801797419633277, 0.4801618945264681, 0.4801337362182604, 0.48011205109933025, 0.4800877646257176, 0.4800736692856255, 0.4800580725078746, 0.48005102963661783, 0.47993843488245735, 0.47991361823287026, 0.4799121616577694, 0.4798988832340445, 0.4798515286972745, 0.4798506768475687, 0.47985024411432065, 0.4798276866085382, 0.4798246791786299, 0.4798209556542304, 0.4798109602215427, 0.47979427287081333, 0.4797841108790507, 0.47978149614395627, 0.47976698144428587, 0.47976615561521213, 0.4797604850831202, 0.479739448564452, 0.4797175567669793, 0.47971480822220974, 0.47970901438700997, 0.479702399831068, 0.47969310020164124, 0.4796910872105768, 0.4796876673410745, 0.4796725182359591, 0.47966727144959387, 0.47965049192265063, 0.47964431514381195, 0.4796236432803992, 0.47962218677377233, 0.4796211542519808, 0.4795923379993877, 0.47956240200837946, 0.4795568764052762, 0.4795401680396615, 0.4795203562169723, 0.47949835539610053, 0.47947150742284805, 0.47944568507352886, 0.4794405655944677, 0.4794377557202816, 0.4794241561843199, 0.47941989442186683, 0.4794065211201165, 0.4793973085391546, 0.4793928921736747, 0.4793858500636139, 0.47936139482833723, 0.47935069832133154, 0.47930247513549806, 0.47930232254647387, 0.4792887199265772, 0.47927105898600764, 0.4792618728833255, 0.47924810417745467, 0.47924642054030164, 0.4792404155042527, 0.47923372016961496, 0.47921922389908395, 0.47919231874952906, 0.4791821092018234, 0.47918035540466125, 0.47917031912319435, 0.47916794511258154, 0.479160569714063, 0.4791552626351531, 0.479126097488688, 0.4791187087014598, 0.47910174138409334, 0.47910052451339663, 0.47908961875821443, 0.47907899685907424, 0.4790521507556728, 0.47903769593861234, 0.47903725826850807, 0.4790277017967257, 0.47901137123878945, 0.47901041235328246, 0.47898248552090616, 0.4789811147189926, 0.4789791799770648, 0.4789065029683879, 0.47888864062253245, 0.47879291873793994, 0.47877545300511737, 0.4787643906870647, 0.47875355549556753, 0.4787486082787731, 0.4787455434965647, 0.4787274573788439, 0.4786866361583318, 0.4786813902350862, 0.4786773375623714, 0.4786694467075909, 0.47863776925134044, 0.4786315316724003, 0.4786025564164511, 0.478596780276937, 0.4785744723574437, 0.47857166289267783, 0.4785614955616776, 0.47854983663218376, 0.47848895344771875, 0.47848565856780334, 0.47847430003055386, 0.4784740132554718, 0.4784353475166363, 0.47843169162336063, 0.47842812628447073, 0.4784114720281703, 0.47840481656969136, 0.4783958057922479, 0.47834729313589425, 0.4783452392065713, 0.47834420217540446, 0.478319464186489, 0.47830987846264456, 0.47829583466340625, 0.4782852435784129, 0.47826720144771534, 0.47825514823790216, 0.47825410166142174, 0.47819630873833135, 0.4781920992169638, 0.4781728759419611, 0.4781645936156493, 0.47814702767193923, 0.47813317053340476, 0.4781316018457185, 0.47810854999456215, 0.4780722004977871, 0.4780668183594227, 0.47806167912735037, 0.4780580949824614, 0.4780550954092992, 0.4780519198705205, 0.4780438682787892, 0.47804192742301577, 0.4780246409126447, 0.47798952252167176, 0.47798082159419125, 0.4779727477726741, 0.4779687447121114, 0.4779480787339697, 0.47786834542598033, 0.4778579844844765, 0.4778452923539309, 0.47783335202286004, 0.47782734844633246, 0.47782065473947416, 0.47781540960808994, 0.4778113575472487, 0.4777708301145083, 0.47776905633645034, 0.47776288154052904, 0.47774221631754016, 0.47771625521268735, 0.47769987986226525, 0.4776837335925867, 0.4776619915224446, 0.477651517846021, 0.47764829428669675, 0.47762467839110956, 0.4775887756522819, 0.4775859666740255, 0.4775686343968147, 0.4775681110734323, 0.47749893709139585, 0.4774883339853558, 0.4774039892737888, 0.4774014177007732, 0.47738801222961824, 0.47737697578805005, 0.4773686006098828, 0.47735969133222034, 0.4773501376620855, 0.4773493021659145, 0.4773418565506125, 0.4773339237956545, 0.47732170511151545, 0.4773101865129132, 0.4773038017859784, 0.47730356425974935, 0.47729556017716823, 0.4772890394009228, 0.4772769640169565, 0.4772684608360143, 0.4772518101179245, 0.4772440956700961, 0.4772141266868742, 0.4772064692997891, 0.4771684093823094, 0.4771614057033646, 0.4771587609291217, 0.47711568014001454, 0.47709796326543696, 0.47706828007146457, 0.4770590203049768, 0.4770456521115917, 0.47703702890983374, 0.47701952038944895, 0.4770188248551573, 0.477014082903676, 0.4770039284559559, 0.4769238784017396, 0.4769210697640119, 0.47690821026172153, 0.4768970425045015, 0.4768724138715641, 0.47686199133052803, 0.47684778581702775, 0.476829846615415, 0.47678258708039667, 0.47675666645878456, 0.4767342331658671, 0.47671776622940687, 0.4766593628549811, 0.47664532324008246, 0.47662323389125616, 0.47660360268780744, 0.47659253296948006, 0.4765767683926084, 0.4764932670501815, 0.47649277070199225, 0.4764750044267184, 0.4764697269909447, 0.47640920585572316, 0.47640270044032823, 0.4763923505493119, 0.476389542190967, 0.4763805743455156, 0.4763646588789878, 0.47636270741866005, 0.47631322256718733, 0.47626656119799643, 0.4762586363188021, 0.47620184045164576, 0.4761807725427759, 0.4761515005169618, 0.4761382108322, 0.4761278614621226, 0.47611787254595833, 0.47609869335225447, 0.47609189200691276, 0.4760918719224984, 0.47607805328581726, 0.47605178962695543, 0.47604873747023785, 0.47598836114182513, 0.4759820936676969, 0.4759763036718424, 0.4759466529587449, 0.4759345884254763, 0.47591954624671196, 0.4759178200442591, 0.47591164737043756, 0.4758909892536054, 0.4758499700752293, 0.47584866737636383, 0.47579721333328323, 0.47579709959958444, 0.47575034699596713, 0.47573997978075466, 0.4757267381872274, 0.4756999140101493, 0.47569617400164066, 0.47569163547082005, 0.47563748136648504, 0.4756335917511526, 0.4756331458314976, 0.475618226997928, 0.47559143336476306, 0.4755903948856478, 0.4755899951298016, 0.4755698838370697, 0.4755670759235694, 0.47552946149798936, 0.4754741225759787, 0.4754379697637681, 0.4754278105563754, 0.47541739841985065, 0.4754149222703719, 0.4753863944175274, 0.47535542867433755, 0.47535237494374416, 0.475332264591394, 0.4753054368731769, 0.47529544955691494, 0.47524942887340915, 0.4752469609182734, 0.4751757362805806, 0.4751529594232468, 0.47514261204481095, 0.4751219570468993, 0.4749968723919348, 0.4749954115868184, 0.4749944907310648, 0.4749579113522952, 0.47494937635721196, 0.4749057856514483, 0.47486482517993955, 0.47481702941596154, 0.47481124711738987, 0.47475707357110275, 0.474752776949517, 0.4747259523445234, 0.4747156058542847, 0.4746901430619524, 0.4746859724717689, 0.47466819789116077, 0.4746639911755394, 0.4746048503844381, 0.47458474304979886, 0.47458193568917656, 0.4745804615511974, 0.4745640903757057, 0.4745309210777656, 0.4745223868209823, 0.4745119690531772, 0.4745075746336912, 0.4744883732548558, 0.4744412185645323, 0.4744153886221911, 0.4742996968740049, 0.47426722386421577, 0.4742618841227541, 0.4742579955823194, 0.4742525932859623, 0.4742412328170897, 0.4742225208643665, 0.4742214750916871, 0.4741646209725032, 0.4741595203300261, 0.47415497817407154, 0.47413690524379426, 0.47411649369337916, 0.4741006370804774, 0.4740840074632274, 0.47407454695612183, 0.4740634523475742, 0.47400950445886886, 0.4740094645397891, 0.4739987989790145, 0.4739834748831102, 0.47396856102279505, 0.4739571002912684, 0.4739174270222034, 0.47386265143459716, 0.4738521246730767, 0.47376779967824323, 0.47374098053067915, 0.47372347373648793, 0.4737099871305353, 0.4736948262599995, 0.47367903198933636, 0.47354079441740826, 0.4735374566074818, 0.4734591907552942, 0.47344768947408505, 0.4733993677626977, 0.47333742371353954, 0.4733182185738006, 0.47329993637018947, 0.47327311988801957, 0.4732727183479095, 0.473271682336706, 0.47321700567698394, 0.4732122613043929, 0.4731665988590122, 0.4731636797346608, 0.4731586338318776, 0.47315073890219456, 0.4731350388513385, 0.4731087439469173, 0.4730965626747288, 0.47309363450603414, 0.4730673006546159, 0.47302733467584096, 0.47302512804628255, 0.47301464941376353, 0.4730036262303334, 0.4729930840828383, 0.47298717167547333, 0.47293628539192933, 0.47291478325276926, 0.4728985833970065, 0.47287785829287104, 0.47287309419706447, 0.47286733374633666, 0.4728654879572248, 0.4728620328444578, 0.4728462801876749, 0.4727983466956267, 0.4727252261973271, 0.4727008470514918, 0.472672344347395, 0.4726280021857696, 0.4726087954140503, 0.4725541266308899, 0.4725454755238107, 0.4724890873981868, 0.47248354295693007, 0.4724176317645494, 0.47241467293104755, 0.4724087520959283, 0.4724080572117424, 0.47233354113670595, 0.47233159129433094, 0.4723080064684934, 0.4722870148982494, 0.4721867492566224, 0.472150400870544, 0.47203594301392215, 0.4720300375087776, 0.47196058168531313, 0.47195069877913753, 0.4719455103373265, 0.4719292794016041, 0.47191282875317747, 0.4719038302269652, 0.4718887744243074, 0.4718809085187165, 0.4718617049427004, 0.47186026783795615, 0.47180202980665215, 0.47177197080958716, 0.471766457603283, 0.47175047422582733, 0.47174725452443045, 0.47173475750761745, 0.471723666907112, 0.4717163036527461, 0.4717132613108783, 0.47168780720960857, 0.47168520275117454, 0.47165403259191147, 0.4715980766168493, 0.4715098221306102, 0.4714990474536434, 0.47148728559082165, 0.4714862416736808, 0.471456045785491, 0.47142357843336274, 0.4714209741320363, 0.47134160594852753, 0.47132807240565977, 0.47123926272544436, 0.4712167899939144, 0.4711228699680185, 0.47111368639010515, 0.47108791849308274, 0.47108214087264677, 0.4710254071402931, 0.4710237180658661, 0.47099691522310805, 0.4709263751840527, 0.47087591177816257, 0.47083498722243455, 0.4707814562210569, 0.47076610748989245, 0.4707595298149571, 0.47073934181854976, 0.4706962365595075, 0.4706732126800674, 0.47053451777366406, 0.4704928512469418, 0.4704599115898442, 0.47044352035944564, 0.47040911940427066, 0.47036075758034473, 0.4703053860313207, 0.47027771489414294, 0.47025549405206396, 0.4702286960642003, 0.47022049240622515, 0.47021194834133095, 0.4701673979698338, 0.47010270421996764, 0.4700979632071944, 0.4700873214394346, 0.47007539987217234, 0.4700178352365954, 0.4700127573871603, 0.47001015394939216, 0.4698644436846657, 0.46983633154325116, 0.4698231919201212, 0.4697973487719252, 0.4697728242256346, 0.46977124531954834, 0.4697197143071532, 0.4696722139641341, 0.46967143369825043, 0.4696253615519412, 0.469590353691896, 0.4695504685239795, 0.469435947146766, 0.4694341235167038, 0.4694191274799649, 0.46940733086005193, 0.4693708504198741, 0.4693688877651219, 0.4693489314461074, 0.4692447195593666, 0.4691382976608014, 0.46910676709381127, 0.46909571588028026, 0.4690683268531235, 0.4690483720171902, 0.46902622988101994, 0.4690084433619814, 0.46900190796514757, 0.46898649025659317, 0.4688524494507283, 0.46883931301034737, 0.4688247881371402, 0.46881827929132075, 0.4687775091909896, 0.46873586050992744, 0.4687132032476707, 0.46868759164697704, 0.4685979255640363, 0.46838708191012707, 0.46838511973790825, 0.46838047252023823, 0.4682567621034298, 0.4682471970347734, 0.46820262914672656, 0.4681498478142673, 0.46812306378427243, 0.46810776461867787, 0.46808463308011633, 0.4680646476651231, 0.4679972013587442, 0.4679751542908258, 0.4679666309137557, 0.4679587718963192, 0.4679245458581873, 0.46792323168283956, 0.4678868887211435, 0.46787172451062625, 0.4678519359998294, 0.4677235257107525, 0.4676967446228705, 0.46769478279836557, 0.46765831814445613, 0.4676143494367762, 0.46739695136789755, 0.467394349641337, 0.46706059061448957, 0.467055853240098, 0.4670405543045562, 0.46701377801146055, 0.46697535841965265, 0.4669707129028395, 0.46694771049175293, 0.4669082945363725, 0.46689946393779325, 0.4668857320580099, 0.46686855002527455, 0.4668374862995204, 0.46667498224147974, 0.46665067509602887, 0.4666086044106585, 0.46657357503678165, 0.4664831734140924, 0.4664423714188738, 0.46644032345031605, 0.46635046065224556, 0.46631204788674874, 0.4662852768187301, 0.4662042532121474, 0.4661982679575043, 0.4661116204461045, 0.46607267503468214, 0.4660501349800444, 0.46598495646914595, 0.465873274770893, 0.4658543659603079, 0.46584845474653086, 0.4658477609916508, 0.4657276664137799, 0.46566760455979156, 0.4656465883914532, 0.46559153915987195, 0.46547625518869135, 0.4654593567404038, 0.4653827627155752, 0.46532442489282005, 0.46530230449270293, 0.46529384083227165, 0.46527466915522847, 0.4652153191727902, 0.46519554479396835, 0.4651886388020476, 0.4651644952594341, 0.46511027317230397, 0.465101061168971, 0.46500453107635636, 0.46497776967262977, 0.4648744235070295, 0.4646240449169238, 0.46457422087419636, 0.46453255911680147, 0.46452404571554645, 0.4644657220176491, 0.46443896470345386, 0.46440003748210323, 0.4642858058746136, 0.4642238730616604, 0.4642085860902834, 0.4641818307497521, 0.4640009049166703, 0.4639951574101449, 0.4636974615648673, 0.4636720665251152, 0.4635693210435801, 0.46354156155581966, 0.46351903764307906, 0.46349853819124054, 0.46345650474620476, 0.4634288840205853, 0.46336696664471927, 0.4633423044495292, 0.4632705641465878, 0.4632414745451675, 0.46320235557652784, 0.46316397706070295, 0.46315642525952905, 0.4631157817991066, 0.46299182445529746, 0.46290229867546734, 0.4628788928995952, 0.46285214799218855, 0.46281573262723946, 0.46279385278702106, 0.46257886496931844, 0.4625521224686088, 0.4624441176661023, 0.462395932791323, 0.4623163149880233, 0.46226415574788565, 0.4622202538437238, 0.4621772474601124, 0.46213370559757033, 0.46209070034732663, 0.46204420298069343, 0.4620273275856367, 0.4618819219937369, 0.46187605470557463, 0.4618701499028377, 0.4618337453705586, 0.46157829767941294, 0.461570213941722, 0.4614927556623878, 0.46147131827168325, 0.4614445848229436, 0.4613344773523977, 0.4613193413953095, 0.4612823338523023, 0.4611533132689702, 0.4611446883979956, 0.4609453771711664, 0.4609079421773665, 0.46084545894373913, 0.4606679974123073, 0.46053325786759686, 0.4605050080383068, 0.46046301306950815, 0.46045051696691125, 0.4604200302052649, 0.4603970717633718, 0.46034891752317164, 0.460183338300529, 0.46016320950190776, 0.45987357486990627, 0.4598009732995648, 0.4597095127359358, 0.4595237295805226, 0.45950123367436535, 0.4591466167432583, 0.4590984820156799, 0.4590506070843858, 0.45886189174217656, 0.4588351806636137, 0.4587923384977019, 0.45878071915365143, 0.4586791749341928, 0.4585996511788304, 0.4585540430032402, 0.4583795460713015, 0.458327862031102, 0.45820409249523414, 0.45818041377246826, 0.45811765564459656, 0.4580535511135329, 0.4580282684800372, 0.45785444065907, 0.4577498054700365, 0.4575425463006545, 0.4574775381946662, 0.4574561288766208, 0.45742943045660506, 0.45734728997782886, 0.4567264973184824, 0.456685938107347, 0.45665924680298775, 0.4564972522050382, 0.4564491608219073, 0.4563865135414427, 0.4563833081057137, 0.45635982503786604, 0.4558963745159217, 0.45578801684764153, 0.45567924149189315, 0.45563632806852483, 0.4555867984498697, 0.45537992375149605, 0.4550182791577166, 0.4547190328852821, 0.45465668106060153, 0.454316949569592, 0.45373971421016307, 0.4533377769090403, 0.45301690967283126, 0.4526773863841758, 0.45265073417473944, 0.451698822339129, 0.45167218019848115, 0.4498940003611033]], 'auc': [0.9205909005185406]}\n"
     ]
    }
   ],
   "source": [
    "print(clfutil.get_auc_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_data = clfutil.get_auc_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_data = clfutil.get_precision_recall_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [[0.2344149861807759, 0.3077337644839666, 0.33678756476683935, 0.35939730372720063, 0.3791596638655462, 0.39283842794759827, 0.40361990950226245, 0.41463871209284914, 0.4253472222222222, 0.435948361469712, 0.44615069615069614, 0.4570887673538073, 0.4671265358913559, 0.47729789590254706, 0.484643179765131, 0.49226863604892684, 0.49929278642149927, 0.5084337349397591, 0.515890613451589, 0.5160177427304091, 0.5254108723135272, 0.5252908447142135, 0.5329015544041451, 0.539560730351945, 0.5475932936722553, 0.5548209366391185, 0.5637489445538981, 0.5709332562843109, 0.5802432512607535, 0.588521105375038, 0.5883961117861483, 0.5960223741454319, 0.5962076468759714, 0.6033715012722646, 0.6110749185667752, 0.6197934021992669, 0.6258943781942078, 0.6320195326124869, 0.6379494482022072, 0.6381766381766382, 0.647080291970803, 0.6577081000373274, 0.6647619047619048, 0.6713615023474179, 0.6712328767123288, 0.6781150159744409, 0.6783859368757491, 0.6786570743405276, 0.6860655737704918, 0.6863468634686347, 0.6977329974811083, 0.7065404475043029, 0.7092260603410582, 0.7177996422182469, 0.7181208053691275, 0.7184422560429723, 0.7187639946260636, 0.7246907924874026, 0.7364960075152653, 0.7423224568138196, 0.742198751800288, 0.7449926722032242, 0.7501246882793018, 0.7577608142493639, 0.7660239708181344, 0.7736252002135612, 0.7799671592775042, 0.7824151363383417, 0.7887005649717514, 0.7885811192764274, 0.7953757225433526, 0.8039332538736591, 0.8133414932680538, 0.8160200250312891, 0.819693094629156, 0.8236446766819072, 0.8296593186372746, 0.832421340629275, 0.8385744234800838, 0.8441091954022989, 0.8509544787077826, 0.8540090771558245, 0.8592420726991493, 0.8599071207430341, 0.8640699523052464, 0.864516129032258, 0.8652138821630347, 0.8715596330275229, 0.8739279588336192, 0.8805970149253731, 0.8854824165915239, 0.8953271028037383, 0.8933717579250721, 0.8954635108481263, 0.9033570701932858, 0.9059561128526645, 0.9093851132686084, 0.912751677852349, 0.921911421911422, 0.9233576642335767, 0.9255989911727617, 0.932806324110672, 0.9398601398601398, 0.9404934687953556, 0.946236559139785, 0.9555921052631579, 0.9633507853403142, 0.9738805970149254, 0.9722772277227723, 0.9808917197452229, 0.9840182648401826, 0.9872773536895675, 0.985632183908046, 0.9899665551839465, 0.9917355371900827, 0.9943820224719101, 1.0, 1.0]], 'recall': [[1.0, 0.9973799126637555, 0.9934497816593887, 0.9895196506550218, 0.9851528384279477, 0.9820960698689957, 0.9737991266375546, 0.9672489082969432, 0.962882096069869, 0.9585152838427947, 0.951528384279476, 0.9489082969432314, 0.9462882096069869, 0.9410480349344978, 0.9371179039301311, 0.9314410480349345, 0.9248908296943231, 0.9213973799126638, 0.914410480349345, 0.914410480349345, 0.9074235807860263, 0.9069868995633188, 0.8982532751091703, 0.8903930131004367, 0.8842794759825328, 0.879475982532751, 0.8746724890829695, 0.862882096069869, 0.8541484716157205, 0.8462882096069869, 0.8458515283842795, 0.8375545851528384, 0.8375545851528384, 0.8283842794759826, 0.8192139737991266, 0.8122270742358079, 0.8021834061135371, 0.7912663755458516, 0.7825327510917031, 0.7825327510917031, 0.774235807860262, 0.7694323144104803, 0.7620087336244541, 0.7493449781659388, 0.7489082969432315, 0.7414847161572052, 0.7414847161572052, 0.7414847161572052, 0.731004366812227, 0.731004366812227, 0.725764192139738, 0.7170305676855895, 0.7082969432314411, 0.7008733624454149, 0.7008733624454149, 0.7008733624454149, 0.7008733624454149, 0.6908296943231441, 0.6847161572052402, 0.6755458515283843, 0.6751091703056769, 0.665938864628821, 0.6567685589519651, 0.6502183406113538, 0.6419213973799127, 0.6327510917030568, 0.6222707423580786, 0.6139737991266375, 0.6096069868995633, 0.6091703056768559, 0.6008733624454149, 0.5890829694323144, 0.5803493449781659, 0.5694323144104804, 0.5598253275109171, 0.5506550218340611, 0.5423580786026201, 0.5314410480349345, 0.5240174672489083, 0.5131004366812227, 0.506113537117904, 0.49301310043668123, 0.4851528384279476, 0.4851528384279476, 0.47467248908296944, 0.46812227074235807, 0.46812227074235807, 0.45633187772925765, 0.44497816593886463, 0.43799126637554586, 0.42882096069868997, 0.4183406113537118, 0.40611353711790393, 0.39650655021834064, 0.38777292576419214, 0.37860262008733625, 0.3681222707423581, 0.3563318777292576, 0.34541484716157206, 0.3314410480349345, 0.3205240174672489, 0.3091703056768559, 0.2934497816593886, 0.28296943231441046, 0.2689956331877729, 0.2537117903930131, 0.2410480349344978, 0.2279475982532751, 0.21441048034934498, 0.2017467248908297, 0.18820960698689956, 0.16943231441048034, 0.1497816593886463, 0.12925764192139738, 0.10480349344978165, 0.07729257641921397, 0.04585152838427948, 0.0]], 'thresholds': [[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.17666666666666664, 0.18, 0.18666666666666665, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.2675, 0.27, 0.27666666666666667, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.3375, 0.34, 0.35, 0.36, 0.37, 0.375, 0.38, 0.38666666666666666, 0.3866666666666667, 0.39, 0.3975, 0.4, 0.41, 0.42, 0.43, 0.43166666666666664, 0.4333333333333333, 0.4366666666666667, 0.44, 0.45, 0.46, 0.4625, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.5476666666666666, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.6759999999999999, 0.68, 0.69, 0.696, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.0]], 'auc': [0.8019116373742557]}\n"
     ]
    }
   ],
   "source": [
    "print(pr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot precision-recall curves\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(pr_data['precision'][0], pr_data['recall'][0], color='darkorange',\n",
    "        lw=lw, label='Precision-Recall curve')\n",
    "# plt.plot(pr_data['precision'][0], pr_data['thresholds'][0], color='darkblue',\n",
    "#         lw=lw, label='Thresholds')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot auc curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "# output_mapping = clfutil.get_output_mapping()\n",
    "# get key corresponding to value 1\n",
    "\n",
    "# pos_label = list(output_mapping.keys())[list(output_mapping.values()).index(1)]\n",
    "\n",
    "fpr, tpr, thresholds = auc_data['fpr'][0], auc_data['tpr'][0], auc_data['thresholds'][0]\n",
    "roc_auc = auc_data['auc'][0]\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "        lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=15)\n",
    "plt.ylabel('True Positive Rate', fontsize=15)\n",
    "plt.title('Receiver operating characteristic', fontsize=15)\n",
    "plt.legend(loc=\"lower right\", fontsize=15)\n",
    "plt.savefig('roc_curve.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from statsmodels.stats.outliers_influence import OLSInfluence\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import sys \n",
    "project_path = os.getenv('PROJECT_PATH')\n",
    "sys.path.append(project_path)\n",
    "sys.path.append('../Enums/')\n",
    "# from Enums.enums import RegressionMetrics\n",
    "from enum import Enum\n",
    "class RegressionMetrics(Enum):\n",
    "    R2 = \"R2 Score\"\n",
    "    MAE = \"Mean Absolute Error\"\n",
    "    MSE = \"Mean Squared Error\"\n",
    "    RMSE = \"Root Mean Squared Error\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class RegressionUtility():\n",
    "    def __init__(self, data, target_column, metric_type=RegressionMetrics.R2.value):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.cardinality_threshold = 10\n",
    "        self.metric_type = metric_type\n",
    "        self.classifiers = [\n",
    "            Ridge(alpha=0.5),\n",
    "            BayesianRidge(),\n",
    "            RandomForestRegressor(),\n",
    "            AdaBoostRegressor()\n",
    "        ]\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and (self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64'):\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def split_data(self):\n",
    "        X = self.data.drop(self.target_column, axis=1)\n",
    "        y = self.data[self.target_column]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.split_data()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('regressor', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "\n",
    "        results = []\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            \n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "\n",
    "            self.estimator.fit(self.X_train, self.y_train)\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(self.X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            r2 = r2_score(self.y_test, y_pred)\n",
    "            mse = mean_squared_error(self.y_test, y_pred)\n",
    "            mae = mean_absolute_error(self.y_test, y_pred)\n",
    "            rmse = mean_squared_error(self.y_test, y_pred, squared=False)\n",
    "\n",
    "            results.append({\n",
    "                'Classifier' : classifier.__class__.__name__,\n",
    "                RegressionMetrics.R2.value : round(r2, 2),\n",
    "                RegressionMetrics.MSE.value : round(mse, 2),\n",
    "                RegressionMetrics.MAE.value : round(mae, 2),\n",
    "                RegressionMetrics.RMSE.value : round(rmse, 2)\n",
    "            })\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results)\n",
    "        self.getBestModel(self.metric_type)\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        self.best_estimator = self.trained_models[self.best_model['Classifier']]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        return self.output_mapping\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        feature_importance = {}\n",
    "        feature_importance['feature_names'] = self.X_train.columns.tolist()\n",
    "        feature_importance['feature_importance'] = permutation_importance(self.best_estimator, self.X_test, self.y_test, n_repeats=3, random_state=42)['importances_mean'].tolist()\n",
    "        return feature_importance\n",
    "    \n",
    "    def get_scatter_plot_data(self):\n",
    "        scatter_plot_data = {}\n",
    "        scatter_plot_data['y_true'] = self.y_test.tolist()\n",
    "        scatter_plot_data['y_pred'] = self.best_estimator.predict(self.X_test).tolist()\n",
    "        return scatter_plot_data\n",
    "\n",
    "    def get_residual_plot_data(self):\n",
    "        residual_plot_data = {}\n",
    "        residual_plot_data['y_pred'] = self.best_estimator.predict(self.X_test).tolist()\n",
    "        residual_plot_data['residuals'] = (self.best_estimator.predict(self.X_test) - self.y_test).tolist()\n",
    "        return residual_plot_data\n",
    "    \n",
    "    def get_cooks_distance_data(self):\n",
    "        regressor = self.best_estimator.named_steps['regressor']\n",
    "        cooks_distance_data = {}\n",
    "        cooks_distance_data['x'] = list(range(len(self.X_test)))\n",
    "        cooks_distance_data['y'] = OLSInfluence(regressor).cooks_distance[0].tolist()\n",
    "        return cooks_distance_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/51182.csv')\n",
    "target_column = 'Weekly_Sales'\n",
    "reg_util = RegressionUtility(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: BayesianRidge Processing:  25%|██▌       | 1/4 [00:00<00:00,  7.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Training Current Classifier: AdaBoostRegressor Processing: 100%|██████████| 4/4 [00:10<00:00,  2.72s/it]    \n"
     ]
    }
   ],
   "source": [
    "reg_util.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = reg_util.get_feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_names': ['Store', 'Date', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment'], 'feature_importance': [1.7166392375275246, 0.08333023643625721, -9.728671697473157e-05, 0.012868375710693694, 0.008195576078779557, 0.9302109857759442, 0.1220995346093442]}\n"
     ]
    }
   ],
   "source": [
    "print(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot_data = reg_util.get_scatter_plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_true': [1138800.32, 1304850.67, 1769296.25, 1077640.13, 428851.99, 1004523.59, 1523410.71, 1014898.78, 1955896.59, 958667.23, 687344.68, 513991.57, 1840686.94, 881503.95, 955506.95, 874790.68, 672194.03, 820964.1, 608390.94, 547384.9, 733564.77, 457711.68, 2102530.17, 875372.91, 981345.2, 1999794.26, 2495630.51, 2461468.35, 620087.35, 1509323.09, 1033552.18, 1375458.21, 1686010.02, 1394065.76, 1379488.05, 611258.71, 1933719.21, 1912791.09, 2427640.17, 1837743.6, 808821.5, 773878.58, 1153332.89, 1244390.03, 1285358.01, 895069.88, 1507460.69, 481119.6, 2042581.71, 469598.57, 2057059.53, 1833511.08, 1725268.56, 1063557.49, 1837553.43, 412314.71, 1495536.46, 873643.14, 457216.87, 935266.43, 1530761.43, 922539.94, 1124763.74, 386344.54, 275313.34, 224294.39, 697645.32, 450756.71, 2091663.2, 537224.52, 246124.61, 767338.32, 1448938.92, 1911967.44, 941612.04, 555279.02, 432808.48, 656637.63, 579874.22, 387944.83, 1249696.97, 292859.36, 994801.4, 494145.8, 412456.48, 280472.78, 496851.6, 848358.09, 599629.25, 947815.05, 453943.89, 813845.5, 374556.08, 1799682.38, 565297.54, 1377092.33, 471115.38, 1762155.79, 722496.93, 264214.12, 844373.31, 2066541.86, 1597868.05, 1308122.15, 597856.51, 586289.08, 920128.89, 719888.76, 749549.55, 483660.15, 1122034.48, 1084722.78, 791356.9, 619369.72, 941829.0, 960746.04, 1081322.12, 1079931.63, 874446.32, 1853161.99, 321299.99, 532241.22, 522105.93, 735796.38, 751963.81, 1440963.0, 559285.35, 1010711.08, 531811.85, 833782.7, 813630.44, 522554.04, 1507637.17, 1404516.29, 929690.71, 911969.0, 584000.71, 2027056.39, 1761235.67, 2202450.81, 1315356.99, 1016143.64, 575676.13, 246277.18, 273690.37, 1510397.27, 968258.09, 825283.43, 531600.62, 1224175.99, 1042043.55, 1334571.87, 917317.15, 1198104.22, 1069533.17, 1294105.01, 1472752.01, 505329.66, 2013115.79, 821568.64, 1344483.81, 1434709.63, 892133.41, 753860.89, 1733822.4, 1877592.55, 1354168.18, 471449.98, 454694.21, 1203172.05, 527509.76, 853073.17, 402341.76, 368929.55, 1930814.66, 1149448.02, 1379579.63, 1405168.06, 520284.79, 311590.54, 418925.47, 2290549.32, 1375962.46, 967310.82, 877813.33, 757738.76, 1511641.09, 284309.34, 895020.48, 1090558.57, 968816.33, 1205536.71, 924011.76, 1257921.28, 916522.66, 904650.55, 392152.3, 556046.12, 472511.32, 492792.8, 617405.35, 782796.01, 1750891.47, 1135577.62, 530367.83, 274634.52, 1112449.3, 498056.0, 1419445.12, 554036.84, 1469693.99, 347295.6, 1968045.91, 295339.01, 1933577.2, 1843030.95, 581473.55, 461868.09, 274721.85, 272997.65, 1493525.93, 354993.26, 831425.2, 506273.74, 925916.65, 1361945.18, 654088.02, 1172003.1, 1306194.55, 1220579.55, 515777.97, 642827.29, 1949183.14, 310800.79, 653468.75, 1986445.65, 1672339.27, 977062.44, 685531.85, 2143080.57, 1809989.29, 1366381.6, 565390.4, 1703850.25, 1935299.94, 1345454.0, 517021.3, 1323999.36, 1554837.62, 551799.63, 845252.21, 1051518.45, 1150204.71, 948977.5, 1226997.7, 967729.35, 527041.46, 571190.83, 230519.49, 1407842.91, 579272.38, 427175.03, 1550214.02, 997868.63, 1244542.33, 1148987.46, 942970.63, 640181.86, 905984.49, 1334627.96, 1427383.24, 2363601.47, 771298.98, 793589.18, 555424.24, 1287288.59, 452792.53, 512834.04, 301444.94, 1880752.36, 620908.18, 618949.82, 1132948.48, 484032.75, 847380.07, 1140501.03, 2338832.4, 1206795.74, 1891816.0, 2015563.48, 553834.04, 2068942.97, 1297792.41, 348591.74, 1946369.57, 1245480.95, 2144336.89, 619639.74, 1525147.09, 1781717.71, 538344.1, 659950.36, 971422.67, 956987.81, 1008483.07, 768390.05, 1118313.7, 958007.69, 1157557.79, 1337617.55, 1273279.79, 763479.9, 872113.23, 537455.65, 1109216.35, 246970.97, 1327405.42, 1799070.98, 1355234.3, 1945808.26, 1333315.03, 1183571.35, 1830939.1, 1441559.4, 349214.18, 1477134.75, 475770.14, 1115255.65, 335858.11, 413042.12, 855001.02, 1182694.95, 781694.57, 1146992.13, 1173131.63, 793184.25, 237095.82, 244856.44, 1307928.01, 1111638.07, 655157.32, 1539483.7, 1345311.65, 320831.36, 224639.76, 1931668.64, 1795152.73, 1867345.09, 2039222.26, 867283.25, 324174.79, 1932233.17, 1095091.53, 1376670.27, 542663.53, 2078420.31, 1697229.58, 363064.64, 733037.32, 316687.22, 564538.07, 944100.3, 1858440.92, 982523.26, 899044.34, 1615524.71, 813954.82, 1441032.59, 269624.2, 1171391.41, 405860.37, 1027584.51, 1929738.27, 816838.31, 597855.07, 1893955.27, 2283540.3, 603147.26, 953495.48, 530059.06, 1230613.5, 892393.77, 1470520.83, 1817887.23, 1826241.44, 1162675.85, 1429954.66, 1359158.57, 1494251.5, 416953.51, 498749.62, 926455.64, 434471.38, 1773500.56, 1424225.44, 1311175.93, 1208600.05, 1375307.54, 3766687.43, 435579.7, 281909.79, 1720908.01, 922440.64, 1285976.53, 504750.35, 711470.8, 610641.42, 2094373.0, 1309437.17, 1890273.44, 827738.06, 1870843.9, 1308537.75, 2152229.11, 1280231.85, 1051922.95, 768718.11, 1960587.76, 517869.97, 2010216.49, 329467.82, 713479.91, 436970.1, 1539930.5, 1049372.38, 2039818.41, 1903385.14, 1130022.99, 554972.42, 817485.14, 2205919.86, 852333.75, 2168041.61, 1170456.16, 1670579.82, 1539230.32, 618121.82, 1402372.09, 1925728.84, 911245.43, 495951.66, 263263.02, 1197373.13, 293350.51, 821498.18, 373267.58, 1346783.35, 1092616.49, 1352401.08, 501251.4, 1514259.78, 2034695.56, 979552.34, 629152.06, 426151.88, 438529.81, 777175.28, 628218.22, 1407036.59, 333522.6, 1040143.14, 1621841.33, 1763545.32, 1794868.74, 407764.25, 2052984.81, 1272395.02, 475776.45, 453632.76, 521516.96, 385672.11, 2168709.76, 2658725.29, 2374660.64, 916033.92, 285100.0, 336378.38, 1078182.18, 1563140.85, 1279080.58, 927249.61, 350276.29, 419348.59, 1259941.48, 1360969.45, 503720.98, 1156826.31, 297753.49, 916446.02, 534597.69, 1572966.15, 1310684.1, 325041.68, 1350441.68, 798593.88, 1764984.15, 1360520.56, 558837.27, 444181.85, 1547729.24, 1293404.18, 1336044.75, 1669299.78, 1958823.56, 361311.41, 443557.65, 2103322.68, 855459.96, 1536549.95, 987990.24, 369722.32, 434822.13, 1607343.41, 220060.35, 549505.55, 833517.19, 877235.96, 649128.23, 1095421.65, 1110706.06, 861965.12, 680943.03, 1790439.16, 541120.2, 1876704.26, 1556627.62, 571463.93, 1629391.28, 715876.27, 410497.73, 628494.63, 1621109.3, 712647.97, 835181.18, 276198.74, 1765571.91, 873576.96, 767358.37, 325345.41, 471281.68, 855385.01, 1707662.87, 466322.76, 389540.62, 2105301.39, 1875040.16, 1412925.25, 525545.76, 344642.01, 951588.37, 1460354.67, 1827440.43, 1974960.86, 365098.24, 2077256.24, 325310.3, 2008344.92, 997672.62, 312161.0, 424083.99, 613531.11, 514731.6, 490503.69, 491179.79, 829284.67, 454183.42, 304989.97, 1804246.16, 985896.44, 1568048.54, 761793.94, 958487.75, 972663.59, 355626.87, 1445596.61, 1751369.75, 457030.86, 815915.52, 723086.2, 1048802.62, 1333740.35, 1989674.07, 769848.75, 505068.22, 1198014.97, 435109.11, 583210.87, 1243812.59, 460331.7, 282558.65, 885445.47, 382677.76, 280785.76, 734297.87, 1379652.65, 452169.28, 672062.08, 758510.36, 808030.15, 288247.24, 1487542.53, 888834.07, 739866.16, 1979247.12, 1109574.11, 837548.62, 727772.8, 1004749.41, 587370.81, 1702220.96, 1648602.39, 1764133.09, 718393.61, 1002806.39, 1321102.35, 1127859.69, 320691.21, 463448.59, 286477.35, 1891034.93, 699536.73, 1413124.11, 348895.98, 1531938.44, 1443285.79, 1379651.87, 511049.06, 1757041.96, 558473.6, 979848.71, 1694862.41, 1743882.19, 288855.71, 1373907.21, 600952.06, 1870619.23, 1044639.69, 1837884.79, 1514828.82, 1280465.8, 419497.95, 1483784.18, 912762.76, 651521.77, 1373270.06, 583364.02, 1177340.99, 534740.3, 1503284.06, 973585.33, 977286.07, 505406.72, 570611.23, 356622.61, 1981607.78, 1907351.2, 1855703.66, 328633.34, 1316899.31, 2203523.2, 1031139.3, 672831.78, 1811455.15, 1456793.33, 428806.46, 1459601.17, 307126.34, 541216.92, 1101458.21, 286347.26, 1327424.28, 1377593.1, 1224915.66, 950862.92, 1143724.48, 822167.17, 312078.71, 226702.36, 963910.81, 445530.16, 325201.05, 2115408.31, 513107.2, 2008350.58, 1405007.44, 1086231.47, 1332716.53, 278287.04, 490981.78, 1355391.79, 943912.77, 1021534.7, 2117854.6, 1682316.31, 1900535.9, 1921655.48, 948964.99, 1230011.95, 1639999.47, 1278304.33, 574450.23, 446336.8, 1215354.38, 423175.56, 1297237.7, 300255.87, 415202.04, 423805.22, 616324.24, 2005478.46, 356797.0, 663396.32, 1338716.37, 479263.15, 1376571.21, 1557776.1, 1518841.45, 394645.25, 365248.94, 773367.71, 792299.15, 462474.16, 1212938.67, 338737.33, 1442819.28, 1234875.33, 677971.33, 545570.86, 1371465.66, 303108.81, 699464.43, 1321914.34, 700272.01, 385631.48, 2044155.39, 513073.87, 336241.0, 330604.9, 857797.33, 2251206.64, 1266564.94, 1358816.46, 1645892.97, 1697230.96, 326870.13, 729036.06, 498241.06, 945018.83, 905324.68, 699270.1, 267495.76, 1840131.19, 249798.75, 1851519.69, 508309.81, 2109107.9, 382914.66, 335741.9, 1372504.9, 873065.23, 540149.85, 1863195.68, 923644.6, 959339.51, 1283849.38, 662198.65, 916967.92, 513615.82, 1280414.8, 611390.67, 1814806.63, 2429310.9, 890547.07, 1827797.4, 1115138.51, 1150003.36, 1665502.55, 578002.85, 323915.32, 905756.13, 826626.5, 1789113.32, 751167.12, 554093.15, 749779.1, 659816.15, 1060433.1, 505978.46, 297293.59, 1245898.73, 985594.23, 1543365.9, 997502.47, 511316.29, 2370116.52, 376183.44, 1392543.37, 529418.64, 592981.33, 1048706.75, 1219583.91, 395107.35, 794660.24, 727163.67, 2165160.29, 1311775.83, 946060.98, 1289082.81, 830756.76, 1106575.59, 586061.46, 555954.13, 938604.58, 1314987.4, 1263680.51, 755098.41, 1711769.11, 408838.73, 2149355.2, 2197299.65, 403342.4, 872817.62, 1759777.25, 1012075.12, 1386472.59, 903882.96, 1991824.05, 887979.47, 1320239.51, 2258616.24, 1371405.33, 458086.69, 1130926.79, 595421.23, 1188047.61, 821127.53, 313387.11, 1884734.31, 1802755.11, 1484995.38, 1827521.71, 952766.93, 294882.83, 1088248.4, 1037464.27, 1062629.3, 1106847.62, 1473386.75, 1017593.47, 1522978.54, 1941676.61, 817653.25, 733455.07, 1523101.38, 1949177.13, 485150.01, 310141.68, 1877410.36, 390732.02, 1029849.2, 408679.36, 1913494.81, 2105058.91, 991570.02, 1007257.83, 527117.81, 894865.3, 953533.95, 1244391.83, 448392.17, 1377716.17, 998362.05, 454412.28, 262789.95, 928537.54, 506502.09, 1399662.07, 1214944.29, 380188.69, 1456300.89, 362134.09, 2065191.27, 1141184.66, 436293.4, 806012.48, 773725.08, 213538.32, 1511717.53, 1574287.76, 1788227.6, 1854967.66, 484835.2, 2024554.1, 240044.57, 795133.0, 508576.62, 1631737.68, 1869110.55, 369106.72, 1931104.67, 1213860.61, 1642970.27, 383550.93, 891736.91, 585895.34, 3487986.89, 885608.04, 1593655.96, 1319054.57, 1953539.85, 1061196.47, 1911510.64, 333948.0, 296673.77, 714677.47, 516556.94, 442457.35, 1000582.06, 2148822.76, 928264.4, 294264.2, 1429143.06, 1594968.28, 529707.87, 1522042.57, 592947.75, 237129.81, 1033017.37, 270677.98, 2154137.67, 529852.7, 1547654.98, 611585.54, 1336404.65, 1758971.38, 336189.66, 1267619.06, 660619.99, 651837.77, 1002856.2, 1198709.65, 410804.39, 303643.84, 1351791.03, 519585.67, 1311986.87, 1682614.26, 660632.05, 2035189.66, 574622.56, 1512207.95, 836419.14, 1390934.27, 683300.84, 1325835.7, 244338.31, 984833.35, 1478321.26, 533414.62, 1347454.59, 775910.43, 337979.65, 1704218.84, 675202.87, 1564819.81, 282545.55, 1166117.85, 1065350.56, 1297535.69, 1897429.36, 342214.9, 2131900.55, 1691439.52, 1857500.96, 2138144.91, 517850.83, 1601377.41, 401615.8, 979428.66, 1794355.49, 1620374.24, 615997.29, 877268.29, 451077.21, 851762.28, 1066792.63, 1143819.35, 1557314.58, 1962445.04, 283455.13, 1650894.3, 1983190.56, 1048866.3, 910240.68, 1189646.45, 1263534.86, 982598.88, 1422794.26, 416036.75, 1061134.37, 420515.63, 825584.22, 1200019.74, 468189.93, 1336838.41, 1264272.52, 624114.56, 469311.17, 1886503.93, 781267.76, 1297335.87, 1227469.2, 529384.31, 680254.35, 469563.7, 272190.83, 988764.84, 892070.82, 1331137.96, 2062481.56, 902109.69, 2302504.86, 329183.92, 1426405.46, 449516.29, 883683.35, 339976.65, 396968.8, 2082355.12, 535937.25, 1430851.11, 1704753.02, 589091.04, 321110.22, 1537139.56, 642776.4, 655811.95, 2432736.52, 1523979.11, 958225.41, 3818686.45, 468428.3, 955294.7, 1248901.98, 558671.14, 1935869.1, 480239.88, 1069112.0, 1244381.98, 2156035.06, 463561.48, 638144.98, 1337506.74, 660838.75, 616345.25, 1090915.09, 1364445.98, 1133807.03, 435972.82, 303908.81, 574955.95, 575997.78, 562173.12, 527953.14, 1306551.71, 1229257.7, 527572.25, 1527845.81, 918049.28, 1808250.71, 239431.85, 1122053.58, 1502078.93, 303043.02, 1455119.97, 1385769.03, 668390.82, 970641.34, 688940.94, 1414564.53, 1946070.88, 1848426.78, 1754879.45, 1792345.3, 1391813.69, 1524390.07, 1464616.59, 1425559.02, 1688531.34, 1513635.64, 1828052.47, 827717.85, 273079.07, 966780.01, 658997.55, 929096.9, 1939980.43, 1313729.72, 505405.85, 893399.77, 1158698.44, 918335.68, 391860.04, 314607.22, 585548.79, 1863840.49, 1436383.84, 497374.57, 407589.16, 2020332.07, 557166.35, 2246179.91, 912857.1, 996937.95, 1282378.71, 1394393.84, 757369.87, 1310087.0, 1230245.74, 649791.15, 1242746.06, 1436311.76, 1468350.36, 913616.32, 1661767.33, 813756.09, 1415204.88, 427491.04, 2236209.13, 848289.41, 1187776.19, 923600.02, 1536176.54, 1370659.54, 575570.77, 1375101.26, 976393.43, 1351407.79, 369350.6, 918006.9, 864881.24, 562633.67, 2137809.5, 556925.19, 1327719.34, 1660081.29, 1624477.58, 1372043.71, 394918.83, 988392.99, 1230118.02, 624099.48, 754236.7, 411116.95, 2224499.28, 1176588.25, 360256.58, 1811562.88, 1246062.17, 667353.79, 1461393.91, 588363.62, 1048101.39, 630740.11, 1740063.1, 1149427.48, 1680764.06, 1934099.65, 1511041.69, 328498.92, 820188.42, 453016.91, 981615.81, 1408907.89, 1021391.99, 432424.85, 594744.89, 315645.53, 1302499.23, 1295605.35, 924174.4, 1037549.71, 622437.08, 337825.89, 507335.75, 2163384.17, 1267675.05, 667151.46, 1213486.95, 1384721.84, 306827.36, 277137.86, 981646.46, 2121788.61, 298080.45, 453308.15, 570816.34, 491115.86, 903864.02, 1677472.78, 1588430.71, 1388553.11, 1317379.68, 412882.31, 429305.82, 312361.88, 1116295.24, 1220815.33, 1484708.38, 717207.19, 1544653.37, 2005341.43, 941008.85, 712312.89, 1772143.94, 552985.34, 1539387.83, 1449142.92, 2189353.63, 2055952.61, 1344580.92, 298697.84, 491449.94, 1033171.07, 981210.57, 1999363.49, 2207214.81, 805028.74, 643603.69, 899761.48, 1908278.27, 241937.11, 361067.07, 1199845.29, 726422.55, 1277959.42, 522816.85, 1841369.99, 710496.97, 802583.89, 342385.38, 2095591.63, 1277882.77, 1445249.09, 261131.09, 684348.92, 1543947.23, 329613.2, 1635078.41, 535769.32, 1350646.16, 859258.17, 489079.23, 306098.17, 1246242.61, 558691.43, 481144.09, 2081534.65, 541406.98, 359949.27, 1290684.95, 1857533.7, 1034119.21, 503295.29, 1239423.19, 437222.94, 589554.29, 820288.35, 366367.55, 2094515.71, 340497.08, 1419236.9, 449355.91, 500945.63, 1785823.37, 1794962.64, 725043.04, 994610.43, 1707481.9, 768070.53, 1011201.12, 425215.71, 1492060.89, 801098.43, 890689.51, 2066187.72, 816138.33], 'y_pred': [1160604.4502000012, 1305752.1619999998, 1896981.431800001, 978873.9856000006, 437229.9608000003, 988968.8510000004, 1249239.5160999987, 972519.3193000001, 2026752.1443999996, 970569.9564999999, 675883.1444000001, 541380.4840000004, 1989747.2021999985, 833611.7703999999, 1008719.4177000001, 1016799.4070000005, 671909.4615000003, 780616.5916000003, 560222.5388999998, 577387.2798000004, 723883.2872999999, 424599.61579999974, 1999015.1930000002, 898710.5769000005, 1017532.8402999998, 1940036.2198000005, 2225380.8622999988, 2061854.5551999984, 572087.427, 1615479.1691, 983441.0425000009, 1384493.0061000003, 1699010.3619, 1382215.0512000013, 1430830.951600001, 664464.9021000003, 1858893.5764000013, 1903457.5992000017, 2323285.7614000007, 1852263.1363000008, 781921.7602000003, 783262.7702000008, 1116640.8375999995, 1226361.1672999994, 1327118.448100001, 905237.9564, 1555362.2234000007, 490636.9523000006, 1909080.1586000004, 499420.54179999983, 2071810.7135000003, 1853168.3419000006, 1645677.8656000001, 1047705.0147000003, 1853182.17, 445608.48919999995, 1551766.3160000008, 784034.4550999999, 489721.22769999935, 894733.5759999997, 1498251.6920999982, 966610.6856000004, 1171503.6015, 354261.67279999965, 281510.83500000014, 246836.57240000018, 691161.8492999998, 468260.0101999996, 2019120.3265999984, 538579.0398000001, 246591.15160000033, 738972.6241999997, 1514302.3546000016, 1984665.8406000002, 929349.7032999996, 517492.7028999999, 429538.5542000002, 1086833.1621999994, 614551.4945999997, 418955.9600000002, 1298092.5223000003, 290967.6310999998, 910237.4215000006, 521110.8950000001, 414101.4139999998, 292257.5783999998, 518947.2590000001, 899036.1160999995, 532329.9627, 954154.4166, 451141.7388000001, 830011.2432999999, 387710.5315000002, 1646317.0204000005, 564749.6051999998, 1341318.5424, 431861.90859999985, 1873512.401700001, 732452.0989999993, 293325.38199999987, 909847.3855000001, 2075432.5648000003, 1591374.6966, 1407676.6782999993, 589819.4539999999, 568714.6647999998, 923809.6626000005, 786019.195, 793057.3861999997, 496816.65309999994, 1209896.3765999996, 1154484.824200001, 710088.191999999, 621047.3894999989, 960160.3144999996, 902283.0894000009, 1054981.1643999987, 1078163.9834000003, 880158.9015000005, 1853373.1592, 334621.7733, 500500.4118, 515213.3552999997, 774903.9274000003, 705807.3622000004, 1577900.5485000003, 507011.18759999966, 933816.8233000004, 517413.7395000004, 774962.8206000002, 790869.1655000005, 515699.8818000003, 1493843.7946999995, 1423849.2377999998, 956135.3282999996, 942995.9212000001, 559772.5710000001, 2153321.4913000013, 1770231.0777, 2170337.231500001, 1288220.3611000015, 1010834.0213000007, 604283.6941999991, 264666.7528000001, 263235.23300000024, 1451565.0764999983, 948703.6852999999, 891341.8811000005, 534365.1364, 1353107.9559, 1195771.4404999998, 1190201.827099998, 904622.8681000002, 826699.6432999994, 1010411.9811000001, 1316555.9200999998, 1288243.2101000017, 517633.8981000004, 1940029.6995000008, 803842.3950999997, 1403548.2008999998, 1385385.5378999994, 892302.5171000005, 724153.5766000001, 1245867.4056000004, 1987792.5875999983, 1442383.1023999995, 515833.9029000002, 438769.98789999983, 1341204.2735, 600943.1125000004, 929419.4810000001, 366295.0644, 341121.7177999999, 1849464.9410999992, 1153162.7944000002, 1383999.6089000008, 1390327.1085000006, 551497.5310000005, 291130.34920000006, 422729.2639999999, 2184034.2962000016, 1401008.1002000002, 960578.2972000008, 886483.8556000006, 856205.7365999997, 1160917.8290999986, 306699.9443, 917293.4139000005, 1327290.2834999987, 992357.5331999998, 1319649.9410000003, 986709.5621000003, 1276123.0713000023, 910289.0106000002, 800428.3165000003, 362603.8635000001, 522134.4335000001, 452226.5175999997, 504770.7461000007, 558066.3649000003, 790675.0783000002, 1968606.8948999995, 1119052.9298999994, 509632.12910000014, 283761.5205000003, 1028211.0323999997, 544040.3450999998, 1472653.3307000005, 550880.1743, 1255482.4735999997, 335475.3563000001, 1985284.9983000013, 289693.7738000001, 2162585.3354000007, 2223333.632899998, 542959.9736, 457242.4296000001, 253052.2509000002, 280245.78369999997, 1494081.2776000001, 378225.42320000037, 880613.6086999999, 520039.9134, 1042677.2738999999, 1446014.0357, 698379.9622999995, 1239219.753499999, 1457521.307600001, 1035783.1585999989, 507872.19170000014, 726313.6178000006, 1730811.8530000004, 269788.737, 848324.6709999994, 1999455.3384999987, 1681326.1815, 991791.1643000002, 681172.2805, 2368544.0748, 1891038.3584999982, 1441423.4561, 547919.1429000001, 1817844.223700001, 1868747.7916999995, 1443110.3332999998, 503606.38570000016, 1313772.4863999987, 1403882.6567, 544036.7852000004, 877729.5464, 947864.6153999992, 1236913.7491999997, 1103678.2604000003, 1317696.0894999998, 938913.0407000008, 495535.3249, 604391.2076999997, 260489.36240000027, 1343102.225, 507920.9576000001, 406874.15230000013, 1234811.4372000007, 993181.6338000001, 1187520.7128999997, 1006873.2499999995, 987428.7316999991, 737119.0068000008, 891245.4343999997, 1327641.3671, 1388667.3410000012, 2343194.8300999976, 785419.9857000002, 814980.7826000002, 516837.2861999999, 1289328.5795999991, 428171.7019999998, 545826.9082000002, 320444.44830000005, 1834074.6855999997, 579697.8348999999, 623915.2587999995, 1399111.2340999993, 514238.9030999997, 870047.7628000006, 1140247.9117000005, 1926613.7072, 1184910.7470000004, 2067808.781300001, 1996937.9096000013, 554520.7611000002, 1811882.5387999997, 1345403.2924000015, 353416.8431000004, 1945981.6195000003, 1324644.9802000006, 2244910.7714999984, 610083.3484000006, 1547797.2758999998, 1756322.3151000002, 515444.18830000004, 581589.9802, 978269.1270000007, 935736.9406000008, 984982.4276000002, 755448.9171000001, 1078112.0346999995, 979087.9252, 1195856.7997999997, 1259678.8956000002, 1262798.0038999987, 769989.5851, 968038.4827999999, 568616.6130000002, 1132694.3054999998, 272970.2613000002, 1484830.5677999994, 1544120.1545999998, 1377884.0938000006, 1916425.234799999, 1254998.9172999999, 1196105.1489999997, 1763044.1637000002, 1327562.8711999983, 376942.94250000006, 1412360.2639000001, 539312.3056999997, 865705.5647999996, 337643.93639999983, 386421.6518, 827723.8336, 1256393.0347999996, 774880.7894999998, 1072752.8962999994, 1201833.3964000002, 779202.9375, 249375.35990000024, 247615.43669999987, 1317875.4276999994, 1006878.4590999994, 685590.7146, 1530455.4673999995, 1347907.7321000004, 306735.5324000003, 247576.4672, 1970603.7484000004, 1742175.3006, 1895640.372100001, 2069612.9209000003, 756132.3184, 288658.7774000002, 1943087.218000001, 1084331.1857999992, 1435267.327899999, 553643.4702999999, 2044311.696, 1594816.629, 357352.3926000001, 738163.2207000001, 315303.0411000001, 497836.02260000026, 951995.1615000012, 1979695.7462999993, 906092.6523000008, 894189.7432000007, 1524478.7199, 825579.3028000001, 1396876.5752999997, 289865.7693999997, 1134306.6350000002, 426517.0750999998, 882747.8225, 1666115.6301, 908745.502299999, 611914.8827000003, 2040177.9855000016, 2153325.8651, 567230.2600000001, 907309.3027000001, 500607.7329000001, 1200333.4505999999, 849341.0087, 1474135.3839000005, 1945795.1974000006, 1774000.8575000016, 1301275.3352000006, 1472148.7216, 1297600.8268000016, 1516314.2776000008, 371951.9609999999, 505082.58070000017, 926988.0854999996, 446774.88949999993, 1675761.3365999996, 1593392.6318999997, 1361311.6198, 1223988.3894, 1438914.821799999, 3085142.808699997, 429843.31510000007, 282450.75449999975, 1734359.1708999993, 882882.5360999997, 1213780.5895999996, 500379.4225999998, 760984.101799999, 620521.8527999995, 2052592.3347000005, 1334909.1808999998, 1881937.5998000011, 838709.8535000001, 1918157.3586000004, 1585589.0477999994, 2027851.0095, 1285914.0846000013, 1011141.6003999994, 741764.6242999998, 1952985.4907999989, 543154.0827000003, 1940570.0808000013, 324036.2446000002, 660064.1372000009, 399710.44860000035, 1621457.8478000006, 1025939.240900001, 2033604.8789999988, 1494801.1768999991, 988349.1612000003, 523389.61949999945, 834980.7371999997, 1991666.0319999985, 861908.3619999994, 1954170.7397999999, 1332196.265699999, 1832664.9931000003, 1408824.7911999985, 575644.4183000004, 1437560.9586999991, 1866393.5471999987, 880886.4618000005, 500760.93830000027, 287588.24659999995, 1337847.5670999999, 326709.32840000046, 758868.67, 359697.32219999994, 1304366.8304999988, 1137918.2462999988, 1328406.9739000013, 507957.4406000003, 1436207.7076000008, 1757732.3032999989, 933253.2929000002, 688779.5381999998, 427164.6167000003, 435819.8488000001, 904268.3200999993, 570507.6904, 1345504.6697999998, 312596.3666999999, 1054128.7545999999, 1636782.2671999994, 1641213.6867000004, 1877423.1937000009, 432268.2635999997, 2076802.189900001, 1376550.1848, 521919.8458000002, 481119.90030000044, 573436.1177999999, 406372.65779999987, 1966390.991200002, 2749736.7195000034, 2271801.7727000015, 860052.2806999988, 268918.8333999998, 332838.9678000001, 1120018.0267999994, 1427449.4801000005, 1368816.52, 906480.1644000002, 355681.8578999998, 432069.6735999997, 1391135.6733000001, 1421148.5297999997, 543566.9427999997, 1089704.9586999998, 274177.14110000036, 686462.5328999998, 579300.4752, 1437370.8377999994, 1304722.3305, 307649.3631000003, 1534124.5425000007, 787900.7624000001, 1724607.0615999987, 1443510.3594000007, 535275.7211999993, 472212.2396000003, 1462726.3567, 1135959.3302999989, 1491762.7457000006, 1829932.1822, 1926895.819100002, 366346.80029999965, 414076.8288999999, 1950946.6759000013, 811761.2567999997, 1478574.4424999994, 1002101.6103000003, 415505.4864000003, 418606.11239999975, 1634818.2217999992, 262883.52899999986, 514063.0663999994, 877309.4145000002, 762893.5369000003, 610204.5977000003, 1060705.5815999997, 1080884.8832999994, 885501.1921999997, 632042.4737000003, 1916937.5258000004, 577645.5243999999, 1826634.5696999987, 1326967.2426999987, 565415.3330999998, 1557823.0799999994, 755911.0487, 407412.70239999995, 715863.7903999998, 1807531.7677000002, 747896.7473999996, 801475.1606000001, 246019.43060000028, 1845268.4095000005, 811822.8483, 741443.0739, 328623.70679999964, 498917.2201999995, 897213.7992999996, 1682539.1003999994, 502745.0848999997, 381276.1220999999, 2247463.662499998, 1675951.5114000002, 1351536.2932999993, 539629.3403000003, 336781.5397999999, 943605.5897999998, 1403064.6900999974, 1752013.4054999999, 2075073.6693999998, 283254.56020000024, 1613203.4881999996, 305939.2552, 1959087.2007999998, 988185.9806000004, 276363.53260000027, 472041.8238, 564677.5498000002, 529952.8890000002, 483539.55010000034, 473384.15880000027, 782572.8929000006, 514693.07770000043, 293386.5771000002, 1807329.9581999995, 989061.7515000002, 1483358.9586000002, 668705.2712000004, 963065.9608000009, 907174.3982000005, 352789.6617000002, 1444097.4598999983, 1784067.9076999992, 433437.6917999998, 628762.0619999999, 740384.5265000002, 948534.1719000001, 1350004.4726000002, 1981396.5869999998, 788760.6627000001, 537552.6001, 1166517.8961999998, 436572.9075000001, 616604.1445, 1141417.6614999995, 519826.58970000007, 309006.8801, 930140.9463000005, 376177.7766000002, 284799.7016999999, 749581.2376999997, 1428945.8294000009, 452247.9231, 667511.3044000011, 791682.5769999992, 842896.4184999994, 292106.9327999999, 1407699.0050999983, 903998.3927999999, 715883.7912999995, 1935539.6149000004, 1112555.9011000001, 826125.7945000003, 713969.6972999999, 1042496.6175999998, 592676.9369999998, 1413779.1020999996, 1604627.2907, 1864007.4610999995, 679375.6026999997, 962559.6037999992, 1356856.4990999987, 1240410.6874, 319494.3078999999, 527379.2080000001, 287281.12449999974, 2067027.8563000006, 703043.5518000002, 1407946.2854, 353832.1106000004, 1593637.6424000007, 1421686.5710999996, 1401225.343199999, 527838.9257000001, 1641713.856900001, 570607.8961000008, 983294.3996000004, 1697265.0083999983, 1851482.5549, 314704.9771, 1338100.9457999996, 532380.7129000002, 1900166.0187000001, 983752.4905999999, 1803891.8376999986, 1472522.4670999988, 1315819.5810999996, 429823.90689999954, 1441268.2605000003, 987198.5580000003, 613762.8690999993, 1383957.7805999997, 706249.7708000003, 995247.8311000008, 618171.9223000004, 1497095.6330999997, 979435.6137000003, 1092951.3883999998, 529145.9018999995, 576230.7937000004, 321138.1503000001, 1985348.7415999987, 1847348.5327999995, 1918810.0327999995, 322433.9080999999, 1465632.9295999997, 2034288.9374000004, 1064968.1071000001, 684067.9909000001, 1813491.2682000012, 1464749.8181999999, 442033.9868999999, 1402943.6919000014, 307921.9716, 456552.3676, 1091812.1961999997, 298375.80949999986, 1311693.9546999997, 1366427.4892999989, 1234091.4905999997, 1026382.2174000002, 1355131.3664999988, 794648.7277000002, 357007.7923999999, 248231.8264000002, 947883.8849, 452082.6306000001, 275340.8986000002, 1967664.377900001, 517708.5282999998, 2126463.3502999987, 1354669.285199999, 1019131.4210999997, 1412493.3935000012, 275092.9475, 478994.7736000001, 1335250.6199, 947694.1858999993, 1076398.9355000006, 2098577.745599999, 1780233.2764000006, 1878985.3102999998, 1701524.8672999993, 854766.1107000001, 1168240.1069999998, 1611938.003900001, 1299118.7092, 499043.3539000005, 425261.1379000002, 1272140.5561000004, 404533.73670000024, 1387904.8931000007, 304815.98720000027, 436963.36220000027, 424460.6867, 631094.1869000002, 1951723.2206999997, 385539.9180999999, 592796.3042000004, 1313793.8306000007, 524805.0613000005, 1302891.9486000007, 1604723.7202, 1383145.0768000013, 377259.2085999996, 372874.38150000013, 788481.3579, 777875.4093000004, 456214.84180000046, 1353981.3295000005, 336051.31260000006, 1463191.8596999994, 1249360.2296999996, 662540.5176999996, 564090.2202000004, 1379478.4741000012, 287332.88820000016, 742678.1383000002, 1341299.4414, 695598.4645000002, 366412.1782, 2029646.8711999995, 520319.3093000001, 339370.64839999995, 340060.7397000002, 821037.9647999995, 2056986.8159000003, 1384577.8148000005, 1381498.0502999993, 1730502.6089000003, 1616127.8859000003, 297949.63420000026, 746052.7776, 505334.4501000002, 909284.0880000005, 764776.1329999996, 692266.4141000002, 276611.8719999999, 1515850.2647000009, 274951.9682, 1844578.4017000003, 507811.51749999984, 2224283.458299998, 412318.41570000007, 312554.8817, 1383510.9733000007, 846585.3090999994, 475458.3319, 2165701.2200999996, 947719.8752000008, 992031.0913000004, 1288059.6569, 623391.1996999995, 965891.183200001, 515126.73659999983, 1388941.3831000011, 593651.6601000003, 1818823.6701999998, 2010926.2645000014, 972008.6260000004, 1733703.6606, 1108739.9366999995, 1181049.3134, 1445214.4250999999, 557843.4706999995, 329295.72620000027, 891125.3039999994, 871161.2794000001, 1427539.1285999995, 765941.2379999998, 539600.4850999999, 750634.8812000001, 573279.6198999998, 1070343.7263999996, 545980.9819000004, 307083.6216, 1261377.7011999998, 1078104.0223999997, 1508623.0074000016, 797271.7145, 571024.4898999998, 2198834.136099998, 390801.13279999956, 1402273.1539000003, 561880.5136000005, 587796.4008999998, 1029965.6557000002, 1264617.4304000002, 380356.97990000027, 764860.6334000003, 769382.4793000002, 2114725.1819999986, 1363488.7470000007, 901674.3799, 1297743.6995000006, 871792.2705000001, 1067134.4255000001, 528583.9275999998, 557864.2094, 967850.8787000004, 1445834.2868000004, 1265141.1808000002, 775327.0214, 1855637.410699998, 402580.39730000007, 1907728.429599999, 2178266.4685000004, 373783.8157000001, 870564.4267000001, 1727356.0761000006, 991186.134200001, 1384125.8044999999, 933256.9107999998, 1668804.9465000012, 848940.5188999997, 1379204.0811999994, 2179746.4733999996, 1368176.1689000013, 481165.8404, 921925.4062999994, 612895.9875000005, 1163395.9680000008, 776126.1637999996, 322815.00800000015, 1865787.3193000003, 1815990.4426999989, 1564010.8354999984, 1816552.074200001, 814757.0951000002, 286598.4543999998, 980066.1226000002, 994347.8149999996, 953031.8553000006, 1121786.8757999996, 1365395.5193999999, 977153.8115000005, 1524818.1106, 2084966.1379999989, 817779.6811000011, 751293.0724999997, 1320948.9473999997, 1763149.6390000016, 500046.0710999997, 304121.4962000005, 1530678.1191, 413686.16269999987, 962135.5892000003, 426883.3156999998, 1675782.5480000002, 1873830.6967999989, 950917.2556999996, 1050446.0077000002, 542934.6381000001, 957494.5854999997, 969383.4328000002, 1350800.4724999997, 453092.2398000002, 1487604.0442000004, 1014962.5430999993, 621634.4944999999, 259931.3599000001, 884244.0952999996, 504029.9862999998, 1457371.6369, 1275520.6035, 363678.6212999999, 1362039.7275999999, 354468.9032000002, 2109647.5833999994, 1204380.7903000005, 452310.6975000001, 769618.9547999993, 865068.6766000002, 262289.5879000003, 1739367.6340000003, 1470836.3719000004, 1861816.8201, 1961389.790499999, 533597.023, 1999537.819500002, 249095.3792000003, 790405.3611999999, 501128.45909999986, 1461545.3416999998, 1998377.4056999988, 343025.78029999963, 2024325.5214999998, 1387540.9620999994, 1470723.2522999977, 414118.4401999996, 900378.3071000003, 570112.5933000002, 3614408.535999999, 757076.4553999999, 1459785.9617999995, 1322380.5158999995, 2144235.7395999995, 1039455.4479, 1859972.5644999999, 298780.5346, 299582.2700999998, 722288.8842, 513204.5719999999, 454514.55870000017, 956890.7276999993, 2098047.4680000027, 951056.0060000003, 296034.6196000002, 1396308.1771000007, 1492884.2683000003, 526838.1126999997, 1434542.0741000003, 587279.1499999997, 264661.79230000003, 1079435.7644000002, 298032.7777, 2150163.766999999, 519319.8588999997, 1602573.0238000008, 617838.8768000002, 1258018.3191, 1777821.1293999988, 304256.98570000014, 1363470.3935999991, 719727.4096000005, 719173.8396999999, 1004088.0544000001, 1218321.9918999989, 415674.2853999995, 302709.4395000002, 1494666.9306000003, 544944.0522, 1333819.4298999999, 1574351.6903000018, 641438.1097999999, 2011296.385, 562156.0342000003, 1381697.6975000007, 863250.9979, 1891309.4707000025, 678891.0704000001, 1316489.1116000006, 271280.07620000024, 881253.1279999998, 1293447.2185000002, 529232.2681999998, 1355248.7342999997, 788828.8195999999, 338365.56539999985, 2318271.317399998, 659927.4714999998, 1569865.7134999987, 296023.48140000016, 1171502.9342000003, 1139300.7441000005, 1332409.2437, 1905178.5063000005, 355143.57180000044, 1966008.5373000014, 1821654.5880999998, 1849945.3587000004, 2182694.061699999, 525994.6180999998, 1530277.4671999994, 440487.78609999997, 941380.6096000007, 1822091.9226999981, 1598298.1293999993, 585782.1687999999, 856962.2262000002, 445004.59149999986, 896143.582500001, 1099219.4876999988, 1109707.220999999, 1228312.2682999992, 1977437.6664000007, 287897.0074, 1779562.3415000003, 1879255.9316000002, 1000155.7644000005, 921657.3961, 1138070.889499999, 1589576.7981999998, 1014052.6041000001, 1318849.901700002, 435703.60000000015, 1049452.2906000004, 419313.8958000003, 936165.4182999998, 1235598.1530000002, 458463.28580000007, 1308361.7467999994, 1343341.7204999996, 626353.9641999998, 434559.62189999974, 2053096.2489000007, 802362.6252, 1353729.3225, 1199432.1543999997, 531146.0808999997, 721899.3899000003, 462276.7797000002, 287917.4468999998, 970216.3156000004, 938017.1699000001, 1383326.8364999997, 2125440.7785000005, 906677.7254999994, 2057070.3109, 307053.2757000003, 1461490.9135000012, 393898.3449000005, 862670.8366000003, 383924.35830000025, 435418.11519999994, 2178620.629999999, 513425.0966000006, 1365261.3749000004, 1888717.0894999998, 535686.5387000003, 311631.06450000004, 1472860.963400001, 643897.6196000001, 656456.1274000001, 2182711.700100001, 1607823.4685000002, 880977.798799999, 3436418.878099999, 516299.86900000006, 893099.5929000006, 1305710.6959999993, 548709.2353000004, 1840227.3564000004, 471304.35389999964, 949955.6265000002, 1236368.9173, 2236225.2438999983, 494436.22689999983, 658917.4386000009, 1325644.5856999995, 643506.1022000005, 615845.2664999997, 1063510.1889000006, 1362675.7752999992, 1071649.6792000004, 448359.77360000036, 347980.1315999995, 569329.3497999996, 574475.4955000001, 555780.8235000005, 518696.30549999984, 1360693.8413000004, 1192532.5206000002, 514608.35509999975, 1560051.1447, 984872.8406000008, 1973784.1893999993, 247054.29290000026, 1035568.7920999991, 1445741.3659, 304691.54219999997, 1516859.1609999996, 1403937.6065999984, 677072.0554000001, 1000371.2852999998, 710321.8561000001, 1426333.1867000007, 1943294.3725999997, 1836143.3997999993, 1913760.6845999996, 1808190.4881999982, 1279720.4070000001, 1462090.8970999995, 1485733.5666999999, 1382594.5531000006, 1472986.474799999, 1516092.1464999996, 1792681.3012, 833768.8156999993, 288465.9121999999, 988993.6317000013, 647385.5046999997, 905368.9404999993, 2005766.5873999982, 1880067.5093000003, 642584.3539999994, 865809.1327999997, 1227480.5587999998, 864162.7593000005, 390405.0886000001, 292562.31470000034, 527763.8914000002, 1802023.4878999994, 1374080.0564999997, 460959.31880000065, 405682.9226000003, 2024636.4255999995, 583670.1220000002, 2182533.269200001, 898282.0612999997, 979817.043700001, 1180223.9988999998, 1406093.5814000017, 744449.9965000002, 1299161.1178999993, 1187172.8671999997, 600170.3648999999, 1279345.693099999, 1451292.6678000006, 1393708.4182000004, 915356.6358999994, 1578470.2991000013, 850912.0853000002, 1436603.6585999995, 424684.89350000006, 2139139.0672000004, 820675.3873999999, 1220802.4093999993, 1001708.4256999999, 1470965.7348000002, 1253867.4541, 576185.8279000004, 1407788.6370000008, 978606.4984000002, 1490030.2498000006, 390109.6208000002, 889204.0673, 884573.9728999991, 599166.7682999998, 2078761.4329000001, 513080.48459999973, 1261486.9160000007, 1604846.8355999992, 1604838.6202999996, 1403613.254399999, 405313.25869999983, 1034312.4615000006, 1253188.9121999992, 649517.6859000002, 722831.4334999998, 409261.1828000002, 2187719.8756, 1262158.3262999982, 344385.3675999999, 1745992.9811000002, 1234157.4515999986, 663416.7450999997, 1402356.0661999995, 505489.6245999997, 965644.0926000007, 670518.441400001, 1791534.0712999993, 1286137.7581000004, 1362262.3936999992, 1728308.4656000012, 1462288.9841, 326360.1669000002, 831363.1818000003, 451248.5329000002, 1012142.5874999997, 1384704.719000001, 990825.4681999997, 415378.6745000001, 621845.5355000003, 289679.26370000024, 1303108.1423999998, 1164742.4339999997, 981021.6324, 1070207.1108, 623731.7482, 304868.47059999994, 505937.5917999995, 1832501.4431000007, 1330648.7649000008, 674290.7781999988, 1228303.3102999995, 1435853.9184999994, 304917.6724000005, 296333.10480000044, 1061230.9241000006, 2045946.6502, 295038.8096000001, 422293.4269999999, 621300.7731000003, 515576.4149999998, 891595.6127999999, 1613469.9090999991, 1664257.1189000001, 1418728.7041000002, 1338507.8119, 422323.59539999993, 431065.12440000015, 323187.28910000017, 1119431.2129000009, 1288690.2550000013, 1574111.8674999997, 708325.5605, 1422260.0329999998, 2098537.8514999985, 945651.3760000004, 724198.8493000001, 1934856.7471000007, 527814.8646, 1609832.4244999983, 1442966.7384000004, 2042517.2102000015, 2118021.0878, 1382293.5222000019, 295220.1165000001, 547976.7715000001, 1079274.8194000004, 989379.9378000003, 2138262.689599998, 2132952.7819999987, 761419.5212000007, 592094.2997, 953053.5287999999, 1862394.0507999999, 297846.0657, 319435.58409999986, 1183379.9556000002, 690646.8590999994, 1319944.6167000001, 521340.10039999976, 1802142.9281999997, 698736.1924000005, 805230.9771000007, 328388.48860000004, 2005263.2583000003, 1233768.0589000005, 1534669.686, 271232.35649999994, 688191.5628000004, 1345538.7320999994, 321550.88020000013, 1544645.7501999983, 512962.4799999997, 1389355.1646999991, 754532.6186999996, 511075.9237999995, 320292.3271, 1270733.8262, 551653.2656000003, 495300.6538999996, 2180395.0388, 584337.3003999998, 431673.9338000004, 1309284.062899999, 1884994.1764999998, 1077665.7110000015, 567046.8944, 1325536.9847000004, 430612.6387999999, 640786.1513000007, 870856.2287999998, 379971.72139999963, 2095282.3846999994, 345561.34170000016, 1366361.0349999985, 430101.89539999975, 547900.4111999996, 1900698.1324000005, 1963133.4424000012, 662228.4588999996, 983171.8872000002, 1768390.2349999996, 777663.4092, 1140408.2833000005, 438995.3318999996, 1481960.8430999985, 773083.0878000004, 755417.3260000001, 1947608.0948999994, 790233.6515999999]}\n"
     ]
    }
   ],
   "source": [
    "print(scatter_plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = scatter_plot_data['y_true']\n",
    "y_pred = scatter_plot_data['y_pred']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "plt.switch_backend('agg')\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.scatter(y_true, y_pred, color='darkorange',\n",
    "        lw=lw, label='Scatter Plot')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Scatter Plot')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('scatter_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_plot_data = reg_util.get_residual_plot_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'y_true': [1138800.32, 1304850.67, 1769296.25, 1077640.13, 428851.99, 1004523.59, 1523410.71, 1014898.78, 1955896.59, 958667.23, 687344.68, 513991.57, 1840686.94, 881503.95, 955506.95, 874790.68, 672194.03, 820964.1, 608390.94, 547384.9, 733564.77, 457711.68, 2102530.17, 875372.91, 981345.2, 1999794.26, 2495630.51, 2461468.35, 620087.35, 1509323.09, 1033552.18, 1375458.21, 1686010.02, 1394065.76, 1379488.05, 611258.71, 1933719.21, 1912791.09, 2427640.17, 1837743.6, 808821.5, 773878.58, 1153332.89, 1244390.03, 1285358.01, 895069.88, 1507460.69, 481119.6, 2042581.71, 469598.57, 2057059.53, 1833511.08, 1725268.56, 1063557.49, 1837553.43, 412314.71, 1495536.46, 873643.14, 457216.87, 935266.43, 1530761.43, 922539.94, 1124763.74, 386344.54, 275313.34, 224294.39, 697645.32, 450756.71, 2091663.2, 537224.52, 246124.61, 767338.32, 1448938.92, 1911967.44, 941612.04, 555279.02, 432808.48, 656637.63, 579874.22, 387944.83, 1249696.97, 292859.36, 994801.4, 494145.8, 412456.48, 280472.78, 496851.6, 848358.09, 599629.25, 947815.05, 453943.89, 813845.5, 374556.08, 1799682.38, 565297.54, 1377092.33, 471115.38, 1762155.79, 722496.93, 264214.12, 844373.31, 2066541.86, 1597868.05, 1308122.15, 597856.51, 586289.08, 920128.89, 719888.76, 749549.55, 483660.15, 1122034.48, 1084722.78, 791356.9, 619369.72, 941829.0, 960746.04, 1081322.12, 1079931.63, 874446.32, 1853161.99, 321299.99, 532241.22, 522105.93, 735796.38, 751963.81, 1440963.0, 559285.35, 1010711.08, 531811.85, 833782.7, 813630.44, 522554.04, 1507637.17, 1404516.29, 929690.71, 911969.0, 584000.71, 2027056.39, 1761235.67, 2202450.81, 1315356.99, 1016143.64, 575676.13, 246277.18, 273690.37, 1510397.27, 968258.09, 825283.43, 531600.62, 1224175.99, 1042043.55, 1334571.87, 917317.15, 1198104.22, 1069533.17, 1294105.01, 1472752.01, 505329.66, 2013115.79, 821568.64, 1344483.81, 1434709.63, 892133.41, 753860.89, 1733822.4, 1877592.55, 1354168.18, 471449.98, 454694.21, 1203172.05, 527509.76, 853073.17, 402341.76, 368929.55, 1930814.66, 1149448.02, 1379579.63, 1405168.06, 520284.79, 311590.54, 418925.47, 2290549.32, 1375962.46, 967310.82, 877813.33, 757738.76, 1511641.09, 284309.34, 895020.48, 1090558.57, 968816.33, 1205536.71, 924011.76, 1257921.28, 916522.66, 904650.55, 392152.3, 556046.12, 472511.32, 492792.8, 617405.35, 782796.01, 1750891.47, 1135577.62, 530367.83, 274634.52, 1112449.3, 498056.0, 1419445.12, 554036.84, 1469693.99, 347295.6, 1968045.91, 295339.01, 1933577.2, 1843030.95, 581473.55, 461868.09, 274721.85, 272997.65, 1493525.93, 354993.26, 831425.2, 506273.74, 925916.65, 1361945.18, 654088.02, 1172003.1, 1306194.55, 1220579.55, 515777.97, 642827.29, 1949183.14, 310800.79, 653468.75, 1986445.65, 1672339.27, 977062.44, 685531.85, 2143080.57, 1809989.29, 1366381.6, 565390.4, 1703850.25, 1935299.94, 1345454.0, 517021.3, 1323999.36, 1554837.62, 551799.63, 845252.21, 1051518.45, 1150204.71, 948977.5, 1226997.7, 967729.35, 527041.46, 571190.83, 230519.49, 1407842.91, 579272.38, 427175.03, 1550214.02, 997868.63, 1244542.33, 1148987.46, 942970.63, 640181.86, 905984.49, 1334627.96, 1427383.24, 2363601.47, 771298.98, 793589.18, 555424.24, 1287288.59, 452792.53, 512834.04, 301444.94, 1880752.36, 620908.18, 618949.82, 1132948.48, 484032.75, 847380.07, 1140501.03, 2338832.4, 1206795.74, 1891816.0, 2015563.48, 553834.04, 2068942.97, 1297792.41, 348591.74, 1946369.57, 1245480.95, 2144336.89, 619639.74, 1525147.09, 1781717.71, 538344.1, 659950.36, 971422.67, 956987.81, 1008483.07, 768390.05, 1118313.7, 958007.69, 1157557.79, 1337617.55, 1273279.79, 763479.9, 872113.23, 537455.65, 1109216.35, 246970.97, 1327405.42, 1799070.98, 1355234.3, 1945808.26, 1333315.03, 1183571.35, 1830939.1, 1441559.4, 349214.18, 1477134.75, 475770.14, 1115255.65, 335858.11, 413042.12, 855001.02, 1182694.95, 781694.57, 1146992.13, 1173131.63, 793184.25, 237095.82, 244856.44, 1307928.01, 1111638.07, 655157.32, 1539483.7, 1345311.65, 320831.36, 224639.76, 1931668.64, 1795152.73, 1867345.09, 2039222.26, 867283.25, 324174.79, 1932233.17, 1095091.53, 1376670.27, 542663.53, 2078420.31, 1697229.58, 363064.64, 733037.32, 316687.22, 564538.07, 944100.3, 1858440.92, 982523.26, 899044.34, 1615524.71, 813954.82, 1441032.59, 269624.2, 1171391.41, 405860.37, 1027584.51, 1929738.27, 816838.31, 597855.07, 1893955.27, 2283540.3, 603147.26, 953495.48, 530059.06, 1230613.5, 892393.77, 1470520.83, 1817887.23, 1826241.44, 1162675.85, 1429954.66, 1359158.57, 1494251.5, 416953.51, 498749.62, 926455.64, 434471.38, 1773500.56, 1424225.44, 1311175.93, 1208600.05, 1375307.54, 3766687.43, 435579.7, 281909.79, 1720908.01, 922440.64, 1285976.53, 504750.35, 711470.8, 610641.42, 2094373.0, 1309437.17, 1890273.44, 827738.06, 1870843.9, 1308537.75, 2152229.11, 1280231.85, 1051922.95, 768718.11, 1960587.76, 517869.97, 2010216.49, 329467.82, 713479.91, 436970.1, 1539930.5, 1049372.38, 2039818.41, 1903385.14, 1130022.99, 554972.42, 817485.14, 2205919.86, 852333.75, 2168041.61, 1170456.16, 1670579.82, 1539230.32, 618121.82, 1402372.09, 1925728.84, 911245.43, 495951.66, 263263.02, 1197373.13, 293350.51, 821498.18, 373267.58, 1346783.35, 1092616.49, 1352401.08, 501251.4, 1514259.78, 2034695.56, 979552.34, 629152.06, 426151.88, 438529.81, 777175.28, 628218.22, 1407036.59, 333522.6, 1040143.14, 1621841.33, 1763545.32, 1794868.74, 407764.25, 2052984.81, 1272395.02, 475776.45, 453632.76, 521516.96, 385672.11, 2168709.76, 2658725.29, 2374660.64, 916033.92, 285100.0, 336378.38, 1078182.18, 1563140.85, 1279080.58, 927249.61, 350276.29, 419348.59, 1259941.48, 1360969.45, 503720.98, 1156826.31, 297753.49, 916446.02, 534597.69, 1572966.15, 1310684.1, 325041.68, 1350441.68, 798593.88, 1764984.15, 1360520.56, 558837.27, 444181.85, 1547729.24, 1293404.18, 1336044.75, 1669299.78, 1958823.56, 361311.41, 443557.65, 2103322.68, 855459.96, 1536549.95, 987990.24, 369722.32, 434822.13, 1607343.41, 220060.35, 549505.55, 833517.19, 877235.96, 649128.23, 1095421.65, 1110706.06, 861965.12, 680943.03, 1790439.16, 541120.2, 1876704.26, 1556627.62, 571463.93, 1629391.28, 715876.27, 410497.73, 628494.63, 1621109.3, 712647.97, 835181.18, 276198.74, 1765571.91, 873576.96, 767358.37, 325345.41, 471281.68, 855385.01, 1707662.87, 466322.76, 389540.62, 2105301.39, 1875040.16, 1412925.25, 525545.76, 344642.01, 951588.37, 1460354.67, 1827440.43, 1974960.86, 365098.24, 2077256.24, 325310.3, 2008344.92, 997672.62, 312161.0, 424083.99, 613531.11, 514731.6, 490503.69, 491179.79, 829284.67, 454183.42, 304989.97, 1804246.16, 985896.44, 1568048.54, 761793.94, 958487.75, 972663.59, 355626.87, 1445596.61, 1751369.75, 457030.86, 815915.52, 723086.2, 1048802.62, 1333740.35, 1989674.07, 769848.75, 505068.22, 1198014.97, 435109.11, 583210.87, 1243812.59, 460331.7, 282558.65, 885445.47, 382677.76, 280785.76, 734297.87, 1379652.65, 452169.28, 672062.08, 758510.36, 808030.15, 288247.24, 1487542.53, 888834.07, 739866.16, 1979247.12, 1109574.11, 837548.62, 727772.8, 1004749.41, 587370.81, 1702220.96, 1648602.39, 1764133.09, 718393.61, 1002806.39, 1321102.35, 1127859.69, 320691.21, 463448.59, 286477.35, 1891034.93, 699536.73, 1413124.11, 348895.98, 1531938.44, 1443285.79, 1379651.87, 511049.06, 1757041.96, 558473.6, 979848.71, 1694862.41, 1743882.19, 288855.71, 1373907.21, 600952.06, 1870619.23, 1044639.69, 1837884.79, 1514828.82, 1280465.8, 419497.95, 1483784.18, 912762.76, 651521.77, 1373270.06, 583364.02, 1177340.99, 534740.3, 1503284.06, 973585.33, 977286.07, 505406.72, 570611.23, 356622.61, 1981607.78, 1907351.2, 1855703.66, 328633.34, 1316899.31, 2203523.2, 1031139.3, 672831.78, 1811455.15, 1456793.33, 428806.46, 1459601.17, 307126.34, 541216.92, 1101458.21, 286347.26, 1327424.28, 1377593.1, 1224915.66, 950862.92, 1143724.48, 822167.17, 312078.71, 226702.36, 963910.81, 445530.16, 325201.05, 2115408.31, 513107.2, 2008350.58, 1405007.44, 1086231.47, 1332716.53, 278287.04, 490981.78, 1355391.79, 943912.77, 1021534.7, 2117854.6, 1682316.31, 1900535.9, 1921655.48, 948964.99, 1230011.95, 1639999.47, 1278304.33, 574450.23, 446336.8, 1215354.38, 423175.56, 1297237.7, 300255.87, 415202.04, 423805.22, 616324.24, 2005478.46, 356797.0, 663396.32, 1338716.37, 479263.15, 1376571.21, 1557776.1, 1518841.45, 394645.25, 365248.94, 773367.71, 792299.15, 462474.16, 1212938.67, 338737.33, 1442819.28, 1234875.33, 677971.33, 545570.86, 1371465.66, 303108.81, 699464.43, 1321914.34, 700272.01, 385631.48, 2044155.39, 513073.87, 336241.0, 330604.9, 857797.33, 2251206.64, 1266564.94, 1358816.46, 1645892.97, 1697230.96, 326870.13, 729036.06, 498241.06, 945018.83, 905324.68, 699270.1, 267495.76, 1840131.19, 249798.75, 1851519.69, 508309.81, 2109107.9, 382914.66, 335741.9, 1372504.9, 873065.23, 540149.85, 1863195.68, 923644.6, 959339.51, 1283849.38, 662198.65, 916967.92, 513615.82, 1280414.8, 611390.67, 1814806.63, 2429310.9, 890547.07, 1827797.4, 1115138.51, 1150003.36, 1665502.55, 578002.85, 323915.32, 905756.13, 826626.5, 1789113.32, 751167.12, 554093.15, 749779.1, 659816.15, 1060433.1, 505978.46, 297293.59, 1245898.73, 985594.23, 1543365.9, 997502.47, 511316.29, 2370116.52, 376183.44, 1392543.37, 529418.64, 592981.33, 1048706.75, 1219583.91, 395107.35, 794660.24, 727163.67, 2165160.29, 1311775.83, 946060.98, 1289082.81, 830756.76, 1106575.59, 586061.46, 555954.13, 938604.58, 1314987.4, 1263680.51, 755098.41, 1711769.11, 408838.73, 2149355.2, 2197299.65, 403342.4, 872817.62, 1759777.25, 1012075.12, 1386472.59, 903882.96, 1991824.05, 887979.47, 1320239.51, 2258616.24, 1371405.33, 458086.69, 1130926.79, 595421.23, 1188047.61, 821127.53, 313387.11, 1884734.31, 1802755.11, 1484995.38, 1827521.71, 952766.93, 294882.83, 1088248.4, 1037464.27, 1062629.3, 1106847.62, 1473386.75, 1017593.47, 1522978.54, 1941676.61, 817653.25, 733455.07, 1523101.38, 1949177.13, 485150.01, 310141.68, 1877410.36, 390732.02, 1029849.2, 408679.36, 1913494.81, 2105058.91, 991570.02, 1007257.83, 527117.81, 894865.3, 953533.95, 1244391.83, 448392.17, 1377716.17, 998362.05, 454412.28, 262789.95, 928537.54, 506502.09, 1399662.07, 1214944.29, 380188.69, 1456300.89, 362134.09, 2065191.27, 1141184.66, 436293.4, 806012.48, 773725.08, 213538.32, 1511717.53, 1574287.76, 1788227.6, 1854967.66, 484835.2, 2024554.1, 240044.57, 795133.0, 508576.62, 1631737.68, 1869110.55, 369106.72, 1931104.67, 1213860.61, 1642970.27, 383550.93, 891736.91, 585895.34, 3487986.89, 885608.04, 1593655.96, 1319054.57, 1953539.85, 1061196.47, 1911510.64, 333948.0, 296673.77, 714677.47, 516556.94, 442457.35, 1000582.06, 2148822.76, 928264.4, 294264.2, 1429143.06, 1594968.28, 529707.87, 1522042.57, 592947.75, 237129.81, 1033017.37, 270677.98, 2154137.67, 529852.7, 1547654.98, 611585.54, 1336404.65, 1758971.38, 336189.66, 1267619.06, 660619.99, 651837.77, 1002856.2, 1198709.65, 410804.39, 303643.84, 1351791.03, 519585.67, 1311986.87, 1682614.26, 660632.05, 2035189.66, 574622.56, 1512207.95, 836419.14, 1390934.27, 683300.84, 1325835.7, 244338.31, 984833.35, 1478321.26, 533414.62, 1347454.59, 775910.43, 337979.65, 1704218.84, 675202.87, 1564819.81, 282545.55, 1166117.85, 1065350.56, 1297535.69, 1897429.36, 342214.9, 2131900.55, 1691439.52, 1857500.96, 2138144.91, 517850.83, 1601377.41, 401615.8, 979428.66, 1794355.49, 1620374.24, 615997.29, 877268.29, 451077.21, 851762.28, 1066792.63, 1143819.35, 1557314.58, 1962445.04, 283455.13, 1650894.3, 1983190.56, 1048866.3, 910240.68, 1189646.45, 1263534.86, 982598.88, 1422794.26, 416036.75, 1061134.37, 420515.63, 825584.22, 1200019.74, 468189.93, 1336838.41, 1264272.52, 624114.56, 469311.17, 1886503.93, 781267.76, 1297335.87, 1227469.2, 529384.31, 680254.35, 469563.7, 272190.83, 988764.84, 892070.82, 1331137.96, 2062481.56, 902109.69, 2302504.86, 329183.92, 1426405.46, 449516.29, 883683.35, 339976.65, 396968.8, 2082355.12, 535937.25, 1430851.11, 1704753.02, 589091.04, 321110.22, 1537139.56, 642776.4, 655811.95, 2432736.52, 1523979.11, 958225.41, 3818686.45, 468428.3, 955294.7, 1248901.98, 558671.14, 1935869.1, 480239.88, 1069112.0, 1244381.98, 2156035.06, 463561.48, 638144.98, 1337506.74, 660838.75, 616345.25, 1090915.09, 1364445.98, 1133807.03, 435972.82, 303908.81, 574955.95, 575997.78, 562173.12, 527953.14, 1306551.71, 1229257.7, 527572.25, 1527845.81, 918049.28, 1808250.71, 239431.85, 1122053.58, 1502078.93, 303043.02, 1455119.97, 1385769.03, 668390.82, 970641.34, 688940.94, 1414564.53, 1946070.88, 1848426.78, 1754879.45, 1792345.3, 1391813.69, 1524390.07, 1464616.59, 1425559.02, 1688531.34, 1513635.64, 1828052.47, 827717.85, 273079.07, 966780.01, 658997.55, 929096.9, 1939980.43, 1313729.72, 505405.85, 893399.77, 1158698.44, 918335.68, 391860.04, 314607.22, 585548.79, 1863840.49, 1436383.84, 497374.57, 407589.16, 2020332.07, 557166.35, 2246179.91, 912857.1, 996937.95, 1282378.71, 1394393.84, 757369.87, 1310087.0, 1230245.74, 649791.15, 1242746.06, 1436311.76, 1468350.36, 913616.32, 1661767.33, 813756.09, 1415204.88, 427491.04, 2236209.13, 848289.41, 1187776.19, 923600.02, 1536176.54, 1370659.54, 575570.77, 1375101.26, 976393.43, 1351407.79, 369350.6, 918006.9, 864881.24, 562633.67, 2137809.5, 556925.19, 1327719.34, 1660081.29, 1624477.58, 1372043.71, 394918.83, 988392.99, 1230118.02, 624099.48, 754236.7, 411116.95, 2224499.28, 1176588.25, 360256.58, 1811562.88, 1246062.17, 667353.79, 1461393.91, 588363.62, 1048101.39, 630740.11, 1740063.1, 1149427.48, 1680764.06, 1934099.65, 1511041.69, 328498.92, 820188.42, 453016.91, 981615.81, 1408907.89, 1021391.99, 432424.85, 594744.89, 315645.53, 1302499.23, 1295605.35, 924174.4, 1037549.71, 622437.08, 337825.89, 507335.75, 2163384.17, 1267675.05, 667151.46, 1213486.95, 1384721.84, 306827.36, 277137.86, 981646.46, 2121788.61, 298080.45, 453308.15, 570816.34, 491115.86, 903864.02, 1677472.78, 1588430.71, 1388553.11, 1317379.68, 412882.31, 429305.82, 312361.88, 1116295.24, 1220815.33, 1484708.38, 717207.19, 1544653.37, 2005341.43, 941008.85, 712312.89, 1772143.94, 552985.34, 1539387.83, 1449142.92, 2189353.63, 2055952.61, 1344580.92, 298697.84, 491449.94, 1033171.07, 981210.57, 1999363.49, 2207214.81, 805028.74, 643603.69, 899761.48, 1908278.27, 241937.11, 361067.07, 1199845.29, 726422.55, 1277959.42, 522816.85, 1841369.99, 710496.97, 802583.89, 342385.38, 2095591.63, 1277882.77, 1445249.09, 261131.09, 684348.92, 1543947.23, 329613.2, 1635078.41, 535769.32, 1350646.16, 859258.17, 489079.23, 306098.17, 1246242.61, 558691.43, 481144.09, 2081534.65, 541406.98, 359949.27, 1290684.95, 1857533.7, 1034119.21, 503295.29, 1239423.19, 437222.94, 589554.29, 820288.35, 366367.55, 2094515.71, 340497.08, 1419236.9, 449355.91, 500945.63, 1785823.37, 1794962.64, 725043.04, 994610.43, 1707481.9, 768070.53, 1011201.12, 425215.71, 1492060.89, 801098.43, 890689.51, 2066187.72, 816138.33], 'residuals': [21804.13020000118, 901.4919999998529, 127685.18180000107, -98766.14439999929, 8377.970800000301, -15554.738999999594, -274171.19390000124, -42379.46069999994, 70855.55439999956, 11902.726499999873, -11461.535599999945, 27388.914000000397, 149060.2621999986, -47892.17960000003, 53212.467700000154, 142008.72700000042, -284.5684999997029, -40347.5083999997, -48168.401100000134, 30002.379800000344, -9681.482700000168, -33112.064200000255, -103514.97699999972, 23337.66690000042, 36187.64029999985, -59758.040199999465, -270249.647700001, -399613.79480000166, -47999.92299999995, 106156.07909999997, -50111.13749999914, 9034.796100000385, 13000.341899999883, -11850.708799998742, 51342.901600000914, 53206.192100000335, -74825.63359999866, -9333.490799998399, -104354.40859999927, 14519.536300000735, -26899.73979999975, 9384.190200000885, -36692.05240000039, -18028.862700000638, 41760.438100001076, 10168.07640000002, 47901.53340000077, 9517.35230000061, -133501.55139999953, 29821.971799999825, 14751.183500000276, 19657.261900000507, -79590.69439999992, -15852.4752999997, 15628.73999999999, 33293.77919999993, 56229.856000000844, -89608.68490000011, 32504.357699999353, -40532.8540000004, -32509.737900001695, 44070.74560000049, 46739.861500000115, -32082.867200000328, 6197.495000000112, 22542.182400000165, -6483.47070000018, 17503.30019999959, -72542.87340000155, 1354.5198000001255, 466.5416000003461, -28365.69580000022, 65363.43460000167, 72698.40060000028, -12262.336700000451, -37786.3171000001, -3269.9257999997935, 430195.53219999943, 34677.27459999977, 31011.13000000018, 48395.55230000033, -1891.728900000162, -84563.97849999939, 26965.09500000009, 1644.9339999998338, 11784.798399999796, 22095.6590000001, 50678.02609999955, -67299.28729999997, 6339.36659999995, -2802.1511999999057, 16165.743299999856, 13154.4515000002, -153365.35959999938, -547.9348000002792, -35773.787600000156, -39253.471400000155, 111356.61170000094, 9955.168999999296, 29111.26199999987, 65474.075500000035, 8890.704800000181, -6493.353400000138, 99554.52829999942, -8037.056000000099, -17574.415200000163, 3680.7726000004914, 66130.43499999994, 43507.83619999967, 13156.503099999914, 87861.89659999963, 69762.04420000105, -81268.70800000103, 1677.6694999989122, 18331.31449999963, -58462.95059999917, -26340.955600001384, -1767.646599999629, 5712.581500000553, 211.16920000012033, 13321.78330000001, -31740.80819999997, -6892.574700000288, 39107.54740000027, -46156.447799999616, 136937.54850000027, -52274.16240000032, -76894.25669999956, -14398.110499999602, -58819.87939999974, -22761.274499999476, -6854.158199999656, -13793.375300000422, 19332.947799999733, 26444.618299999624, 31026.9212000001, -24228.13899999985, 126265.10130000138, 8995.407700000098, -32113.578499998897, -27136.628899998497, -5309.618699999293, 28607.56419999909, 18389.57280000008, -10455.136999999755, -58832.19350000168, -19554.404700000072, 66058.45110000041, 2764.516399999964, 128931.96589999995, 153727.89049999975, -144370.0429000021, -12694.281899999827, -371404.57670000056, -59121.188899999834, 22450.910099999746, -184508.79989999835, 12304.238100000424, -73086.09049999923, -17726.24490000028, 59064.390899999766, -49324.092100000475, 169.10710000048857, -29707.313399999868, -487954.9943999995, 110200.0375999983, 88214.92239999957, 44383.92290000024, -15924.222100000188, 138032.22349999985, 73433.35250000039, 76346.3110000001, -36046.695600000035, -27807.832200000063, -81349.71890000068, 3714.7744000002276, 4419.978900000919, -14840.9514999995, 31212.741000000562, -20460.190799999924, 3803.793999999936, -106515.02379999822, 25045.640200000256, -6732.522799999104, 8670.525600000634, 98466.9765999997, -350723.2609000015, 22390.604299999948, 22272.933900000528, 236731.71349999867, 23541.203199999873, 114113.23100000038, 62697.80210000032, 18201.791300002253, -6233.649399999878, -104222.23349999974, -29548.436499999894, -33911.686499999894, -20284.802400000335, 11977.9461000007, -59338.9850999997, 7879.068300000159, 217715.42489999952, -16524.690100000706, -20735.70089999982, 9127.000500000257, -84238.26760000037, 45984.3450999998, 53208.2107000004, -3156.6657000000123, -214211.5164000003, -11820.243699999875, 17239.088300001342, -5645.236199999927, 229008.13540000073, 380302.68289999827, -38513.57640000002, -4625.660399999935, -21669.59909999979, 7248.133699999948, 555.347600000212, 23232.16320000036, 49188.40869999991, 13766.173400000029, 116760.62389999989, 84068.85569999996, 44291.94229999953, 67216.65349999885, 151326.75760000106, -184796.39140000113, -7905.778299999831, 83486.32780000055, -218371.28699999955, -41012.052999999956, 194855.9209999994, 13009.688499998767, 8986.91149999993, 14728.724300000235, -4359.569499999983, 225463.50480000023, 81049.06849999819, 75041.85609999998, -17471.25709999993, 113993.9737000009, -66552.14830000047, 97656.33329999982, -13414.91429999983, -10226.873600001447, -150954.96330000018, -7762.844799999613, 32477.33640000003, -103653.83460000076, 86709.03919999977, 154700.76040000026, 90698.38949999982, -28816.30929999915, -31506.135099999956, 33200.37769999972, 29969.872400000284, -64740.68499999982, -71351.42239999992, -20300.877699999895, -315402.5827999993, -4686.996199999936, -57021.61710000038, -142114.21000000043, 44458.10169999907, 96937.1468000008, -14739.055600000313, -6986.592900000047, -38715.89899999881, -20406.63990000263, 14121.005700000213, 21391.6026000001, -38586.953800000076, 2039.9895999990404, -24620.828000000212, 32992.8682000002, 18999.508300000045, -46677.67440000037, -41210.34510000015, 4965.438799999538, 266162.7540999993, 30206.153099999705, 22667.69280000066, -253.11829999950714, -412218.69279999984, -21884.99299999955, 175992.78130000108, -18625.570399998687, 686.7211000001989, -257060.43120000022, 47610.88240000163, 4825.103100000415, -387.95049999980256, 79164.03020000062, 100573.88149999827, -9556.391599999391, 22650.18589999969, -25395.394899999723, -22899.91169999994, -78360.3798, 6846.457000000635, -21250.86939999927, -23500.64239999978, -12941.132899999968, -40201.66530000046, 21080.235200000112, 38299.00979999965, -77938.65439999988, -10481.786100001307, 6509.685100000002, 95925.2527999999, 31160.96300000022, 23477.95549999969, 25999.291300000186, 157425.14779999945, -254950.8254000002, 22649.793800000567, -29383.025200000964, -78316.11270000017, 12533.79899999965, -67894.93629999994, -113996.5288000016, 27728.76250000007, -64774.486099999864, 63542.16569999966, -249550.08520000032, 1785.8263999998453, -26620.468200000003, -27277.186400000006, 73698.0847999996, -6813.78050000011, -74239.23370000045, 28701.766400000313, -13981.3125, 12279.539900000236, 2758.9966999998724, 9947.417699999409, -104759.61090000067, 30433.3946, -9028.232600000454, 2596.0821000004653, -14095.82759999967, 22936.707200000004, 38935.10840000049, -52977.42940000002, 28295.282100000884, 30390.66090000025, -111150.93160000001, -35516.01259999978, 10854.048000001116, -10760.344200000865, 58597.05789999897, 10979.9402999999, -34108.61400000006, -102412.95100000012, -5712.247399999935, 5125.900700000115, -1384.1788999998826, -66702.04739999969, 7894.861500001163, 121254.82629999937, -76430.60769999924, -4854.596799999243, -91045.99010000005, 11624.482800000114, -44156.01470000041, 20241.569399999687, -37084.774999999674, 20656.70509999979, -144836.6875, -263622.63990000007, 91907.19229999895, 14059.812700000359, 146222.71550000156, -130214.43489999976, -35916.99999999988, -46186.177299999865, -29451.327099999937, -30280.049400000134, -43052.76130000001, 3614.5539000004064, 127907.96740000066, -52240.58249999839, 138599.48520000046, 42194.06160000013, -61557.74319999851, 22062.777600000845, -45001.549000000115, 6332.960700000171, 532.4454999995651, 12303.509499999927, -97739.22340000048, 169167.19189999974, 50135.68980000005, 15388.339399999939, 63607.281799999066, -681544.621300003, -5736.384899999946, 540.964499999769, 13451.160899999319, -39558.10390000034, -72195.94040000043, -4370.927400000161, 49513.30179999897, 9880.432799999486, -41780.66529999953, 25472.010899999877, -8335.840199998813, 10971.793500000029, 47313.45860000048, 277051.29779999936, -124378.10049999994, 5682.234600001248, -40781.34960000054, -26953.485700000194, -7602.269200001145, 25284.11270000029, -69646.40919999871, -5431.575399999798, -53415.772799999104, -37259.651399999624, 81527.34780000057, -23433.139099998865, -6213.531000001123, -408583.96310000075, -141673.82879999967, -31582.800500000594, 17495.597199999727, -214253.82800000138, 9574.611999999383, -213870.8702, 161740.10569999903, 162085.17310000025, -130405.5288000016, -42477.40169999958, 35188.86869999906, -59335.292800001334, -30358.968199999537, 4809.278300000296, 24325.226599999936, 140474.43709999998, 33358.818400000455, -62629.51000000001, -13570.25780000008, -42416.519500001334, 45301.756299998844, -23994.10609999881, 6706.040600000299, -78052.07239999925, -276963.2567000012, -46299.047099999734, 59627.47819999978, 1012.7367000002996, -2709.9611999999033, 127093.04009999929, -57710.52960000001, -61531.920200000284, -20926.23330000008, 13985.614599999855, 14940.937199999345, -122331.63329999964, 82554.45370000089, 24504.013599999715, 23817.37990000099, 104155.16479999991, 46143.39580000017, 27487.140300000436, 51919.15779999987, 20700.547799999884, -202318.76879999787, 91011.42950000335, -102858.86729999864, -55981.6393000012, -16181.166600000171, -3539.4121999999043, 41835.846799999475, -135691.36989999958, 89735.93999999994, -20769.445599999744, 5405.567899999849, 12721.083599999663, 131194.19330000016, 60179.079799999716, 39845.96279999975, -67121.35130000021, -23576.348899999633, -229983.48710000026, 44702.78520000004, -135595.3122000005, -5961.7695000001695, -17392.316899999685, 183682.86250000075, -10693.117599999881, -40377.08840000117, 82989.7994000006, -23561.548800000688, 28030.389600000344, -85002.8833000001, -157444.84970000107, 155717.99570000055, 160632.4021999999, -31927.740899997996, 5035.390299999679, -29480.821100000117, -152376.00409999886, -43698.70320000022, -57975.50750000053, 14111.3703000003, 45783.16640000028, -16216.017600000254, 27474.811799999326, 42823.17899999986, -35442.48360000062, 43792.224500000244, -114342.42309999967, -38923.63229999971, -34716.06840000022, -29821.17670000065, 23536.072199999704, -48900.556299999706, 126498.3658000005, 36525.324399999925, -50069.6903000013, -229660.37730000145, -6048.596900000237, -71568.20000000065, 40034.778700000024, -3085.0276000000304, 87369.16039999982, 186422.46770000015, 35248.77739999967, -33706.01939999999, -30179.309399999707, 79696.49950000062, -61754.11170000001, -25915.296100000036, 3278.2967999996617, 27635.540199999523, 41828.7892999996, -25123.769600000698, 36422.324899999716, -8264.497900000075, 142162.2724999981, -199088.64859999972, -61388.95670000068, 14083.580300000263, -7860.470200000098, -7982.780200000154, -57289.97990000248, -75427.02450000006, 100112.80939999968, -81843.67979999975, -464052.75180000043, -19371.044799999974, -49257.71920000017, -9486.639399999636, -35797.46739999973, 47957.83380000002, -48853.56019999983, 15221.289000000223, -6964.13989999966, -17795.631199999712, -46711.77709999948, 60509.65770000045, -11603.392899999744, 3083.798199999612, 3165.3115000003017, -84689.58139999979, -93088.66879999952, 4578.210800000932, -65489.19179999945, -2837.208299999824, -1499.1501000018325, 32698.157699999167, -23593.16820000019, -187153.4580000001, 17298.3265000002, -100268.44810000004, 16264.122600000119, -8277.48300000024, 18911.912700000103, 32484.380100000068, -31497.07380000013, 1463.7975000001024, 33393.27450000006, -102394.92850000062, 59494.88970000006, 26448.230099999986, 44695.47630000056, -6499.983399999794, 4013.9416999999085, 15283.367699999711, 49293.179400000954, 78.64309999998659, -4550.775599998888, 33172.21699999925, 34866.26849999942, 3859.6927999999025, -79843.5249000017, 15164.322799999965, -23982.368700000574, -43707.50509999972, 2981.7911000000313, -11422.825499999686, -13803.102700000163, 37747.20759999973, 5306.126999999746, -288441.8579000004, -43975.099299999885, 99874.37109999941, -39018.00730000029, -40246.78620000079, 35754.14909999864, 112550.9974, -1196.902100000123, 63930.618000000075, 803.7744999997667, 175992.92630000063, 3506.821800000267, -5177.824600000167, 4936.130600000441, 61699.202400000766, -21599.218900000444, 21573.47319999896, 16789.86570000014, -115328.10309999902, 12134.29610000085, 3445.689600000391, 2402.5983999983873, 107600.36490000016, 25849.267099999997, -35806.264200000325, -68571.3470999999, 29546.78870000015, -60887.19940000004, -33992.9523000014, -42306.35290000122, 35353.781099999556, 10325.956899999524, -42515.91949999961, 74435.7980000003, -37758.900900000706, 10687.720599999651, 122885.75080000027, -182093.15889999922, 83431.6223000004, -6188.426900000311, 5850.283700000378, 115665.31839999987, 23739.1818999995, 5619.563700000406, -35484.45969999989, 3740.9615999986418, -60002.66720000049, 63106.372799999546, -6199.4319000001415, 148733.61959999963, -169234.26259999978, 33828.80710000009, 11236.210900000064, 2036.1182000013068, 7956.488199999789, 13227.52689999988, -56657.47809999855, 795.6315999999642, -84664.55240000004, -9646.013800000306, 12028.549499999848, -15730.325300000375, -11165.610700001242, 9175.830599999754, 75519.29740000016, 211406.88649999886, -27518.44229999988, 44929.0823999999, 21529.46640000021, -16026.92510000011, 6552.470600000117, -49860.1513999998, -147743.93209999916, 4601.328299999761, 118112.77029999858, -50338.15480000083, -67100.04890000029, 79776.86350000114, -3194.0924999999697, -11987.006399999955, -20141.17009999999, 3781.4158999993233, 54864.23550000065, -19276.854400001, 97916.9664000005, -21550.589700000128, -220130.61270000064, -94198.87929999991, -61771.84300000011, -28061.466099998914, 20814.37919999985, -75406.87609999947, -21075.662099999783, 56786.176100000506, -18641.823299999756, 90667.19310000073, 4560.11720000027, 21761.322200000286, 655.4667000000481, 14769.946900000214, -53755.23930000025, 28742.918099999893, -70600.01579999959, -24922.539399999427, 45541.9113000005, -73679.26139999926, 46947.620200000005, -135696.37319999863, -17386.041400000395, 7625.441500000132, 15113.647899999982, -14423.740699999616, -6259.318199999514, 141042.65950000053, -2686.0173999999533, 20372.57969999942, 14484.899699999485, -15430.81230000034, 18519.36020000046, 8012.81410000124, -15775.921799999836, 43213.70830000017, 19385.10139999981, -4673.545499999775, -19219.301799999957, -14508.518800000427, 7245.4393000000855, 3129.6483999999473, 9455.839700000186, -36759.365200000466, -194219.82409999985, 118012.87480000057, 22681.59029999934, 84609.63890000037, -81103.07409999962, -28920.495799999742, 17016.717599999974, 7093.390100000193, -35734.7419999995, -140548.5470000005, -7003.685899999808, 9116.111999999906, -324280.9252999991, 25153.218200000003, -6941.2882999996655, -498.292500000156, 115175.55829999829, 29403.755700000096, -23187.018299999996, 11006.073300000746, -26479.92090000061, -64691.51809999999, 302505.54009999963, 24075.275200000848, 32691.581300000427, 4210.276900000172, -38807.45030000049, 48923.263200000976, 1510.9165999998222, 108526.5831000011, -17739.009899999714, 4017.0401999999303, -418384.63549999846, 81461.55600000045, -94093.73939999985, -6398.573300000513, 31045.9534, -220288.12490000017, -20159.379300000495, 5380.40620000026, -14630.826000000583, 44534.779400000116, -361574.1914000006, 14774.117999999784, -14492.66490000009, 855.7812000000849, -86536.53010000021, 9910.626399999484, 40002.52190000034, 9790.031599999988, 15478.971199999796, 92509.79239999969, -34742.892599998275, -200230.75549999997, 59708.19989999983, -171282.3839000021, 14617.692799999553, 9729.783900000155, 32461.873600000516, -5184.929100000183, -18741.094299999764, 45033.52040000027, -14750.370099999709, -29799.606599999708, 42218.8093000002, -50435.108000001404, 51712.9170000006, -44386.60009999992, 8660.889500000514, 41035.51050000009, -39441.164499999955, -57477.53240000014, 1910.079400000046, 29246.298700000392, 130846.88680000044, 1460.6708000001963, 20228.611399999936, 143868.30069999793, -6258.332699999912, -241626.7704000012, -19033.181499999482, -29558.58429999993, -2253.1932999999262, -32421.173899999354, -20888.985799998976, -2346.785500000231, 29373.950799999875, -323019.1034999988, -39038.9511000003, 58964.571199999424, -78869.76660000067, -3229.161099998746, 23079.150399999984, -209001.3837000006, 17474.75750000053, -24651.641999999294, -45001.3662000004, 9427.898000000161, -18946.990699999733, 13235.332699998748, 79015.45549999853, -10969.635799998883, -138009.8348999999, -8284.375600000203, -108182.27739999967, -43116.455000000424, -109597.44469999941, 14939.25579999946, -107991.23060000013, -40439.65849999944, 1839.5705999999773, 143289.52799999877, 126.431100001093, 17838.00249999971, -202152.43260000017, -186027.4909999983, 14896.0610999997, -6020.183799999475, -346732.2409000001, 22954.14269999985, -67713.61079999967, 18203.955699999817, -237712.26199999987, -231228.21320000128, -40652.76430000039, 43188.17770000023, 15816.828100000042, 62629.28549999965, 15849.48280000023, 106408.64249999961, 4700.06980000023, 109887.87420000043, 16600.493099999265, 167222.21449999989, -2858.590099999914, -44293.44470000046, -2472.1037000002107, 57709.566899999976, 60576.31349999993, -16510.06870000012, -94261.16240000003, -7665.18679999985, 44456.3133999994, 63196.13030000054, 16017.297500000102, -36393.52520000073, 91343.59660000028, 48751.26790000027, 227650.10400000028, -103451.38809999963, 73589.2200999998, 106422.13049999904, 48761.82300000003, -25016.280499998014, 9050.80920000028, -4727.638800000073, -7448.160900000134, -170192.33830000018, 129266.85569999879, -26080.939700000337, 93220.85149999987, 173680.35209999932, -172247.0177000023, 30567.51019999961, 8641.397100000293, -15782.746699999785, 126421.64599999879, -128531.58460000018, -133869.9982000005, 3325.9458999994677, 190695.8895999994, -21741.022099999944, -51538.075500000035, -35167.46539999999, 2908.500099999772, 7611.414199999999, -3352.368000000075, 12057.208700000192, -43691.33230000071, -50775.291999997105, 22791.60600000026, 1770.4196000001975, -32834.882899999386, -102084.01169999968, -2869.7573000002885, -87500.49589999975, -5668.600000000326, 27531.982300000032, 46418.39440000022, 27354.797699999996, -3973.9030000008643, -10532.841100000252, 54918.0438000008, 6253.336800000165, -78386.33089999994, 18849.749399998924, -31932.67429999984, 95851.33359999908, 59107.41960000049, 67336.06969999988, 1231.8544000001857, 19612.34189999895, 4869.895399999514, -934.4004999998142, 142875.90060000028, 25358.38220000005, 21832.55989999976, -108262.56969999825, -19193.940200000186, -23893.274999999907, -12466.525799999712, -130510.25249999925, 26831.857899999944, 500375.2007000025, -4409.769599999883, -9346.58839999931, 26941.766200000246, -103580.22200000018, -184874.04149999982, -4182.351800000179, 7794.144299999578, 12918.389599999879, 385.9153999998234, 614052.4773999981, -15275.398500000243, 5045.903499998618, 13477.931400000176, 5385.084200000158, 73950.18410000042, 34873.55370000005, 7749.146300000371, 12928.671800000418, -165892.01269999845, 130215.0680999998, -7555.601299999515, 44549.15169999888, 8143.788099999831, -71099.94280000054, 38871.98609999998, -38048.05039999937, 27736.432699998142, -22076.110600000713, -30215.12120000017, -20306.063799999887, -6072.618500000157, 44381.30250000092, 32426.857699998887, -34112.12900000112, -329002.3117000009, 14992.626400000649, 4441.877399999998, 128668.04150000028, -103934.62839999981, -48710.535599999595, 11416.716099999961, -51575.56050000107, 326041.93819999974, 31453.72410000011, -103944.3582999981, 19666.85000000015, -11682.079399999697, -1201.7341999997152, 110581.19829999981, 35578.413000000175, -9726.644199999922, -28476.663200000534, 79069.20049999957, 2239.404199999757, -34751.54810000025, 166592.31890000077, 21094.8652, 56393.4524999999, -28037.045600000303, 1761.770899999654, 41645.03990000032, -7286.920299999823, 15726.61689999979, -18548.52439999953, 45946.34990000015, 52188.87649999978, 62959.218500000425, 4568.035499999416, -245434.54909999995, -22130.644299999694, 35085.453500001226, -55617.94509999949, -21012.513399999705, 43947.70830000023, 38449.31519999995, 96265.50999999885, -22512.153399999428, -65589.7350999997, 183964.06949999975, -53404.50129999977, -9479.155499999935, -64278.59659999912, 1121.2196000000695, 644.1774000001606, -250024.81989999907, 83844.35850000009, -77247.61120000109, -382267.57190000126, 47871.569000000076, -62195.107099999324, 56808.71599999932, -9961.904699999606, -95641.7435999997, -8935.526100000367, -119156.37349999975, -8013.062699999893, 80190.1838999982, 30874.746899999853, 20772.458600000944, -11862.154300000519, -17332.647799999453, -499.98350000032224, -27404.901099999435, -1770.204700000817, -62157.350799999665, 12386.953600000357, 44071.3215999995, -5626.6002000003355, -1522.2844999999506, -6392.296499999473, -9256.834500000172, 54142.131300000474, -36725.17939999979, -12963.894900000247, 32205.334700000007, 66823.56060000078, 165533.47939999937, 7622.4429000002565, -86484.78790000093, -56337.56409999984, 1648.5221999999485, 61739.19099999964, 18168.5765999984, 8681.235400000121, 29729.94529999979, 21380.916100000148, 11768.656700000633, -2776.507400000235, -12283.380200000713, 158881.23459999962, 15845.188199998112, -112093.28299999982, -62299.17290000059, 21116.976699999766, -42964.46689999942, -215544.86520000105, 2456.5064999996684, -35371.16879999987, 6050.96569999936, 15386.842199999897, 22213.6217000013, -11612.045300000347, -23727.959500000696, 65786.15739999828, 566337.7893000003, 137178.50399999938, -27590.637200000347, 68782.11879999982, -54172.92069999955, -1454.9513999999035, -22044.905299999635, -57784.89859999984, -61817.00210000062, -62303.78350000037, -36415.25119999936, -1906.2373999996926, 4304.355599999428, 26503.77200000023, -63646.64079999924, -14575.038700000267, -17120.906299998984, -102154.71110000019, 11699.74140000157, -12919.873499999754, -10925.882100000745, -43072.872800000245, -49620.785100000096, 36599.633099999046, 14980.907800000627, -74641.94179999968, 1740.315899999463, -83297.03089999873, 37155.995300000184, 21398.778599999612, -2806.1464999999152, -97070.06279999949, -27614.022600000142, 33026.21939999936, 78108.40569999989, -65210.80519999983, -116792.08590000006, 615.0579000003636, 32687.377000000793, 2213.0684000001056, 138622.45980000054, 20759.02080000023, -28802.832700000028, 19692.73289999913, 36533.09829999972, -59048.06709999987, -43844.70540000021, -66232.42399999942, -55234.45440000086, -19638.959700000472, 31569.544399999082, 10394.428699999815, 45919.47150000057, 23070.892199999187, 25418.205900000175, -31405.266500000143, -1855.7671999998274, -36779.40439999988, 85570.07629999821, -15871.212400000135, -65569.89889999968, -11904.718400001293, -3937.044900000328, -59037.84380000038, -82873.9954000003, -82457.29739999934, 39778.331400000956, 51470.97129999916, 136710.27810000046, -318501.66630000086, -205791.18439999875, -48752.70589999994, -2138.753099999798, 11174.761800000211, -1768.3770999997505, 30526.777499999618, -24203.170999998925, -30566.521800000337, -17046.175499999896, 27100.645500000333, -25966.266299999785, 608.9123999997973, -130862.91600000043, 56847.23239999998, 32657.400799999945, 1294.6682000000728, -32957.41940000007, -1398.158200000471, -330882.7268999992, 62973.71490000072, 7139.3181999988155, 14816.360299999593, 51132.07849999936, -1909.6875999994809, 19195.24480000045, 79584.46410000068, -75841.95979999984, -3041.6403999999166, -31014.723000000115, 50484.43310000037, 24460.55499999982, -12268.407200000132, -64002.87090000091, 75826.40890000015, 30175.594100000104, 21128.131900000153, 9441.285399999935, 1759.3044000001391, 10825.409100000164, 3135.9729000008665, 67874.92500000121, 89403.48749999981, -8881.629499999923, -122393.33700000029, 93196.42149999854, 4642.52600000042, 11885.959300000104, 162712.8071000008, -25170.475399999996, 70444.59449999826, -6176.181599999545, -146836.4197999984, 62068.47779999976, 37712.602200001944, -3477.7234999999055, 56526.831500000146, 46103.74940000044, 8169.3678000003565, 138899.19959999784, -74262.02800000133, -43609.21879999933, -51509.39029999997, 53292.04879999987, -45884.21920000017, 55908.95569999999, -41631.485900000145, -16465.334399999818, -35775.69090000063, 41985.196700000204, -1476.7496000002138, -39227.06180000026, -11760.777599999448, 2647.087100000703, -13996.891399999964, -90328.37169999955, -44114.71109999949, 89420.5959999999, 10101.26649999994, 3842.64280000038, -198408.49790000054, -8062.319799999881, -90432.65980000165, -22806.84000000026, 38709.004699999234, -104725.5513000004, 21996.693799999543, 14194.157100000011, 24491.216199999908, -7038.164399999776, 14156.5638999996, 98860.3888000003, 42930.32039999985, 71724.66380000039, 18599.112899999134, 27460.476499999873, 43546.50100000156, 63751.60440000001, 86113.79470000044, -6610.301200000104, 51231.86130000069, 50567.87879999983, 13604.171399999643, 766.674699999392, 5064.261700000148, -52875.86500000139, -19254.014600000228, 46954.78119999962, 114874.76240000036, 168170.80240000132, -62814.58110000042, -11438.542799999821, 60908.33499999973, 9592.879199999967, 129207.16330000048, 13779.621899999562, -10100.046900001355, -28015.342199999606, -135272.1839999999, -118579.62510000053, -25904.67840000009]}\n"
     ]
    }
   ],
   "source": [
    "print(residual_plot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = residual_plot_data['y_true']\n",
    "residuals = residual_plot_data['residuals']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a fitted model 'model' and residuals 'residuals'\n",
    "# For example:\n",
    "# model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Create a histogram of residuals\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(residuals, bins=20, edgecolor='black', alpha=0.75)\n",
    "plt.xlabel(\"Residuals\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Residual Histogram\")\n",
    "\n",
    "# Create a density plot (kernel density estimation) of residuals\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(residuals, '.', markersize=3, label='Residuals', alpha=0.5)\n",
    "plt.xlabel(\"Observation Index\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Density Plot\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('residual_plot.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestRegressor' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ayush/BTP-2/backend/functions/temp.ipynb Cell 62\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayush/BTP-2/backend/functions/temp.ipynb#Y116sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cooks_distance_data \u001b[39m=\u001b[39m reg_util\u001b[39m.\u001b[39;49mget_cooks_distance_data()\n",
      "\u001b[1;32m/home/ayush/BTP-2/backend/functions/temp.ipynb Cell 62\u001b[0m line \u001b[0;36m2\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ayush/BTP-2/backend/functions/temp.ipynb#Y116sZmlsZQ%3D%3D?line=218'>219</a>\u001b[0m cooks_distance_data \u001b[39m=\u001b[39m {}\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ayush/BTP-2/backend/functions/temp.ipynb#Y116sZmlsZQ%3D%3D?line=219'>220</a>\u001b[0m cooks_distance_data[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test)))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/ayush/BTP-2/backend/functions/temp.ipynb#Y116sZmlsZQ%3D%3D?line=220'>221</a>\u001b[0m cooks_distance_data[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m OLSInfluence(regressor)\u001b[39m.\u001b[39mcooks_distance[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/ayush/BTP-2/backend/functions/temp.ipynb#Y116sZmlsZQ%3D%3D?line=221'>222</a>\u001b[0m \u001b[39mreturn\u001b[39;00m cooks_distance_data\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/btp2/lib/python3.11/site-packages/statsmodels/stats/outliers_influence.py:731\u001b[0m, in \u001b[0;36mOLSInfluence.__init__\u001b[0;34m(self, results)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, results):\n\u001b[1;32m    729\u001b[0m     \u001b[39m# check which model is allowed\u001b[39;00m\n\u001b[1;32m    730\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m maybe_unwrap_results(results)\n\u001b[0;32m--> 731\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnobs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_vars \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39mexog\u001b[39m.\u001b[39mshape\n\u001b[1;32m    732\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mendog\n\u001b[1;32m    733\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mexog\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestRegressor' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "cooks_distance_data = reg_util.get_cooks_distance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
