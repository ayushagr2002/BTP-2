{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import RegressionExperiment\n",
    "from pycaret.classification import ClassificationExperiment\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../Datasets/68071.csv')\n",
    "# target_column = 'income'\n",
    "model_name = 'adult'\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_91e8f_row11_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_91e8f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_91e8f_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_91e8f_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_91e8f_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_91e8f_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_91e8f_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_91e8f_row1_col1\" class=\"data row1 col1\" >income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_91e8f_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_91e8f_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_91e8f_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_91e8f_row3_col1\" class=\"data row3 col1\" ><=50K: 0, >50K: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_91e8f_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_91e8f_row4_col1\" class=\"data row4 col1\" >(48842, 15)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_91e8f_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_91e8f_row5_col1\" class=\"data row5 col1\" >(48842, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_91e8f_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_91e8f_row6_col1\" class=\"data row6 col1\" >(34189, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_91e8f_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_91e8f_row7_col1\" class=\"data row7 col1\" >(14653, 67)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_91e8f_row8_col0\" class=\"data row8 col0\" >Ordinal features</td>\n",
       "      <td id=\"T_91e8f_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_91e8f_row9_col0\" class=\"data row9 col0\" >Numeric features</td>\n",
       "      <td id=\"T_91e8f_row9_col1\" class=\"data row9 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_91e8f_row10_col0\" class=\"data row10 col0\" >Categorical features</td>\n",
       "      <td id=\"T_91e8f_row10_col1\" class=\"data row10 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_91e8f_row11_col0\" class=\"data row11 col0\" >Preprocess</td>\n",
       "      <td id=\"T_91e8f_row11_col1\" class=\"data row11 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_91e8f_row12_col0\" class=\"data row12 col0\" >Imputation type</td>\n",
       "      <td id=\"T_91e8f_row12_col1\" class=\"data row12 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_91e8f_row13_col0\" class=\"data row13 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_91e8f_row13_col1\" class=\"data row13 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_91e8f_row14_col0\" class=\"data row14 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_91e8f_row14_col1\" class=\"data row14 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_91e8f_row15_col0\" class=\"data row15 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_91e8f_row15_col1\" class=\"data row15 col1\" >25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_91e8f_row16_col0\" class=\"data row16 col0\" >Encoding method</td>\n",
       "      <td id=\"T_91e8f_row16_col1\" class=\"data row16 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_91e8f_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_91e8f_row17_col1\" class=\"data row17 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_91e8f_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_91e8f_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_91e8f_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_91e8f_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_91e8f_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_91e8f_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_91e8f_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_91e8f_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_91e8f_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_91e8f_row22_col1\" class=\"data row22 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_91e8f_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_91e8f_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_91e8f_row23_col1\" class=\"data row23 col1\" >2b45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fd9dfb30400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7fd9e4777970>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(data, target=target_column, session_id=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e10a3_row10_col0, #T_e10a3_row10_col1, #T_e10a3_row10_col2, #T_e10a3_row10_col3, #T_e10a3_row10_col4, #T_e10a3_row10_col5, #T_e10a3_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e10a3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e10a3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_e10a3_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_e10a3_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_e10a3_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_e10a3_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_e10a3_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_e10a3_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e10a3_row0_col0\" class=\"data row0 col0\" >0.8017</td>\n",
       "      <td id=\"T_e10a3_row0_col1\" class=\"data row0 col1\" >0.6288</td>\n",
       "      <td id=\"T_e10a3_row0_col2\" class=\"data row0 col2\" >0.2800</td>\n",
       "      <td id=\"T_e10a3_row0_col3\" class=\"data row0 col3\" >0.7201</td>\n",
       "      <td id=\"T_e10a3_row0_col4\" class=\"data row0 col4\" >0.4032</td>\n",
       "      <td id=\"T_e10a3_row0_col5\" class=\"data row0 col5\" >0.3109</td>\n",
       "      <td id=\"T_e10a3_row0_col6\" class=\"data row0 col6\" >0.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e10a3_row1_col0\" class=\"data row1 col0\" >0.7967</td>\n",
       "      <td id=\"T_e10a3_row1_col1\" class=\"data row1 col1\" >0.8309</td>\n",
       "      <td id=\"T_e10a3_row1_col2\" class=\"data row1 col2\" >0.3545</td>\n",
       "      <td id=\"T_e10a3_row1_col3\" class=\"data row1 col3\" >0.6346</td>\n",
       "      <td id=\"T_e10a3_row1_col4\" class=\"data row1 col4\" >0.4549</td>\n",
       "      <td id=\"T_e10a3_row1_col5\" class=\"data row1 col5\" >0.3421</td>\n",
       "      <td id=\"T_e10a3_row1_col6\" class=\"data row1 col6\" >0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e10a3_row2_col0\" class=\"data row2 col0\" >0.7988</td>\n",
       "      <td id=\"T_e10a3_row2_col1\" class=\"data row2 col1\" >0.5719</td>\n",
       "      <td id=\"T_e10a3_row2_col2\" class=\"data row2 col2\" >0.2555</td>\n",
       "      <td id=\"T_e10a3_row2_col3\" class=\"data row2 col3\" >0.7257</td>\n",
       "      <td id=\"T_e10a3_row2_col4\" class=\"data row2 col4\" >0.3779</td>\n",
       "      <td id=\"T_e10a3_row2_col5\" class=\"data row2 col5\" >0.2894</td>\n",
       "      <td id=\"T_e10a3_row2_col6\" class=\"data row2 col6\" >0.3458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e10a3_row3_col0\" class=\"data row3 col0\" >0.8049</td>\n",
       "      <td id=\"T_e10a3_row3_col1\" class=\"data row3 col1\" >0.6175</td>\n",
       "      <td id=\"T_e10a3_row3_col2\" class=\"data row3 col2\" >0.2787</td>\n",
       "      <td id=\"T_e10a3_row3_col3\" class=\"data row3 col3\" >0.7475</td>\n",
       "      <td id=\"T_e10a3_row3_col4\" class=\"data row3 col4\" >0.4061</td>\n",
       "      <td id=\"T_e10a3_row3_col5\" class=\"data row3 col5\" >0.3173</td>\n",
       "      <td id=\"T_e10a3_row3_col6\" class=\"data row3 col6\" >0.3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e10a3_row4_col0\" class=\"data row4 col0\" >0.7970</td>\n",
       "      <td id=\"T_e10a3_row4_col1\" class=\"data row4 col1\" >0.6027</td>\n",
       "      <td id=\"T_e10a3_row4_col2\" class=\"data row4 col2\" >0.2592</td>\n",
       "      <td id=\"T_e10a3_row4_col3\" class=\"data row4 col3\" >0.7067</td>\n",
       "      <td id=\"T_e10a3_row4_col4\" class=\"data row4 col4\" >0.3792</td>\n",
       "      <td id=\"T_e10a3_row4_col5\" class=\"data row4 col5\" >0.2878</td>\n",
       "      <td id=\"T_e10a3_row4_col6\" class=\"data row4 col6\" >0.3398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e10a3_row5_col0\" class=\"data row5 col0\" >0.8005</td>\n",
       "      <td id=\"T_e10a3_row5_col1\" class=\"data row5 col1\" >0.6340</td>\n",
       "      <td id=\"T_e10a3_row5_col2\" class=\"data row5 col2\" >0.2604</td>\n",
       "      <td id=\"T_e10a3_row5_col3\" class=\"data row5 col3\" >0.7345</td>\n",
       "      <td id=\"T_e10a3_row5_col4\" class=\"data row5 col4\" >0.3845</td>\n",
       "      <td id=\"T_e10a3_row5_col5\" class=\"data row5 col5\" >0.2964</td>\n",
       "      <td id=\"T_e10a3_row5_col6\" class=\"data row5 col6\" >0.3534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e10a3_row6_col0\" class=\"data row6 col0\" >0.7991</td>\n",
       "      <td id=\"T_e10a3_row6_col1\" class=\"data row6 col1\" >0.5716</td>\n",
       "      <td id=\"T_e10a3_row6_col2\" class=\"data row6 col2\" >0.2653</td>\n",
       "      <td id=\"T_e10a3_row6_col3\" class=\"data row6 col3\" >0.7162</td>\n",
       "      <td id=\"T_e10a3_row6_col4\" class=\"data row6 col4\" >0.3872</td>\n",
       "      <td id=\"T_e10a3_row6_col5\" class=\"data row6 col5\" >0.2961</td>\n",
       "      <td id=\"T_e10a3_row6_col6\" class=\"data row6 col6\" >0.3486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e10a3_row7_col0\" class=\"data row7 col0\" >0.7964</td>\n",
       "      <td id=\"T_e10a3_row7_col1\" class=\"data row7 col1\" >0.5653</td>\n",
       "      <td id=\"T_e10a3_row7_col2\" class=\"data row7 col2\" >0.2482</td>\n",
       "      <td id=\"T_e10a3_row7_col3\" class=\"data row7 col3\" >0.7148</td>\n",
       "      <td id=\"T_e10a3_row7_col4\" class=\"data row7 col4\" >0.3684</td>\n",
       "      <td id=\"T_e10a3_row7_col5\" class=\"data row7 col5\" >0.2796</td>\n",
       "      <td id=\"T_e10a3_row7_col6\" class=\"data row7 col6\" >0.3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e10a3_row8_col0\" class=\"data row8 col0\" >0.7938</td>\n",
       "      <td id=\"T_e10a3_row8_col1\" class=\"data row8 col1\" >0.5578</td>\n",
       "      <td id=\"T_e10a3_row8_col2\" class=\"data row8 col2\" >0.2552</td>\n",
       "      <td id=\"T_e10a3_row8_col3\" class=\"data row8 col3\" >0.6875</td>\n",
       "      <td id=\"T_e10a3_row8_col4\" class=\"data row8 col4\" >0.3722</td>\n",
       "      <td id=\"T_e10a3_row8_col5\" class=\"data row8 col5\" >0.2787</td>\n",
       "      <td id=\"T_e10a3_row8_col6\" class=\"data row8 col6\" >0.3279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e10a3_row9_col0\" class=\"data row9 col0\" >0.7946</td>\n",
       "      <td id=\"T_e10a3_row9_col1\" class=\"data row9 col1\" >0.5878</td>\n",
       "      <td id=\"T_e10a3_row9_col2\" class=\"data row9 col2\" >0.2543</td>\n",
       "      <td id=\"T_e10a3_row9_col3\" class=\"data row9 col3\" >0.6933</td>\n",
       "      <td id=\"T_e10a3_row9_col4\" class=\"data row9 col4\" >0.3721</td>\n",
       "      <td id=\"T_e10a3_row9_col5\" class=\"data row9 col5\" >0.2796</td>\n",
       "      <td id=\"T_e10a3_row9_col6\" class=\"data row9 col6\" >0.3301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_e10a3_row10_col0\" class=\"data row10 col0\" >0.7984</td>\n",
       "      <td id=\"T_e10a3_row10_col1\" class=\"data row10 col1\" >0.6168</td>\n",
       "      <td id=\"T_e10a3_row10_col2\" class=\"data row10 col2\" >0.2711</td>\n",
       "      <td id=\"T_e10a3_row10_col3\" class=\"data row10 col3\" >0.7081</td>\n",
       "      <td id=\"T_e10a3_row10_col4\" class=\"data row10 col4\" >0.3906</td>\n",
       "      <td id=\"T_e10a3_row10_col5\" class=\"data row10 col5\" >0.2978</td>\n",
       "      <td id=\"T_e10a3_row10_col6\" class=\"data row10 col6\" >0.3479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e10a3_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_e10a3_row11_col0\" class=\"data row11 col0\" >0.0032</td>\n",
       "      <td id=\"T_e10a3_row11_col1\" class=\"data row11 col1\" >0.0758</td>\n",
       "      <td id=\"T_e10a3_row11_col2\" class=\"data row11 col2\" >0.0295</td>\n",
       "      <td id=\"T_e10a3_row11_col3\" class=\"data row11 col3\" >0.0298</td>\n",
       "      <td id=\"T_e10a3_row11_col4\" class=\"data row11 col4\" >0.0246</td>\n",
       "      <td id=\"T_e10a3_row11_col5\" class=\"data row11 col5\" >0.0193</td>\n",
       "      <td id=\"T_e10a3_row11_col6\" class=\"data row11 col6\" >0.0142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fda45412770>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=123, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class=&#x27;auto&#x27;, n_jobs=None, penalty=&#x27;l2&#x27;,\n",
       "                   random_state=123, solver=&#x27;lbfgs&#x27;, tol=0.0001, verbose=0,\n",
       "                   warm_start=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.create_model('lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_config('X_train').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Pinged your deployment. You successfully connected to MongoDB!\n",
      "hello\n",
      "Description              Value\n",
      "hello\n",
      "0                    Session id                123\n",
      "hello\n",
      "1                        Target             income\n",
      "hello\n",
      "2                   Target type             Binary\n",
      "hello\n",
      "3                Target mapping  <=50K: 0, >50K: 1\n",
      "hello\n",
      "4           Original data shape        (48790, 15)\n",
      "hello\n",
      "5        Transformed data shape        (48790, 67)\n",
      "hello\n",
      "6   Transformed train set shape        (34153, 67)\n",
      "hello\n",
      "7    Transformed test set shape        (14637, 67)\n",
      "hello\n",
      "8              Ordinal features                  1\n",
      "hello\n",
      "9              Numeric features                  6\n",
      "hello\n",
      "10         Categorical features                  8\n",
      "hello\n",
      "11                   Preprocess               True\n",
      "hello\n",
      "12              Imputation type             simple\n",
      "hello\n",
      "13           Numeric imputation               mean\n",
      "hello\n",
      "14       Categorical imputation               mode\n",
      "hello\n",
      "15     Maximum one-hot encoding                 25\n",
      "hello\n",
      "16              Encoding method               None\n",
      "hello\n",
      "17               Fold Generator    StratifiedKFold\n",
      "hello\n",
      "18                  Fold Number                 10\n",
      "hello\n",
      "19                     CPU Jobs                 -1\n",
      "hello\n",
      "20                      Use GPU              False\n",
      "hello\n",
      "21               Log Experiment              False\n",
      "hello\n",
      "22              Experiment Name   clf-default-name\n",
      "hello\n",
      "23                          USI               78c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
      "hello\n",
      "ada      Ada Boost Classifier    0.8622  0.9171  0.6156  0.7636  0.6815\n",
      "hello\n",
      "lr        Logistic Regression    0.8519  0.9063  0.5994  0.7336  0.6596\n",
      "hello\n",
      "rf   Random Forest Classifier    0.8550  0.9049  0.6257  0.7305  0.6739\n",
      "hello\n",
      "nb                Naive Bayes    0.6843  0.8700  0.9019  0.4254  0.5780\n",
      "hello\n",
      "knn    K Neighbors Classifier    0.8253  0.8452  0.5734  0.6544  0.6111\n",
      "hello\n",
      "dt   Decision Tree Classifier    0.8159  0.7499  0.6233  0.6141  0.6185\n",
      "hello\n",
      "svm       SVM - Linear Kernel    0.8481  0.0000  0.5688  0.7397  0.6408\n",
      "hello\n",
      "\n",
      "hello\n",
      "Kappa     MCC  TT (Sec)\n",
      "hello\n",
      "ada  0.5949  0.6007     0.310\n",
      "hello\n",
      "lr   0.5662  0.5710     0.611\n",
      "hello\n",
      "rf   0.5814  0.5844     0.642\n",
      "hello\n",
      "nb   0.3743  0.4422     0.221\n",
      "hello\n",
      "knn  0.4991  0.5010     0.656\n",
      "hello\n",
      "dt   0.4973  0.4974     0.206\n",
      "hello\n",
      "svm  0.5469  0.5559     0.207\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import subprocess\n",
    "# import sys \n",
    "# sys.path.append('/home/ayush/BTP-2/backend/')\n",
    "# import trainModelAutoML\n",
    "process = subprocess.Popen(['python3', '/home/ayush/BTP-2/backend/functions/trainModelAutoML.py'], stdout=subprocess.PIPE)\n",
    "\n",
    "while True:\n",
    "    output = process.stdout.readline()\n",
    "    # print(output)\n",
    "    if output.decode('utf-8') == '' and process.poll() is not None:\n",
    "        break\n",
    "    if output:\n",
    "        print('hello')\n",
    "        print(output.strip().decode('utf-8'))\n",
    "        # print(\"hello\")\n",
    "        # sse.publish(output.strip().decode('utf-8'), type='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(capturedOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_leaderboard = exp.get_leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=FastMemory(location=/tmp/joblib),\n",
      "         steps=[('label_encoding',\n",
      "                 TransformerWrapperWithInverse(exclude=None, include=None,\n",
      "                                               transformer=LabelEncoder())),\n",
      "                ('numerical_imputer',\n",
      "                 TransformerWrapper(exclude=None,\n",
      "                                    include=['age', 'fnlwgt', 'educational-num',\n",
      "                                             'capital-gain', 'capital-loss',\n",
      "                                             'hours-per-week'],\n",
      "                                    transformer=SimpleImputer(add_indicator=False,\n",
      "                                                              co...\n",
      "                                                              min_samples_leaf=20,\n",
      "                                                              return_df=True,\n",
      "                                                              smoothing=10,\n",
      "                                                              verbose=0))),\n",
      "                ('clean_column_names',\n",
      "                 TransformerWrapper(exclude=None, include=None,\n",
      "                                    transformer=CleanColumnNames(match='[\\\\]\\\\[\\\\,\\\\{\\\\}\\\\\"\\\\:]+'))),\n",
      "                ['trained_model',\n",
      "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
      "                                      metric='minkowski', metric_params=None,\n",
      "                                      n_jobs=-1, n_neighbors=5, p=2,\n",
      "                                      weights='uniform')]],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(get_leaderboard.iloc[0]['Model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797535e997844369bf0982a3aece849a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from time import sleep\n",
    "\n",
    "text = \"\"\n",
    "for char in tqdm([\"a\", \"b\", \"c\", \"d\"]):\n",
    "    sleep(5)\n",
    "    text = text + char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exp.pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "      <th>TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.3479</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>K Neighbors Classifier</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>0.3221</td>\n",
       "      <td>0.5577</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
       "lr      Logistic Regression    0.7984  0.6168  0.2711  0.7081  0.3906  0.2978   \n",
       "knn  K Neighbors Classifier    0.7766  0.6766  0.3221  0.5577  0.4082  0.2825   \n",
       "\n",
       "        MCC  TT (Sec)  \n",
       "lr   0.3479     0.761  \n",
       "knn  0.2988     0.782  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model\n",
      "Accuracy\n",
      "AUC\n",
      "Recall\n",
      "Prec.\n",
      "F1\n",
      "Kappa\n",
      "MCC\n",
      "TT (Sec)\n"
     ]
    }
   ],
   "source": [
    "for column in results.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>Kappa</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "      <td>0.2978</td>\n",
       "      <td>0.3479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
       "Fold                                                          \n",
       "Mean    0.7984  0.6168  0.2711  0.7081  0.3906  0.2978  0.3479"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[results.index == 'Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7984\n",
      "0.6168\n",
      "0.2711\n",
      "0.7081\n",
      "0.3906\n",
      "0.2978\n",
      "0.3479\n"
     ]
    }
   ],
   "source": [
    "for metric in results.columns:\n",
    "    print(results[results.index == 'Mean'][metric].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(['TT (Sec)','Kappa', 'MCC'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.6199</td>\n",
       "      <td>0.7401</td>\n",
       "      <td>0.6745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7984</td>\n",
       "      <td>0.6168</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>0.3906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model  Accuracy     AUC  Recall   Prec.      F1\n",
       "rf  Random Forest Classifier    0.8569  0.9040  0.6199  0.7401  0.6745\n",
       "lr       Logistic Regression    0.7984  0.6168  0.2711  0.7081  0.3906"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy\n",
      "0.8569\n",
      "AUC\n",
      "0.904\n",
      "Recall\n",
      "0.6199\n",
      "Prec.\n",
      "0.7401\n",
      "F1\n",
      "0.6745\n"
     ]
    }
   ],
   "source": [
    "for metric in results.columns:\n",
    "    # print first row's metric\n",
    "    if metric == 'Model':\n",
    "        continue\n",
    "    print(metric)\n",
    "    print(results.iloc[0][metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ayush/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.548913</td>\n",
       "      <td>0.334021</td>\n",
       "      <td>0.335510</td>\n",
       "      <td>0.325503</td>\n",
       "      <td>0.742666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.570652</td>\n",
       "      <td>0.358427</td>\n",
       "      <td>0.354621</td>\n",
       "      <td>0.345584</td>\n",
       "      <td>0.742626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.554348</td>\n",
       "      <td>0.358026</td>\n",
       "      <td>0.350028</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.593768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.614130</td>\n",
       "      <td>0.405137</td>\n",
       "      <td>0.401276</td>\n",
       "      <td>0.399125</td>\n",
       "      <td>0.760712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.538043</td>\n",
       "      <td>0.334563</td>\n",
       "      <td>0.338462</td>\n",
       "      <td>0.334558</td>\n",
       "      <td>0.689957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>0.385870</td>\n",
       "      <td>0.352309</td>\n",
       "      <td>0.392148</td>\n",
       "      <td>0.246430</td>\n",
       "      <td>0.739050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.548913</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.335749</td>\n",
       "      <td>0.680536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Classifier  Accuracy  Precision    Recall  F1-Score       AUC\n",
       "0      LogisticRegression  0.548913   0.334021  0.335510  0.325503  0.742666\n",
       "1                     SVC  0.570652   0.358427  0.354621  0.345584  0.742626\n",
       "2  DecisionTreeClassifier  0.554348   0.358026  0.350028  0.348534  0.593768\n",
       "3  RandomForestClassifier  0.614130   0.405137  0.401276  0.399125  0.760712\n",
       "4      AdaBoostClassifier  0.538043   0.334563  0.338462  0.334558  0.689957\n",
       "5              GaussianNB  0.385870   0.352309  0.392148  0.246430  0.739050\n",
       "6    KNeighborsClassifier  0.548913   0.341224  0.343373  0.335749  0.680536"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../Datasets/27562.csv')\n",
    "target_column = 'num'\n",
    "classification_utility = ClassificationUtility(data, target_column)\n",
    "classification_utility.train()\n",
    "classification_utility.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'educational-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'income'],\n",
      "      dtype='object')\n",
      "['education', 'occupation', 'native-country']\n",
      "['workclass', 'marital-status', 'relationship', 'race', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# make a pipeline of the following steps\n",
    "# i) Imputation of numerical and categorical variables\n",
    "# ii) Encoding of categorical variables using target encoding if cardinality is less than 10 else one hot encoding\n",
    "# iii) Scaling of numerical variables\n",
    "# iv) Estimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('../Datasets/68071.csv')\n",
    "target_column = 'income'\n",
    "model_name = 'adult'\n",
    "\n",
    "\n",
    "\n",
    "# find categorical and numerical columns\n",
    "categorical_columns = []\n",
    "numerical_columns = []\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == 'object':\n",
    "        categorical_columns.append(column)\n",
    "    else:\n",
    "        numerical_columns.append(column)\n",
    "\n",
    "# find cardinality of categorical columns\n",
    "cardinality = {}\n",
    "for column in categorical_columns:\n",
    "    cardinality[column] = len(data[column].unique())\n",
    "\n",
    "# find columns to be target encoded\n",
    "target_encoded_columns = []\n",
    "one_hot_encoded_columns = []\n",
    "for column in categorical_columns:\n",
    "    if column != target_column:\n",
    "        if cardinality[column] > 10:\n",
    "            target_encoded_columns.append(column)\n",
    "        else:\n",
    "            one_hot_encoded_columns.append(column)\n",
    "\n",
    "# find columns to be one hot encoded\n",
    "\n",
    "le = LabelEncoder()\n",
    "data[target_column] = le.fit_transform(data[target_column])\n",
    "        \n",
    "print(data.columns)\n",
    "print(target_encoded_columns)\n",
    "print(one_hot_encoded_columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=0.2, random_state=42)\n",
    "\n",
    "# make pipeline\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "target_categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('target', TargetEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_columns),\n",
    "        ('cat', categorical_transformer, one_hot_encoded_columns),\n",
    "        ('target', target_categorical_transformer, target_encoded_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    SVC(kernel='linear', max_iter=1000),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier()\n",
    "]\n",
    "scores_arr = []\n",
    "# for classifier in tqdm(classifiers):\n",
    "\n",
    "estimator = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = cross_val_score(estimator, X_train, y_train, cv=5, scoring='accuracy')\n",
    "scores_arr.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8511117586099672, 0.4784630681268004, 0.8142582622544747, 0.8619631987863128, 0.8630482533082594, 0.7209778395263091, 0.8345071814106516]\n"
     ]
    }
   ],
   "source": [
    "print(scores_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "# print label encoder mapping\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import sys \n",
    "sys.path.append('../')\n",
    "from Enums.enums import ClassificationMetrics\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ClassificationUtility():\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.cardinality_threshold = 10\n",
    "        self.classifiers = [\n",
    "            LogisticRegression(max_iter=1000),\n",
    "            SVC(kernel='linear', max_iter=1000, probability=True),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            AdaBoostClassifier(),\n",
    "            GaussianNB(),\n",
    "            KNeighborsClassifier()\n",
    "        ]\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64':\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def encode_target_column(self):\n",
    "        le = LabelEncoder()\n",
    "        self.data[self.target_column] = le.fit_transform(self.data[self.target_column])\n",
    "        self.le = le\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "        self.encode_target_column()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "        classification_metrics = ClassificationMetrics\n",
    "        columns_names = []\n",
    "        columns_names.append('Classifier')\n",
    "        for metric in classification_metrics:\n",
    "            columns_names.append(metric.value)\n",
    "\n",
    "        results = [columns_names]\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            X = self.data.drop(self.target_column, axis=1)\n",
    "            y = self.data[self.target_column]\n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            self.estimator.fit(X_train, y_train)\n",
    "\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred, average='macro')\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "            f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            if len(self.le.classes_) == 2:\n",
    "                auc = roc_auc_score(y_test, self.estimator.predict_proba(X_test)[:, 1])\n",
    "            else:\n",
    "                auc = roc_auc_score(y_test, self.estimator.predict_proba(X_test), average='macro', multi_class='ovo')\n",
    "\n",
    "            results.append([classifier.__class__.__name__, accuracy, precision, recall, f1, auc])\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results[1:], columns=results[0])\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        for i, class_name in enumerate(self.le.classes_):\n",
    "            self.output_mapping[i] = class_name\n",
    "        return self.output_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: KNeighborsClassifier Processing: 100%|██████████| 7/7 [01:08<00:00,  9.72s/it]  \n"
     ]
    }
   ],
   "source": [
    "# data = pd.read_csv('../Datasets/27562.csv')\n",
    "data = pd.read_csv('../Datasets/68071.csv')\n",
    "target_column = 'income'\n",
    "classification_utility = ClassificationUtility(data, target_column)\n",
    "classification_utility.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(classification_utility.le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = classification_utility.results\n",
    "best_model_name = classification_utility.getBestModel(ClassificationMetrics.Accuracy.value)['Classifier']\n",
    "model_parameters = classification_utility.trained_models[best_model_name].get_params()\n",
    "metrics = []\n",
    "for metric in results.columns:\n",
    "    if metric == 'Classifier':\n",
    "        continue\n",
    "    metrics.append({\n",
    "        'metric_name' : metric,\n",
    "        'metric_value' : results.iloc[0][metric],\n",
    "    })\n",
    "\n",
    "parameters = []\n",
    "for key, value in model_parameters.items():\n",
    "    if value == None:\n",
    "        value = 'None'\n",
    "    parameters.append({\n",
    "        'parameter_name' : key,\n",
    "        'parameter_value' : value\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_utility.saveModel(best_model_name, '../Models/27562.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('../Models/27562.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(target_column, axis=1), data[target_column], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metric_name': 'Accuracy', 'metric_value': 0.6413043478260869}, {'metric_name': 'AUC', 'metric_value': 0.44483974358974365}, {'metric_name': 'Precision', 'metric_value': 0.42140170940170946}, {'metric_name': 'Recall', 'metric_value': 0.42327461024408475}, {'metric_name': 'F1', 'metric_value': 0.775362559354226}]\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy       AUC  Precision    Recall        F1\n",
      "3  RandomForestClassifier  0.641304  0.444840   0.421402  0.423275  0.775363\n",
      "1                     SVC  0.570652  0.358427   0.354621  0.345584  0.742021\n",
      "2  DecisionTreeClassifier  0.554348  0.384571   0.393066  0.381803  0.620666\n",
      "0      LogisticRegression  0.548913  0.334021   0.335510  0.325503  0.742666\n",
      "6    KNeighborsClassifier  0.548913  0.341224   0.343373  0.335749  0.680536\n",
      "4      AdaBoostClassifier  0.538043  0.334563   0.338462  0.334558  0.689957\n",
      "5              GaussianNB  0.385870  0.352309   0.392148  0.246430  0.739050\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, TargetEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# import regression models\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import Ridge, BayesianRidge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "import sys \n",
    "project_path = os.getenv('PROJECT_PATH')\n",
    "sys.path.append(project_path)\n",
    "sys.path.append('../Enums/')\n",
    "from Enums.enums import RegressionMetrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class RegressionUtility():\n",
    "    def __init__(self, data, target_column):\n",
    "        self.data = data\n",
    "        self.target_column = target_column\n",
    "        self.cardinality_threshold = 10\n",
    "        self.classifiers = [\n",
    "            Ridge(alpha=0.5),\n",
    "            BayesianRidge(),\n",
    "            RandomForestRegressor(),\n",
    "            AdaBoostRegressor()\n",
    "        ]\n",
    "\n",
    "    def get_numerical_columns(self):\n",
    "        numerical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column and (self.data[column].dtype == 'int64' or self.data[column].dtype == 'float64'):\n",
    "                numerical_columns.append(column)\n",
    "        self.numerical_columns = numerical_columns\n",
    "        # return numerical_columns\n",
    "    \n",
    "    def get_categorical_columns(self):\n",
    "        categorical_columns = []\n",
    "        for column in self.data.columns:\n",
    "            if self.data[column].dtype == 'object':\n",
    "                categorical_columns.append(column)\n",
    "        self.categorical_columns = categorical_columns\n",
    "        # return categorical_columns\n",
    "\n",
    "    def get_categorical_column_cardinality(self):\n",
    "        cardinality = {}\n",
    "        for column in self.categorical_columns:\n",
    "            cardinality[column] = len(self.data[column].unique())\n",
    "        self.cardinality = cardinality\n",
    "\n",
    "    def get_target_encoding_columns(self):\n",
    "        target_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and  self.cardinality[column] > self.cardinality_threshold:\n",
    "                target_encoding_columns.append(column)\n",
    "        self.target_encoding_columns = target_encoding_columns\n",
    "    \n",
    "    def get_one_hot_encoding_columns(self):\n",
    "        one_hot_encoding_columns = []\n",
    "        for column in self.categorical_columns:\n",
    "            if column != self.target_column and self.cardinality[column] <= self.cardinality_threshold:\n",
    "                one_hot_encoding_columns.append(column)\n",
    "        self.one_hot_encoding_columns = one_hot_encoding_columns\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.get_numerical_columns()\n",
    "        self.get_categorical_columns()\n",
    "        self.get_categorical_column_cardinality()\n",
    "        self.get_target_encoding_columns()\n",
    "        self.get_one_hot_encoding_columns()\n",
    "\n",
    "    def get_preprocessor(self):\n",
    "        numerical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        target_categorical_transformer = Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "            ('target', TargetEncoder())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('numerical', numerical_transformer, self.numerical_columns),\n",
    "                ('one_hot_encoding', categorical_transformer, self.one_hot_encoding_columns),\n",
    "                ('target_encoding', target_categorical_transformer, self.target_encoding_columns)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.preprocessor = preprocessor\n",
    "    \n",
    "    def get_estimator(self, estimator):\n",
    "\n",
    "        estimator = Pipeline(steps=[\n",
    "            ('preprocessor', self.preprocessor),\n",
    "            ('classifier', estimator)\n",
    "        ])\n",
    "        self.estimator = estimator\n",
    "    \n",
    "    def trainAutoML(self):\n",
    "        self.prepare_data()\n",
    "        self.get_preprocessor()\n",
    "        print(\"Status: Setting up AutoML Training\", file=sys.stderr)\n",
    "\n",
    "        results = []\n",
    "        trained_models = {}\n",
    "\n",
    "        pbar = tqdm(self.classifiers)\n",
    "        for classifier in pbar:\n",
    "            self.get_estimator(classifier)\n",
    "            X = self.data.drop(self.target_column, axis=1)\n",
    "            y = self.data[self.target_column]\n",
    "            \n",
    "            pbar.set_description(\"Status: %s Current Classifier: %s Processing\" % ('Training', classifier.__class__.__name__))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "            self.estimator.fit(X_train, y_train)\n",
    "            trained_models[classifier.__class__.__name__] = self.estimator\n",
    "\n",
    "            y_pred = self.estimator.predict(X_test)\n",
    "            # print(y_pred)\n",
    "\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "            results.append({\n",
    "                'Classifier' : classifier.__class__.__name__,\n",
    "                RegressionMetrics.R2.value : r2,\n",
    "                RegressionMetrics.MSE.value : mse,\n",
    "                RegressionMetrics.MAE.value : mae,\n",
    "                RegressionMetrics.RMSE.value : rmse\n",
    "            })\n",
    "        \n",
    "        self.trained_models = trained_models\n",
    "        self.results = pd.DataFrame(results)\n",
    "\n",
    "    def getBestModel(self, metric):\n",
    "        self.results.sort_values(by=metric, ascending=False, inplace=True)\n",
    "        self.best_model = self.results.iloc[0]\n",
    "        return self.best_model\n",
    "    \n",
    "    def saveModel(self, model_name, save_path):\n",
    "        joblib.dump(self.trained_models[model_name], save_path)\n",
    "        self.save_path = save_path\n",
    "    \n",
    "    def get_input_schema(self):\n",
    "        self.input_schema = []\n",
    "        for column in self.data.columns:\n",
    "            if column != self.target_column:\n",
    "                self.input_schema.append({\n",
    "                    'column_name' : column,\n",
    "                    'column_type' : self.data[column].dtype.name\n",
    "                })\n",
    "        return self.input_schema\n",
    "    \n",
    "    def get_output_schema(self):\n",
    "        self.output_schema = []\n",
    "        self.output_schema.append({\n",
    "            'column_name' : self.target_column,\n",
    "            'column_type' : self.data[self.target_column].dtype.name\n",
    "        })\n",
    "        return self.output_schema\n",
    "    \n",
    "    def get_output_mapping(self):\n",
    "        self.output_mapping = {}\n",
    "        for i, class_name in enumerate(self.le.classes_):\n",
    "            self.output_mapping[str(class_name)] = i\n",
    "        return self.output_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../backend/Walmart.csv')\n",
    "target_column = 'Weekly_Sales'\n",
    "reg_util = RegressionUtility(data, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Status: Setting up AutoML Training\n",
      "Status: Training Current Classifier: AdaBoostRegressor Processing: 100%|██████████| 4/4 [00:03<00:00,  1.23it/s]    \n"
     ]
    }
   ],
   "source": [
    "reg_util.trainAutoML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.159073</td>\n",
       "      <td>2.709084e+11</td>\n",
       "      <td>433043.517724</td>\n",
       "      <td>520488.659793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>3.200472e+11</td>\n",
       "      <td>475527.780787</td>\n",
       "      <td>565727.167346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.972341</td>\n",
       "      <td>8.910513e+09</td>\n",
       "      <td>56805.422846</td>\n",
       "      <td>94395.512885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.366526</td>\n",
       "      <td>2.040766e+11</td>\n",
       "      <td>393209.639893</td>\n",
       "      <td>451748.408276</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Classifier  R2 Score  Mean Squared Error  Mean Absolute Error  \\\n",
       "0                  Ridge  0.159073        2.709084e+11        433043.517724   \n",
       "1          BayesianRidge  0.006541        3.200472e+11        475527.780787   \n",
       "2  RandomForestRegressor  0.972341        8.910513e+09         56805.422846   \n",
       "3      AdaBoostRegressor  0.366526        2.040766e+11        393209.639893   \n",
       "\n",
       "   Root Mean Squared Error  \n",
       "0            520488.659793  \n",
       "1            565727.167346  \n",
       "2             94395.512885  \n",
       "3            451748.408276  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_util.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
